{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.1013215859030836,
  "eval_steps": 500,
  "global_step": 1000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0,
      "learning_rate": 5.000000000000001e-07,
      "loss": 3.4837,
      "step": 1
    },
    {
      "epoch": 0.0,
      "learning_rate": 1.0000000000000002e-06,
      "loss": 3.421,
      "step": 2
    },
    {
      "epoch": 0.0,
      "learning_rate": 1.5e-06,
      "loss": 3.4057,
      "step": 3
    },
    {
      "epoch": 0.0,
      "learning_rate": 2.0000000000000003e-06,
      "loss": 3.4035,
      "step": 4
    },
    {
      "epoch": 0.01,
      "learning_rate": 2.5e-06,
      "loss": 3.2612,
      "step": 5
    },
    {
      "epoch": 0.01,
      "learning_rate": 3e-06,
      "loss": 3.4662,
      "step": 6
    },
    {
      "epoch": 0.01,
      "learning_rate": 3.5000000000000004e-06,
      "loss": 3.4528,
      "step": 7
    },
    {
      "epoch": 0.01,
      "learning_rate": 4.000000000000001e-06,
      "loss": 3.2216,
      "step": 8
    },
    {
      "epoch": 0.01,
      "learning_rate": 4.5e-06,
      "loss": 3.5331,
      "step": 9
    },
    {
      "epoch": 0.01,
      "learning_rate": 5e-06,
      "loss": 3.4739,
      "step": 10
    },
    {
      "epoch": 0.01,
      "learning_rate": 5.500000000000001e-06,
      "loss": 3.8404,
      "step": 11
    },
    {
      "epoch": 0.01,
      "learning_rate": 6e-06,
      "loss": 3.8214,
      "step": 12
    },
    {
      "epoch": 0.01,
      "learning_rate": 6.5000000000000004e-06,
      "loss": 3.5681,
      "step": 13
    },
    {
      "epoch": 0.02,
      "learning_rate": 7.000000000000001e-06,
      "loss": 3.4257,
      "step": 14
    },
    {
      "epoch": 0.02,
      "learning_rate": 7.5e-06,
      "loss": 3.4143,
      "step": 15
    },
    {
      "epoch": 0.02,
      "learning_rate": 8.000000000000001e-06,
      "loss": 3.4768,
      "step": 16
    },
    {
      "epoch": 0.02,
      "learning_rate": 8.500000000000002e-06,
      "loss": 3.5127,
      "step": 17
    },
    {
      "epoch": 0.02,
      "learning_rate": 9e-06,
      "loss": 3.2998,
      "step": 18
    },
    {
      "epoch": 0.02,
      "learning_rate": 9.5e-06,
      "loss": 3.2866,
      "step": 19
    },
    {
      "epoch": 0.02,
      "learning_rate": 1e-05,
      "loss": 3.4027,
      "step": 20
    },
    {
      "epoch": 0.02,
      "learning_rate": 1.05e-05,
      "loss": 3.4313,
      "step": 21
    },
    {
      "epoch": 0.02,
      "learning_rate": 1.1000000000000001e-05,
      "loss": 3.1273,
      "step": 22
    },
    {
      "epoch": 0.03,
      "learning_rate": 1.1500000000000002e-05,
      "loss": 3.0616,
      "step": 23
    },
    {
      "epoch": 0.03,
      "learning_rate": 1.2e-05,
      "loss": 3.4465,
      "step": 24
    },
    {
      "epoch": 0.03,
      "learning_rate": 1.25e-05,
      "loss": 3.1692,
      "step": 25
    },
    {
      "epoch": 0.03,
      "learning_rate": 1.3000000000000001e-05,
      "loss": 3.2481,
      "step": 26
    },
    {
      "epoch": 0.03,
      "learning_rate": 1.3500000000000001e-05,
      "loss": 3.4275,
      "step": 27
    },
    {
      "epoch": 0.03,
      "learning_rate": 1.4000000000000001e-05,
      "loss": 3.3356,
      "step": 28
    },
    {
      "epoch": 0.03,
      "learning_rate": 1.45e-05,
      "loss": 3.5024,
      "step": 29
    },
    {
      "epoch": 0.03,
      "learning_rate": 1.5e-05,
      "loss": 3.3726,
      "step": 30
    },
    {
      "epoch": 0.03,
      "learning_rate": 1.55e-05,
      "loss": 3.4327,
      "step": 31
    },
    {
      "epoch": 0.04,
      "learning_rate": 1.6000000000000003e-05,
      "loss": 3.4416,
      "step": 32
    },
    {
      "epoch": 0.04,
      "learning_rate": 1.65e-05,
      "loss": 3.5425,
      "step": 33
    },
    {
      "epoch": 0.04,
      "learning_rate": 1.7000000000000003e-05,
      "loss": 3.217,
      "step": 34
    },
    {
      "epoch": 0.04,
      "learning_rate": 1.75e-05,
      "loss": 3.283,
      "step": 35
    },
    {
      "epoch": 0.04,
      "learning_rate": 1.8e-05,
      "loss": 3.483,
      "step": 36
    },
    {
      "epoch": 0.04,
      "learning_rate": 1.85e-05,
      "loss": 3.555,
      "step": 37
    },
    {
      "epoch": 0.04,
      "learning_rate": 1.9e-05,
      "loss": 3.407,
      "step": 38
    },
    {
      "epoch": 0.04,
      "learning_rate": 1.9500000000000003e-05,
      "loss": 3.2687,
      "step": 39
    },
    {
      "epoch": 0.04,
      "learning_rate": 2e-05,
      "loss": 3.5258,
      "step": 40
    },
    {
      "epoch": 0.05,
      "learning_rate": 2.05e-05,
      "loss": 3.3584,
      "step": 41
    },
    {
      "epoch": 0.05,
      "learning_rate": 2.1e-05,
      "loss": 3.3977,
      "step": 42
    },
    {
      "epoch": 0.05,
      "learning_rate": 2.15e-05,
      "loss": 3.5133,
      "step": 43
    },
    {
      "epoch": 0.05,
      "learning_rate": 2.2000000000000003e-05,
      "loss": 3.4043,
      "step": 44
    },
    {
      "epoch": 0.05,
      "learning_rate": 2.25e-05,
      "loss": 3.2414,
      "step": 45
    },
    {
      "epoch": 0.05,
      "learning_rate": 2.3000000000000003e-05,
      "loss": 3.3189,
      "step": 46
    },
    {
      "epoch": 0.05,
      "learning_rate": 2.35e-05,
      "loss": 3.339,
      "step": 47
    },
    {
      "epoch": 0.05,
      "learning_rate": 2.4e-05,
      "loss": 3.356,
      "step": 48
    },
    {
      "epoch": 0.05,
      "learning_rate": 2.45e-05,
      "loss": 3.3845,
      "step": 49
    },
    {
      "epoch": 0.06,
      "learning_rate": 2.5e-05,
      "loss": 3.4047,
      "step": 50
    },
    {
      "epoch": 0.06,
      "learning_rate": 2.5500000000000003e-05,
      "loss": 3.4075,
      "step": 51
    },
    {
      "epoch": 0.06,
      "learning_rate": 2.6000000000000002e-05,
      "loss": 3.1971,
      "step": 52
    },
    {
      "epoch": 0.06,
      "learning_rate": 2.6500000000000004e-05,
      "loss": 3.2538,
      "step": 53
    },
    {
      "epoch": 0.06,
      "learning_rate": 2.7000000000000002e-05,
      "loss": 3.5962,
      "step": 54
    },
    {
      "epoch": 0.06,
      "learning_rate": 2.7500000000000004e-05,
      "loss": 3.4584,
      "step": 55
    },
    {
      "epoch": 0.06,
      "learning_rate": 2.8000000000000003e-05,
      "loss": 3.461,
      "step": 56
    },
    {
      "epoch": 0.06,
      "learning_rate": 2.8499999999999998e-05,
      "loss": 3.4684,
      "step": 57
    },
    {
      "epoch": 0.06,
      "learning_rate": 2.9e-05,
      "loss": 3.4149,
      "step": 58
    },
    {
      "epoch": 0.06,
      "learning_rate": 2.95e-05,
      "loss": 3.4266,
      "step": 59
    },
    {
      "epoch": 0.07,
      "learning_rate": 3e-05,
      "loss": 3.5096,
      "step": 60
    },
    {
      "epoch": 0.07,
      "learning_rate": 3.05e-05,
      "loss": 3.4488,
      "step": 61
    },
    {
      "epoch": 0.07,
      "learning_rate": 3.1e-05,
      "loss": 3.3184,
      "step": 62
    },
    {
      "epoch": 0.07,
      "learning_rate": 3.15e-05,
      "loss": 3.2574,
      "step": 63
    },
    {
      "epoch": 0.07,
      "learning_rate": 3.2000000000000005e-05,
      "loss": 3.19,
      "step": 64
    },
    {
      "epoch": 0.07,
      "learning_rate": 3.2500000000000004e-05,
      "loss": 3.3165,
      "step": 65
    },
    {
      "epoch": 0.07,
      "learning_rate": 3.3e-05,
      "loss": 3.1784,
      "step": 66
    },
    {
      "epoch": 0.07,
      "learning_rate": 3.35e-05,
      "loss": 3.3827,
      "step": 67
    },
    {
      "epoch": 0.07,
      "learning_rate": 3.4000000000000007e-05,
      "loss": 3.1006,
      "step": 68
    },
    {
      "epoch": 0.08,
      "learning_rate": 3.45e-05,
      "loss": 3.3479,
      "step": 69
    },
    {
      "epoch": 0.08,
      "learning_rate": 3.5e-05,
      "loss": 3.5415,
      "step": 70
    },
    {
      "epoch": 0.08,
      "learning_rate": 3.55e-05,
      "loss": 3.3923,
      "step": 71
    },
    {
      "epoch": 0.08,
      "learning_rate": 3.6e-05,
      "loss": 3.2877,
      "step": 72
    },
    {
      "epoch": 0.08,
      "learning_rate": 3.65e-05,
      "loss": 3.3294,
      "step": 73
    },
    {
      "epoch": 0.08,
      "learning_rate": 3.7e-05,
      "loss": 3.2899,
      "step": 74
    },
    {
      "epoch": 0.08,
      "learning_rate": 3.7500000000000003e-05,
      "loss": 3.4446,
      "step": 75
    },
    {
      "epoch": 0.08,
      "learning_rate": 3.8e-05,
      "loss": 3.1973,
      "step": 76
    },
    {
      "epoch": 0.08,
      "learning_rate": 3.85e-05,
      "loss": 3.2875,
      "step": 77
    },
    {
      "epoch": 0.09,
      "learning_rate": 3.9000000000000006e-05,
      "loss": 3.4138,
      "step": 78
    },
    {
      "epoch": 0.09,
      "learning_rate": 3.9500000000000005e-05,
      "loss": 3.0923,
      "step": 79
    },
    {
      "epoch": 0.09,
      "learning_rate": 4e-05,
      "loss": 3.2303,
      "step": 80
    },
    {
      "epoch": 0.09,
      "learning_rate": 4.05e-05,
      "loss": 3.2053,
      "step": 81
    },
    {
      "epoch": 0.09,
      "learning_rate": 4.1e-05,
      "loss": 3.1835,
      "step": 82
    },
    {
      "epoch": 0.09,
      "learning_rate": 4.15e-05,
      "loss": 3.3369,
      "step": 83
    },
    {
      "epoch": 0.09,
      "learning_rate": 4.2e-05,
      "loss": 3.3185,
      "step": 84
    },
    {
      "epoch": 0.09,
      "learning_rate": 4.25e-05,
      "loss": 3.3051,
      "step": 85
    },
    {
      "epoch": 0.09,
      "learning_rate": 4.3e-05,
      "loss": 3.3068,
      "step": 86
    },
    {
      "epoch": 0.1,
      "learning_rate": 4.35e-05,
      "loss": 3.216,
      "step": 87
    },
    {
      "epoch": 0.1,
      "learning_rate": 4.4000000000000006e-05,
      "loss": 3.3608,
      "step": 88
    },
    {
      "epoch": 0.1,
      "learning_rate": 4.4500000000000004e-05,
      "loss": 3.2391,
      "step": 89
    },
    {
      "epoch": 0.1,
      "learning_rate": 4.5e-05,
      "loss": 3.2755,
      "step": 90
    },
    {
      "epoch": 0.1,
      "learning_rate": 4.55e-05,
      "loss": 3.0971,
      "step": 91
    },
    {
      "epoch": 0.1,
      "learning_rate": 4.600000000000001e-05,
      "loss": 3.2637,
      "step": 92
    },
    {
      "epoch": 0.1,
      "learning_rate": 4.6500000000000005e-05,
      "loss": 3.3819,
      "step": 93
    },
    {
      "epoch": 0.1,
      "learning_rate": 4.7e-05,
      "loss": 3.4177,
      "step": 94
    },
    {
      "epoch": 0.1,
      "learning_rate": 4.75e-05,
      "loss": 3.3461,
      "step": 95
    },
    {
      "epoch": 0.11,
      "learning_rate": 4.8e-05,
      "loss": 3.3624,
      "step": 96
    },
    {
      "epoch": 0.11,
      "learning_rate": 4.85e-05,
      "loss": 3.3241,
      "step": 97
    },
    {
      "epoch": 0.11,
      "learning_rate": 4.9e-05,
      "loss": 3.463,
      "step": 98
    },
    {
      "epoch": 0.11,
      "learning_rate": 4.9500000000000004e-05,
      "loss": 3.197,
      "step": 99
    },
    {
      "epoch": 0.11,
      "learning_rate": 5e-05,
      "loss": 3.3392,
      "step": 100
    },
    {
      "epoch": 0.11,
      "learning_rate": 5.05e-05,
      "loss": 3.2443,
      "step": 101
    },
    {
      "epoch": 0.11,
      "learning_rate": 5.1000000000000006e-05,
      "loss": 3.4178,
      "step": 102
    },
    {
      "epoch": 0.11,
      "learning_rate": 5.1500000000000005e-05,
      "loss": 3.389,
      "step": 103
    },
    {
      "epoch": 0.11,
      "learning_rate": 5.2000000000000004e-05,
      "loss": 3.2211,
      "step": 104
    },
    {
      "epoch": 0.12,
      "learning_rate": 5.25e-05,
      "loss": 3.3312,
      "step": 105
    },
    {
      "epoch": 0.12,
      "learning_rate": 5.25e-05,
      "loss": 3.4114,
      "step": 106
    },
    {
      "epoch": 0.12,
      "learning_rate": 5.300000000000001e-05,
      "loss": 3.2385,
      "step": 107
    },
    {
      "epoch": 0.12,
      "learning_rate": 5.3500000000000006e-05,
      "loss": 3.2976,
      "step": 108
    },
    {
      "epoch": 0.12,
      "learning_rate": 5.4000000000000005e-05,
      "loss": 3.1615,
      "step": 109
    },
    {
      "epoch": 0.12,
      "learning_rate": 5.45e-05,
      "loss": 3.4048,
      "step": 110
    },
    {
      "epoch": 0.12,
      "learning_rate": 5.500000000000001e-05,
      "loss": 3.4051,
      "step": 111
    },
    {
      "epoch": 0.12,
      "learning_rate": 5.550000000000001e-05,
      "loss": 3.2261,
      "step": 112
    },
    {
      "epoch": 0.12,
      "learning_rate": 5.6000000000000006e-05,
      "loss": 3.3704,
      "step": 113
    },
    {
      "epoch": 0.13,
      "learning_rate": 5.65e-05,
      "loss": 3.1891,
      "step": 114
    },
    {
      "epoch": 0.13,
      "learning_rate": 5.6999999999999996e-05,
      "loss": 3.3325,
      "step": 115
    },
    {
      "epoch": 0.13,
      "learning_rate": 5.7499999999999995e-05,
      "loss": 3.3737,
      "step": 116
    },
    {
      "epoch": 0.13,
      "learning_rate": 5.8e-05,
      "loss": 3.318,
      "step": 117
    },
    {
      "epoch": 0.13,
      "learning_rate": 5.85e-05,
      "loss": 3.3254,
      "step": 118
    },
    {
      "epoch": 0.13,
      "learning_rate": 5.9e-05,
      "loss": 3.415,
      "step": 119
    },
    {
      "epoch": 0.13,
      "learning_rate": 5.95e-05,
      "loss": 3.2399,
      "step": 120
    },
    {
      "epoch": 0.13,
      "learning_rate": 6e-05,
      "loss": 3.5728,
      "step": 121
    },
    {
      "epoch": 0.13,
      "learning_rate": 6.05e-05,
      "loss": 3.4162,
      "step": 122
    },
    {
      "epoch": 0.14,
      "learning_rate": 6.1e-05,
      "loss": 3.3026,
      "step": 123
    },
    {
      "epoch": 0.14,
      "learning_rate": 6.15e-05,
      "loss": 3.2586,
      "step": 124
    },
    {
      "epoch": 0.14,
      "learning_rate": 6.2e-05,
      "loss": 3.2891,
      "step": 125
    },
    {
      "epoch": 0.14,
      "learning_rate": 6.25e-05,
      "loss": 3.3074,
      "step": 126
    },
    {
      "epoch": 0.14,
      "learning_rate": 6.3e-05,
      "loss": 3.1975,
      "step": 127
    },
    {
      "epoch": 0.14,
      "learning_rate": 6.35e-05,
      "loss": 3.4335,
      "step": 128
    },
    {
      "epoch": 0.14,
      "learning_rate": 6.400000000000001e-05,
      "loss": 3.2166,
      "step": 129
    },
    {
      "epoch": 0.14,
      "learning_rate": 6.450000000000001e-05,
      "loss": 3.5692,
      "step": 130
    },
    {
      "epoch": 0.14,
      "learning_rate": 6.500000000000001e-05,
      "loss": 3.1113,
      "step": 131
    },
    {
      "epoch": 0.15,
      "learning_rate": 6.55e-05,
      "loss": 3.1528,
      "step": 132
    },
    {
      "epoch": 0.15,
      "learning_rate": 6.6e-05,
      "loss": 3.401,
      "step": 133
    },
    {
      "epoch": 0.15,
      "learning_rate": 6.65e-05,
      "loss": 3.0415,
      "step": 134
    },
    {
      "epoch": 0.15,
      "learning_rate": 6.7e-05,
      "loss": 3.2036,
      "step": 135
    },
    {
      "epoch": 0.15,
      "learning_rate": 6.750000000000001e-05,
      "loss": 3.1422,
      "step": 136
    },
    {
      "epoch": 0.15,
      "learning_rate": 6.800000000000001e-05,
      "loss": 3.0997,
      "step": 137
    },
    {
      "epoch": 0.15,
      "learning_rate": 6.850000000000001e-05,
      "loss": 3.3726,
      "step": 138
    },
    {
      "epoch": 0.15,
      "learning_rate": 6.9e-05,
      "loss": 3.1453,
      "step": 139
    },
    {
      "epoch": 0.15,
      "learning_rate": 6.95e-05,
      "loss": 3.2419,
      "step": 140
    },
    {
      "epoch": 0.16,
      "learning_rate": 7e-05,
      "loss": 3.1056,
      "step": 141
    },
    {
      "epoch": 0.16,
      "learning_rate": 7.05e-05,
      "loss": 3.3981,
      "step": 142
    },
    {
      "epoch": 0.16,
      "learning_rate": 7.1e-05,
      "loss": 3.2783,
      "step": 143
    },
    {
      "epoch": 0.16,
      "learning_rate": 7.15e-05,
      "loss": 3.1214,
      "step": 144
    },
    {
      "epoch": 0.16,
      "learning_rate": 7.2e-05,
      "loss": 3.2591,
      "step": 145
    },
    {
      "epoch": 0.16,
      "learning_rate": 7.25e-05,
      "loss": 3.3375,
      "step": 146
    },
    {
      "epoch": 0.16,
      "learning_rate": 7.3e-05,
      "loss": 3.1939,
      "step": 147
    },
    {
      "epoch": 0.16,
      "learning_rate": 7.35e-05,
      "loss": 3.3885,
      "step": 148
    },
    {
      "epoch": 0.16,
      "learning_rate": 7.4e-05,
      "loss": 3.1786,
      "step": 149
    },
    {
      "epoch": 0.17,
      "learning_rate": 7.450000000000001e-05,
      "loss": 3.2437,
      "step": 150
    },
    {
      "epoch": 0.17,
      "learning_rate": 7.500000000000001e-05,
      "loss": 3.1655,
      "step": 151
    },
    {
      "epoch": 0.17,
      "learning_rate": 7.55e-05,
      "loss": 3.2501,
      "step": 152
    },
    {
      "epoch": 0.17,
      "learning_rate": 7.6e-05,
      "loss": 3.1039,
      "step": 153
    },
    {
      "epoch": 0.17,
      "learning_rate": 7.65e-05,
      "loss": 3.0422,
      "step": 154
    },
    {
      "epoch": 0.17,
      "learning_rate": 7.7e-05,
      "loss": 3.2224,
      "step": 155
    },
    {
      "epoch": 0.17,
      "learning_rate": 7.75e-05,
      "loss": 3.3688,
      "step": 156
    },
    {
      "epoch": 0.17,
      "learning_rate": 7.800000000000001e-05,
      "loss": 3.18,
      "step": 157
    },
    {
      "epoch": 0.17,
      "learning_rate": 7.850000000000001e-05,
      "loss": 3.3193,
      "step": 158
    },
    {
      "epoch": 0.18,
      "learning_rate": 7.900000000000001e-05,
      "loss": 3.0143,
      "step": 159
    },
    {
      "epoch": 0.18,
      "learning_rate": 7.950000000000001e-05,
      "loss": 3.3041,
      "step": 160
    },
    {
      "epoch": 0.18,
      "learning_rate": 8e-05,
      "loss": 3.0795,
      "step": 161
    },
    {
      "epoch": 0.18,
      "learning_rate": 8.05e-05,
      "loss": 3.3209,
      "step": 162
    },
    {
      "epoch": 0.18,
      "learning_rate": 8.1e-05,
      "loss": 3.0228,
      "step": 163
    },
    {
      "epoch": 0.18,
      "learning_rate": 8.15e-05,
      "loss": 3.2272,
      "step": 164
    },
    {
      "epoch": 0.18,
      "learning_rate": 8.2e-05,
      "loss": 3.3444,
      "step": 165
    },
    {
      "epoch": 0.18,
      "learning_rate": 8.25e-05,
      "loss": 3.1973,
      "step": 166
    },
    {
      "epoch": 0.18,
      "learning_rate": 8.3e-05,
      "loss": 3.2665,
      "step": 167
    },
    {
      "epoch": 0.19,
      "learning_rate": 8.35e-05,
      "loss": 3.1086,
      "step": 168
    },
    {
      "epoch": 0.19,
      "learning_rate": 8.4e-05,
      "loss": 3.0447,
      "step": 169
    },
    {
      "epoch": 0.19,
      "learning_rate": 8.450000000000001e-05,
      "loss": 3.1282,
      "step": 170
    },
    {
      "epoch": 0.19,
      "learning_rate": 8.5e-05,
      "loss": 2.8976,
      "step": 171
    },
    {
      "epoch": 0.19,
      "learning_rate": 8.55e-05,
      "loss": 3.0891,
      "step": 172
    },
    {
      "epoch": 0.19,
      "learning_rate": 8.6e-05,
      "loss": 3.0724,
      "step": 173
    },
    {
      "epoch": 0.19,
      "learning_rate": 8.65e-05,
      "loss": 3.1737,
      "step": 174
    },
    {
      "epoch": 0.19,
      "learning_rate": 8.7e-05,
      "loss": 3.0374,
      "step": 175
    },
    {
      "epoch": 0.19,
      "learning_rate": 8.75e-05,
      "loss": 3.3311,
      "step": 176
    },
    {
      "epoch": 0.19,
      "learning_rate": 8.800000000000001e-05,
      "loss": 3.2377,
      "step": 177
    },
    {
      "epoch": 0.2,
      "learning_rate": 8.850000000000001e-05,
      "loss": 3.0481,
      "step": 178
    },
    {
      "epoch": 0.2,
      "learning_rate": 8.900000000000001e-05,
      "loss": 3.1262,
      "step": 179
    },
    {
      "epoch": 0.2,
      "learning_rate": 8.950000000000001e-05,
      "loss": 3.1508,
      "step": 180
    },
    {
      "epoch": 0.2,
      "learning_rate": 9e-05,
      "loss": 3.0747,
      "step": 181
    },
    {
      "epoch": 0.2,
      "learning_rate": 9.05e-05,
      "loss": 3.2756,
      "step": 182
    },
    {
      "epoch": 0.2,
      "learning_rate": 9.1e-05,
      "loss": 3.1552,
      "step": 183
    },
    {
      "epoch": 0.2,
      "learning_rate": 9.15e-05,
      "loss": 2.9463,
      "step": 184
    },
    {
      "epoch": 0.2,
      "learning_rate": 9.200000000000001e-05,
      "loss": 3.1245,
      "step": 185
    },
    {
      "epoch": 0.2,
      "learning_rate": 9.250000000000001e-05,
      "loss": 3.2724,
      "step": 186
    },
    {
      "epoch": 0.21,
      "learning_rate": 9.300000000000001e-05,
      "loss": 3.2059,
      "step": 187
    },
    {
      "epoch": 0.21,
      "learning_rate": 9.350000000000001e-05,
      "loss": 3.218,
      "step": 188
    },
    {
      "epoch": 0.21,
      "learning_rate": 9.4e-05,
      "loss": 3.2485,
      "step": 189
    },
    {
      "epoch": 0.21,
      "learning_rate": 9.449999999999999e-05,
      "loss": 3.1483,
      "step": 190
    },
    {
      "epoch": 0.21,
      "learning_rate": 9.5e-05,
      "loss": 3.3004,
      "step": 191
    },
    {
      "epoch": 0.21,
      "learning_rate": 9.55e-05,
      "loss": 3.2341,
      "step": 192
    },
    {
      "epoch": 0.21,
      "learning_rate": 9.6e-05,
      "loss": 3.3174,
      "step": 193
    },
    {
      "epoch": 0.21,
      "learning_rate": 9.65e-05,
      "loss": 3.1397,
      "step": 194
    },
    {
      "epoch": 0.21,
      "learning_rate": 9.7e-05,
      "loss": 3.2256,
      "step": 195
    },
    {
      "epoch": 0.22,
      "learning_rate": 9.75e-05,
      "loss": 3.3872,
      "step": 196
    },
    {
      "epoch": 0.22,
      "learning_rate": 9.8e-05,
      "loss": 3.2314,
      "step": 197
    },
    {
      "epoch": 0.22,
      "learning_rate": 9.850000000000001e-05,
      "loss": 3.3762,
      "step": 198
    },
    {
      "epoch": 0.22,
      "learning_rate": 9.900000000000001e-05,
      "loss": 3.2725,
      "step": 199
    },
    {
      "epoch": 0.22,
      "learning_rate": 9.95e-05,
      "loss": 3.3473,
      "step": 200
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.0001,
      "loss": 3.2964,
      "step": 201
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.00010049999999999999,
      "loss": 3.1219,
      "step": 202
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.000101,
      "loss": 3.2847,
      "step": 203
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.0001015,
      "loss": 3.1519,
      "step": 204
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.00010200000000000001,
      "loss": 3.2043,
      "step": 205
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0001025,
      "loss": 3.2448,
      "step": 206
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.00010300000000000001,
      "loss": 3.0668,
      "step": 207
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0001035,
      "loss": 3.1479,
      "step": 208
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.00010400000000000001,
      "loss": 3.2008,
      "step": 209
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.00010449999999999999,
      "loss": 3.1387,
      "step": 210
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.000105,
      "loss": 3.2166,
      "step": 211
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0001055,
      "loss": 3.2421,
      "step": 212
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.00010600000000000002,
      "loss": 3.2188,
      "step": 213
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.0001065,
      "loss": 3.2448,
      "step": 214
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.00010700000000000001,
      "loss": 3.058,
      "step": 215
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.0001075,
      "loss": 3.045,
      "step": 216
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.00010800000000000001,
      "loss": 3.3385,
      "step": 217
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.00010850000000000001,
      "loss": 3.1991,
      "step": 218
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.000109,
      "loss": 3.0373,
      "step": 219
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.0001095,
      "loss": 3.0968,
      "step": 220
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.00011000000000000002,
      "loss": 3.3251,
      "step": 221
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.0001105,
      "loss": 3.1758,
      "step": 222
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.00011100000000000001,
      "loss": 3.1894,
      "step": 223
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.0001115,
      "loss": 3.0857,
      "step": 224
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.00011200000000000001,
      "loss": 3.1642,
      "step": 225
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.00011250000000000001,
      "loss": 3.0968,
      "step": 226
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.000113,
      "loss": 2.9736,
      "step": 227
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.00011350000000000001,
      "loss": 3.2147,
      "step": 228
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.00011399999999999999,
      "loss": 3.318,
      "step": 229
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.0001145,
      "loss": 3.164,
      "step": 230
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.00011499999999999999,
      "loss": 3.1879,
      "step": 231
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0001155,
      "loss": 3.2429,
      "step": 232
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.000116,
      "loss": 3.0803,
      "step": 233
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.00011650000000000001,
      "loss": 3.1198,
      "step": 234
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.000117,
      "loss": 3.2091,
      "step": 235
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.00011750000000000001,
      "loss": 3.0865,
      "step": 236
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.000118,
      "loss": 3.0288,
      "step": 237
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.00011850000000000001,
      "loss": 2.9757,
      "step": 238
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.000119,
      "loss": 3.1894,
      "step": 239
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.00011950000000000002,
      "loss": 3.1389,
      "step": 240
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.00012,
      "loss": 3.2927,
      "step": 241
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.00012050000000000002,
      "loss": 3.1265,
      "step": 242
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.000121,
      "loss": 3.1089,
      "step": 243
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.00012150000000000001,
      "loss": 3.0466,
      "step": 244
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.000122,
      "loss": 3.3347,
      "step": 245
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.00012250000000000002,
      "loss": 3.1958,
      "step": 246
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.000123,
      "loss": 3.2048,
      "step": 247
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.00012350000000000002,
      "loss": 3.2344,
      "step": 248
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.000124,
      "loss": 3.2287,
      "step": 249
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.00012450000000000002,
      "loss": 3.3119,
      "step": 250
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.000125,
      "loss": 3.1462,
      "step": 251
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0001255,
      "loss": 3.4123,
      "step": 252
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.000126,
      "loss": 3.1005,
      "step": 253
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.00012649999999999998,
      "loss": 3.1302,
      "step": 254
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.000127,
      "loss": 3.2997,
      "step": 255
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0001275,
      "loss": 3.2441,
      "step": 256
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.00012800000000000002,
      "loss": 3.1116,
      "step": 257
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0001285,
      "loss": 3.042,
      "step": 258
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.00012900000000000002,
      "loss": 2.9881,
      "step": 259
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0001295,
      "loss": 3.2656,
      "step": 260
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.00013000000000000002,
      "loss": 3.1139,
      "step": 261
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0001305,
      "loss": 3.1703,
      "step": 262
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.000131,
      "loss": 3.3539,
      "step": 263
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0001315,
      "loss": 3.3371,
      "step": 264
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.000132,
      "loss": 3.0999,
      "step": 265
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0001325,
      "loss": 3.146,
      "step": 266
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.000133,
      "loss": 3.1696,
      "step": 267
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0001335,
      "loss": 3.3061,
      "step": 268
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.000134,
      "loss": 3.1222,
      "step": 269
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.00013450000000000002,
      "loss": 3.1574,
      "step": 270
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.00013500000000000003,
      "loss": 3.1956,
      "step": 271
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.00013550000000000001,
      "loss": 3.0591,
      "step": 272
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.00013600000000000003,
      "loss": 3.2514,
      "step": 273
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0001365,
      "loss": 3.3325,
      "step": 274
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.00013700000000000002,
      "loss": 3.5719,
      "step": 275
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0001375,
      "loss": 3.1753,
      "step": 276
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.000138,
      "loss": 3.126,
      "step": 277
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0001385,
      "loss": 3.0298,
      "step": 278
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.000139,
      "loss": 2.92,
      "step": 279
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0001395,
      "loss": 3.0644,
      "step": 280
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.00014,
      "loss": 3.1589,
      "step": 281
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0001405,
      "loss": 3.2118,
      "step": 282
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.000141,
      "loss": 3.135,
      "step": 283
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0001415,
      "loss": 3.1945,
      "step": 284
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.000142,
      "loss": 3.3117,
      "step": 285
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.00014250000000000002,
      "loss": 3.3859,
      "step": 286
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.000143,
      "loss": 3.1878,
      "step": 287
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.00014350000000000002,
      "loss": 3.2482,
      "step": 288
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.000144,
      "loss": 3.269,
      "step": 289
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.00014450000000000002,
      "loss": 3.191,
      "step": 290
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.000145,
      "loss": 3.0482,
      "step": 291
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0001455,
      "loss": 3.156,
      "step": 292
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.000146,
      "loss": 3.2083,
      "step": 293
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0001465,
      "loss": 3.0206,
      "step": 294
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.000147,
      "loss": 3.1008,
      "step": 295
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0001475,
      "loss": 3.1501,
      "step": 296
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.000148,
      "loss": 3.2987,
      "step": 297
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0001485,
      "loss": 3.2169,
      "step": 298
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.00014900000000000002,
      "loss": 2.8615,
      "step": 299
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.00014950000000000003,
      "loss": 3.1662,
      "step": 300
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.00014950000000000003,
      "loss": 3.2025,
      "step": 301
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.00015000000000000001,
      "loss": 2.98,
      "step": 302
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0001505,
      "loss": 3.0858,
      "step": 303
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.000151,
      "loss": 3.2243,
      "step": 304
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0001515,
      "loss": 3.3312,
      "step": 305
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.000152,
      "loss": 3.3387,
      "step": 306
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0001525,
      "loss": 3.1555,
      "step": 307
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.000153,
      "loss": 3.1382,
      "step": 308
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0001535,
      "loss": 3.0223,
      "step": 309
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.000154,
      "loss": 3.0775,
      "step": 310
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0001545,
      "loss": 3.1185,
      "step": 311
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.000155,
      "loss": 3.1943,
      "step": 312
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0001555,
      "loss": 3.0685,
      "step": 313
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.00015600000000000002,
      "loss": 3.2339,
      "step": 314
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0001565,
      "loss": 3.1234,
      "step": 315
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.00015700000000000002,
      "loss": 3.1988,
      "step": 316
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0001575,
      "loss": 3.0659,
      "step": 317
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.00015800000000000002,
      "loss": 3.1671,
      "step": 318
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0001585,
      "loss": 2.9668,
      "step": 319
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.00015900000000000002,
      "loss": 3.1925,
      "step": 320
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0001595,
      "loss": 3.1224,
      "step": 321
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.00016,
      "loss": 2.9899,
      "step": 322
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0001605,
      "loss": 3.1518,
      "step": 323
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.000161,
      "loss": 2.9331,
      "step": 324
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0001615,
      "loss": 2.9472,
      "step": 325
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.000162,
      "loss": 3.1517,
      "step": 326
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.00016250000000000002,
      "loss": 3.2345,
      "step": 327
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.000163,
      "loss": 3.2624,
      "step": 328
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.00016350000000000002,
      "loss": 3.055,
      "step": 329
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.000164,
      "loss": 3.2863,
      "step": 330
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.00016450000000000001,
      "loss": 2.948,
      "step": 331
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.000165,
      "loss": 3.1152,
      "step": 332
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0001655,
      "loss": 3.2037,
      "step": 333
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.000166,
      "loss": 3.2969,
      "step": 334
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0001665,
      "loss": 3.2525,
      "step": 335
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.000167,
      "loss": 3.3967,
      "step": 336
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0001675,
      "loss": 3.0961,
      "step": 337
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.000168,
      "loss": 3.2891,
      "step": 338
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0001685,
      "loss": 3.2225,
      "step": 339
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.00016900000000000002,
      "loss": 3.0833,
      "step": 340
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.00016950000000000003,
      "loss": 3.189,
      "step": 341
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.00017,
      "loss": 2.9255,
      "step": 342
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.00017050000000000002,
      "loss": 3.0358,
      "step": 343
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.000171,
      "loss": 3.0805,
      "step": 344
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.00017150000000000002,
      "loss": 3.0267,
      "step": 345
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.000172,
      "loss": 3.1641,
      "step": 346
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.00017250000000000002,
      "loss": 2.877,
      "step": 347
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.000173,
      "loss": 3.0657,
      "step": 348
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.00017350000000000002,
      "loss": 3.1227,
      "step": 349
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.000174,
      "loss": 2.9308,
      "step": 350
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0001745,
      "loss": 3.1013,
      "step": 351
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.000175,
      "loss": 3.1758,
      "step": 352
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0001755,
      "loss": 3.2208,
      "step": 353
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.00017600000000000002,
      "loss": 2.8883,
      "step": 354
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0001765,
      "loss": 3.0894,
      "step": 355
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.00017700000000000002,
      "loss": 3.2612,
      "step": 356
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0001775,
      "loss": 3.0926,
      "step": 357
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.00017800000000000002,
      "loss": 3.2505,
      "step": 358
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0001785,
      "loss": 3.1683,
      "step": 359
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.00017900000000000001,
      "loss": 3.1289,
      "step": 360
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0001795,
      "loss": 3.2693,
      "step": 361
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.00018,
      "loss": 2.8895,
      "step": 362
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0001805,
      "loss": 3.3443,
      "step": 363
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.000181,
      "loss": 3.1815,
      "step": 364
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0001815,
      "loss": 2.9466,
      "step": 365
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.000182,
      "loss": 2.9765,
      "step": 366
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0001825,
      "loss": 3.1332,
      "step": 367
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.000183,
      "loss": 3.1003,
      "step": 368
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.00018350000000000002,
      "loss": 3.1302,
      "step": 369
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.00018400000000000003,
      "loss": 3.2624,
      "step": 370
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0001845,
      "loss": 3.1461,
      "step": 371
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.00018500000000000002,
      "loss": 3.0751,
      "step": 372
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0001855,
      "loss": 3.2355,
      "step": 373
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.00018600000000000002,
      "loss": 3.2009,
      "step": 374
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0001865,
      "loss": 3.076,
      "step": 375
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.00018700000000000002,
      "loss": 3.1778,
      "step": 376
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0001875,
      "loss": 3.153,
      "step": 377
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.000188,
      "loss": 3.0317,
      "step": 378
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0001885,
      "loss": 2.9516,
      "step": 379
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.00018899999999999999,
      "loss": 3.3719,
      "step": 380
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0001895,
      "loss": 2.9289,
      "step": 381
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.00019,
      "loss": 3.0248,
      "step": 382
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.00019050000000000002,
      "loss": 3.3353,
      "step": 383
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.000191,
      "loss": 3.1736,
      "step": 384
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.00019150000000000002,
      "loss": 3.2677,
      "step": 385
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.000192,
      "loss": 3.0463,
      "step": 386
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.00019250000000000002,
      "loss": 3.1592,
      "step": 387
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.000193,
      "loss": 3.1369,
      "step": 388
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.00019350000000000001,
      "loss": 3.0891,
      "step": 389
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.000194,
      "loss": 3.2986,
      "step": 390
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0001945,
      "loss": 3.1368,
      "step": 391
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.000195,
      "loss": 3.2303,
      "step": 392
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0001955,
      "loss": 3.202,
      "step": 393
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.000196,
      "loss": 3.3576,
      "step": 394
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0001965,
      "loss": 3.2352,
      "step": 395
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.00019700000000000002,
      "loss": 3.0549,
      "step": 396
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.00019750000000000003,
      "loss": 3.344,
      "step": 397
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.00019800000000000002,
      "loss": 3.3654,
      "step": 398
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.00019850000000000003,
      "loss": 3.0266,
      "step": 399
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.000199,
      "loss": 3.0726,
      "step": 400
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.00019950000000000002,
      "loss": 3.2329,
      "step": 401
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0002,
      "loss": 3.3064,
      "step": 402
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.00019991666666666668,
      "loss": 3.2487,
      "step": 403
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.00019983333333333333,
      "loss": 3.1877,
      "step": 404
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.00019975,
      "loss": 3.1208,
      "step": 405
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.00019966666666666668,
      "loss": 3.2677,
      "step": 406
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.00019958333333333335,
      "loss": 3.2764,
      "step": 407
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.00019950000000000002,
      "loss": 3.1373,
      "step": 408
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.00019941666666666667,
      "loss": 3.3844,
      "step": 409
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.00019933333333333334,
      "loss": 2.8854,
      "step": 410
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.00019925,
      "loss": 3.2518,
      "step": 411
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.0001991666666666667,
      "loss": 3.1625,
      "step": 412
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.00019908333333333334,
      "loss": 3.1968,
      "step": 413
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.000199,
      "loss": 3.249,
      "step": 414
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.00019891666666666669,
      "loss": 3.1986,
      "step": 415
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.00019883333333333333,
      "loss": 2.8994,
      "step": 416
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.00019875,
      "loss": 2.9902,
      "step": 417
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.00019866666666666668,
      "loss": 3.056,
      "step": 418
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.00019858333333333335,
      "loss": 3.0654,
      "step": 419
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.00019850000000000003,
      "loss": 3.0973,
      "step": 420
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.00019841666666666667,
      "loss": 3.2271,
      "step": 421
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.00019833333333333335,
      "loss": 2.8813,
      "step": 422
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.00019825,
      "loss": 3.3083,
      "step": 423
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.00019816666666666667,
      "loss": 2.9093,
      "step": 424
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.00019808333333333334,
      "loss": 3.1347,
      "step": 425
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.00019800000000000002,
      "loss": 3.1135,
      "step": 426
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0001979166666666667,
      "loss": 3.1862,
      "step": 427
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.00019783333333333334,
      "loss": 3.112,
      "step": 428
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.00019775,
      "loss": 3.1532,
      "step": 429
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.00019766666666666666,
      "loss": 3.164,
      "step": 430
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.00019758333333333333,
      "loss": 3.3704,
      "step": 431
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.00019750000000000003,
      "loss": 3.1579,
      "step": 432
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.00019741666666666668,
      "loss": 3.2616,
      "step": 433
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.00019733333333333335,
      "loss": 2.8825,
      "step": 434
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.00019725,
      "loss": 2.9931,
      "step": 435
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.00019716666666666667,
      "loss": 3.1423,
      "step": 436
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.00019708333333333334,
      "loss": 3.1078,
      "step": 437
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.00019700000000000002,
      "loss": 3.2367,
      "step": 438
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0001969166666666667,
      "loss": 3.3632,
      "step": 439
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.00019683333333333334,
      "loss": 2.9918,
      "step": 440
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.00019675,
      "loss": 2.9814,
      "step": 441
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.00019666666666666666,
      "loss": 3.0347,
      "step": 442
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.00019658333333333333,
      "loss": 3.2375,
      "step": 443
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0001965,
      "loss": 3.0128,
      "step": 444
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.00019641666666666668,
      "loss": 2.9279,
      "step": 445
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.00019633333333333335,
      "loss": 3.2032,
      "step": 446
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.00019625,
      "loss": 3.1441,
      "step": 447
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.00019616666666666667,
      "loss": 3.1155,
      "step": 448
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.00019608333333333335,
      "loss": 3.2429,
      "step": 449
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.000196,
      "loss": 3.1095,
      "step": 450
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.0001959166666666667,
      "loss": 3.2229,
      "step": 451
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.00019583333333333334,
      "loss": 3.0008,
      "step": 452
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.00019575000000000001,
      "loss": 2.9273,
      "step": 453
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.0001956666666666667,
      "loss": 3.2133,
      "step": 454
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.00019558333333333333,
      "loss": 3.2556,
      "step": 455
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.0001955,
      "loss": 3.1096,
      "step": 456
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.00019541666666666668,
      "loss": 3.2994,
      "step": 457
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.00019533333333333336,
      "loss": 3.2379,
      "step": 458
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.00019525,
      "loss": 2.9204,
      "step": 459
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.00019516666666666668,
      "loss": 3.1473,
      "step": 460
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.00019508333333333335,
      "loss": 2.9051,
      "step": 461
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.000195,
      "loss": 3.0339,
      "step": 462
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.00019491666666666667,
      "loss": 3.1965,
      "step": 463
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.00019483333333333334,
      "loss": 3.028,
      "step": 464
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.00019475000000000002,
      "loss": 3.053,
      "step": 465
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0001946666666666667,
      "loss": 3.2151,
      "step": 466
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.00019458333333333334,
      "loss": 3.2955,
      "step": 467
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0001945,
      "loss": 3.2537,
      "step": 468
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.00019441666666666666,
      "loss": 3.0061,
      "step": 469
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.00019433333333333333,
      "loss": 3.0548,
      "step": 470
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.00019425,
      "loss": 3.2172,
      "step": 471
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.00019416666666666668,
      "loss": 3.1668,
      "step": 472
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.00019408333333333335,
      "loss": 3.0447,
      "step": 473
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.000194,
      "loss": 3.2887,
      "step": 474
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.00019391666666666667,
      "loss": 3.1029,
      "step": 475
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.00019383333333333335,
      "loss": 3.0803,
      "step": 476
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.00019375000000000002,
      "loss": 3.1904,
      "step": 477
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0001936666666666667,
      "loss": 3.0892,
      "step": 478
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.00019358333333333334,
      "loss": 3.2538,
      "step": 479
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.00019350000000000001,
      "loss": 3.0454,
      "step": 480
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.00019341666666666666,
      "loss": 3.0355,
      "step": 481
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.00019333333333333333,
      "loss": 3.287,
      "step": 482
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.00019325,
      "loss": 3.1825,
      "step": 483
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.00019316666666666668,
      "loss": 2.9524,
      "step": 484
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.00019308333333333336,
      "loss": 3.0549,
      "step": 485
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.000193,
      "loss": 3.1543,
      "step": 486
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.00019291666666666668,
      "loss": 3.1311,
      "step": 487
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.00019283333333333332,
      "loss": 3.2027,
      "step": 488
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.00019275,
      "loss": 3.0914,
      "step": 489
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0001926666666666667,
      "loss": 3.286,
      "step": 490
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.00019258333333333334,
      "loss": 3.4909,
      "step": 491
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.00019250000000000002,
      "loss": 3.1086,
      "step": 492
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.00019241666666666666,
      "loss": 2.9693,
      "step": 493
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.00019233333333333334,
      "loss": 3.1278,
      "step": 494
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.00019225,
      "loss": 2.9684,
      "step": 495
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.00019216666666666668,
      "loss": 3.1756,
      "step": 496
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.00019208333333333336,
      "loss": 3.1901,
      "step": 497
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.000192,
      "loss": 3.1362,
      "step": 498
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.00019191666666666668,
      "loss": 3.0186,
      "step": 499
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.00019183333333333333,
      "loss": 3.1948,
      "step": 500
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.00019175,
      "loss": 2.9911,
      "step": 501
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.00019166666666666667,
      "loss": 3.3073,
      "step": 502
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.00019158333333333335,
      "loss": 3.0707,
      "step": 503
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.00019150000000000002,
      "loss": 3.2033,
      "step": 504
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.00019141666666666667,
      "loss": 2.9172,
      "step": 505
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.00019133333333333334,
      "loss": 3.0061,
      "step": 506
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.00019125000000000001,
      "loss": 2.8103,
      "step": 507
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.00019116666666666666,
      "loss": 3.0941,
      "step": 508
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.00019108333333333333,
      "loss": 3.1632,
      "step": 509
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.000191,
      "loss": 3.1602,
      "step": 510
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.00019091666666666668,
      "loss": 3.1715,
      "step": 511
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.00019083333333333336,
      "loss": 3.1601,
      "step": 512
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.00019075,
      "loss": 3.3094,
      "step": 513
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.00019066666666666668,
      "loss": 3.0643,
      "step": 514
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.00019058333333333335,
      "loss": 3.242,
      "step": 515
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.00019050000000000002,
      "loss": 3.2405,
      "step": 516
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.00019041666666666667,
      "loss": 3.2657,
      "step": 517
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.00019033333333333334,
      "loss": 3.2502,
      "step": 518
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.00019025000000000002,
      "loss": 3.0628,
      "step": 519
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.00019016666666666666,
      "loss": 3.2714,
      "step": 520
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.00019008333333333334,
      "loss": 3.2683,
      "step": 521
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.00019,
      "loss": 2.8685,
      "step": 522
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.00018991666666666668,
      "loss": 3.3374,
      "step": 523
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.00018983333333333336,
      "loss": 3.1404,
      "step": 524
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.00018975,
      "loss": 2.9565,
      "step": 525
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.00018966666666666668,
      "loss": 3.3039,
      "step": 526
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.00018958333333333332,
      "loss": 3.0118,
      "step": 527
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0001895,
      "loss": 3.1713,
      "step": 528
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0001894166666666667,
      "loss": 3.2394,
      "step": 529
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.00018933333333333335,
      "loss": 3.4396,
      "step": 530
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.00018925000000000002,
      "loss": 3.0608,
      "step": 531
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.00018916666666666667,
      "loss": 3.1532,
      "step": 532
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.00018908333333333334,
      "loss": 3.0446,
      "step": 533
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.00018899999999999999,
      "loss": 3.0096,
      "step": 534
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0001889166666666667,
      "loss": 3.0937,
      "step": 535
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.00018883333333333336,
      "loss": 2.7893,
      "step": 536
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.00018875,
      "loss": 2.9423,
      "step": 537
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.00018866666666666668,
      "loss": 2.9897,
      "step": 538
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.00018858333333333333,
      "loss": 3.2154,
      "step": 539
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0001885,
      "loss": 3.3286,
      "step": 540
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.00018841666666666667,
      "loss": 3.2616,
      "step": 541
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.00018833333333333335,
      "loss": 2.8734,
      "step": 542
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.00018825000000000002,
      "loss": 3.0555,
      "step": 543
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.00018816666666666667,
      "loss": 3.0744,
      "step": 544
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.00018808333333333334,
      "loss": 3.1786,
      "step": 545
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.000188,
      "loss": 3.1658,
      "step": 546
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.00018791666666666666,
      "loss": 3.1072,
      "step": 547
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.00018783333333333336,
      "loss": 3.3071,
      "step": 548
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.00018775,
      "loss": 2.9953,
      "step": 549
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.00018766666666666668,
      "loss": 2.9944,
      "step": 550
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.00018758333333333333,
      "loss": 2.9885,
      "step": 551
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0001875,
      "loss": 3.1398,
      "step": 552
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.00018741666666666668,
      "loss": 3.2432,
      "step": 553
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.00018733333333333335,
      "loss": 2.898,
      "step": 554
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.00018725000000000002,
      "loss": 3.0153,
      "step": 555
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.00018716666666666667,
      "loss": 3.0847,
      "step": 556
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.00018708333333333335,
      "loss": 3.1915,
      "step": 557
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.00018700000000000002,
      "loss": 3.0973,
      "step": 558
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.00018691666666666667,
      "loss": 3.2881,
      "step": 559
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.00018683333333333334,
      "loss": 3.1489,
      "step": 560
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.00018675,
      "loss": 2.9541,
      "step": 561
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0001866666666666667,
      "loss": 3.17,
      "step": 562
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.00018658333333333333,
      "loss": 2.9544,
      "step": 563
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0001865,
      "loss": 3.1946,
      "step": 564
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.00018641666666666668,
      "loss": 3.1237,
      "step": 565
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.00018633333333333333,
      "loss": 2.9903,
      "step": 566
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.00018625,
      "loss": 3.2424,
      "step": 567
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.00018616666666666667,
      "loss": 3.2924,
      "step": 568
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.00018608333333333335,
      "loss": 3.2195,
      "step": 569
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.00018600000000000002,
      "loss": 2.9847,
      "step": 570
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.00018591666666666667,
      "loss": 3.1821,
      "step": 571
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.00018583333333333334,
      "loss": 3.1406,
      "step": 572
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.00018575,
      "loss": 3.1026,
      "step": 573
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0001856666666666667,
      "loss": 2.9785,
      "step": 574
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.00018558333333333334,
      "loss": 3.1906,
      "step": 575
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0001855,
      "loss": 2.9733,
      "step": 576
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.00018541666666666668,
      "loss": 3.1344,
      "step": 577
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.00018533333333333333,
      "loss": 3.0288,
      "step": 578
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.00018525,
      "loss": 2.866,
      "step": 579
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.00018516666666666668,
      "loss": 3.0403,
      "step": 580
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.00018508333333333335,
      "loss": 3.0926,
      "step": 581
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.00018500000000000002,
      "loss": 2.7793,
      "step": 582
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.00018491666666666667,
      "loss": 3.1829,
      "step": 583
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.00018483333333333334,
      "loss": 3.0862,
      "step": 584
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.00018475,
      "loss": 3.0297,
      "step": 585
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.00018466666666666666,
      "loss": 3.0663,
      "step": 586
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.00018458333333333337,
      "loss": 3.0284,
      "step": 587
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.0001845,
      "loss": 3.0813,
      "step": 588
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.00018441666666666669,
      "loss": 3.0581,
      "step": 589
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.00018433333333333333,
      "loss": 3.1747,
      "step": 590
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.00018425,
      "loss": 3.3473,
      "step": 591
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.00018416666666666665,
      "loss": 3.1362,
      "step": 592
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.00018408333333333335,
      "loss": 3.2398,
      "step": 593
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.00018400000000000003,
      "loss": 3.0792,
      "step": 594
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.00018391666666666667,
      "loss": 3.2092,
      "step": 595
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.00018383333333333335,
      "loss": 3.1521,
      "step": 596
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.00018375,
      "loss": 3.19,
      "step": 597
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.00018366666666666667,
      "loss": 3.0843,
      "step": 598
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.00018358333333333334,
      "loss": 3.2631,
      "step": 599
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.00018350000000000002,
      "loss": 3.4045,
      "step": 600
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0001834166666666667,
      "loss": 3.0856,
      "step": 601
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.00018333333333333334,
      "loss": 2.9735,
      "step": 602
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.00018325,
      "loss": 3.0062,
      "step": 603
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.00018316666666666668,
      "loss": 2.9515,
      "step": 604
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.00018308333333333333,
      "loss": 2.836,
      "step": 605
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.000183,
      "loss": 3.0887,
      "step": 606
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.00018291666666666668,
      "loss": 3.0756,
      "step": 607
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.00018283333333333335,
      "loss": 2.9091,
      "step": 608
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.00018275,
      "loss": 2.9762,
      "step": 609
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.00018266666666666667,
      "loss": 3.0895,
      "step": 610
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.00018258333333333334,
      "loss": 3.2134,
      "step": 611
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0001825,
      "loss": 2.77,
      "step": 612
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0001824166666666667,
      "loss": 3.0621,
      "step": 613
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.00018233333333333334,
      "loss": 3.1063,
      "step": 614
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.00018225,
      "loss": 3.0853,
      "step": 615
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.00018216666666666669,
      "loss": 3.1944,
      "step": 616
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.00018208333333333333,
      "loss": 2.9188,
      "step": 617
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.000182,
      "loss": 3.0811,
      "step": 618
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.00018191666666666668,
      "loss": 3.2267,
      "step": 619
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.00018183333333333335,
      "loss": 3.1752,
      "step": 620
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.00018175,
      "loss": 3.1577,
      "step": 621
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.00018166666666666667,
      "loss": 3.0698,
      "step": 622
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.00018158333333333335,
      "loss": 3.0914,
      "step": 623
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0001815,
      "loss": 2.9552,
      "step": 624
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.00018141666666666667,
      "loss": 3.1264,
      "step": 625
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.00018133333333333334,
      "loss": 3.0775,
      "step": 626
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.00018125000000000001,
      "loss": 3.1918,
      "step": 627
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0001811666666666667,
      "loss": 3.0475,
      "step": 628
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.00018108333333333333,
      "loss": 3.3861,
      "step": 629
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.000181,
      "loss": 3.0957,
      "step": 630
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.00018091666666666666,
      "loss": 3.0136,
      "step": 631
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.00018083333333333336,
      "loss": 3.0731,
      "step": 632
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.00018075000000000003,
      "loss": 3.0461,
      "step": 633
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.00018066666666666668,
      "loss": 3.1179,
      "step": 634
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.00018058333333333335,
      "loss": 3.3075,
      "step": 635
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0001805,
      "loss": 3.1076,
      "step": 636
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.00018041666666666667,
      "loss": 3.0993,
      "step": 637
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.00018033333333333334,
      "loss": 3.071,
      "step": 638
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.00018025000000000002,
      "loss": 2.9756,
      "step": 639
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0001801666666666667,
      "loss": 3.37,
      "step": 640
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.00018008333333333334,
      "loss": 3.2455,
      "step": 641
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.00018,
      "loss": 3.2893,
      "step": 642
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.00017991666666666666,
      "loss": 3.1021,
      "step": 643
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.00017983333333333333,
      "loss": 3.2015,
      "step": 644
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.00017975,
      "loss": 2.8772,
      "step": 645
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.00017966666666666668,
      "loss": 3.1684,
      "step": 646
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.00017958333333333335,
      "loss": 3.2191,
      "step": 647
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0001795,
      "loss": 3.1662,
      "step": 648
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.00017941666666666667,
      "loss": 3.1853,
      "step": 649
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.00017933333333333332,
      "loss": 2.9695,
      "step": 650
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.00017925000000000002,
      "loss": 3.3718,
      "step": 651
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0001791666666666667,
      "loss": 3.0911,
      "step": 652
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.00017908333333333334,
      "loss": 3.1409,
      "step": 653
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.00017900000000000001,
      "loss": 3.0816,
      "step": 654
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.00017891666666666666,
      "loss": 2.9976,
      "step": 655
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.00017883333333333333,
      "loss": 3.2605,
      "step": 656
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.00017875,
      "loss": 2.7676,
      "step": 657
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.00017866666666666668,
      "loss": 3.08,
      "step": 658
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.00017858333333333336,
      "loss": 3.2878,
      "step": 659
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.0001785,
      "loss": 2.9639,
      "step": 660
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.00017841666666666668,
      "loss": 2.7917,
      "step": 661
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.00017833333333333335,
      "loss": 3.0824,
      "step": 662
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.00017825,
      "loss": 2.8887,
      "step": 663
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.00017816666666666667,
      "loss": 3.0749,
      "step": 664
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.00017808333333333334,
      "loss": 2.9557,
      "step": 665
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.00017800000000000002,
      "loss": 3.1738,
      "step": 666
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.00017791666666666666,
      "loss": 3.1663,
      "step": 667
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.00017783333333333334,
      "loss": 3.1368,
      "step": 668
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.00017775,
      "loss": 2.7942,
      "step": 669
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.00017766666666666666,
      "loss": 2.8912,
      "step": 670
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.00017758333333333336,
      "loss": 3.2722,
      "step": 671
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0001775,
      "loss": 3.2528,
      "step": 672
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.00017741666666666668,
      "loss": 3.0499,
      "step": 673
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.00017733333333333335,
      "loss": 2.944,
      "step": 674
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.00017725,
      "loss": 3.1623,
      "step": 675
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.00017716666666666667,
      "loss": 3.071,
      "step": 676
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.00017708333333333335,
      "loss": 3.1783,
      "step": 677
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.00017700000000000002,
      "loss": 3.213,
      "step": 678
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0001769166666666667,
      "loss": 2.934,
      "step": 679
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.00017683333333333334,
      "loss": 3.1454,
      "step": 680
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.00017675000000000001,
      "loss": 3.0469,
      "step": 681
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.00017666666666666666,
      "loss": 3.0375,
      "step": 682
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.00017658333333333333,
      "loss": 3.0781,
      "step": 683
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0001765,
      "loss": 3.077,
      "step": 684
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.00017641666666666668,
      "loss": 3.2565,
      "step": 685
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.00017633333333333335,
      "loss": 3.51,
      "step": 686
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.00017625,
      "loss": 3.0282,
      "step": 687
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.00017616666666666668,
      "loss": 3.2056,
      "step": 688
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.00017608333333333332,
      "loss": 3.2414,
      "step": 689
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.00017600000000000002,
      "loss": 3.0809,
      "step": 690
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0001759166666666667,
      "loss": 3.1584,
      "step": 691
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.00017583333333333334,
      "loss": 3.17,
      "step": 692
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.00017575000000000002,
      "loss": 3.0493,
      "step": 693
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.00017566666666666666,
      "loss": 3.3097,
      "step": 694
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.00017558333333333334,
      "loss": 3.0682,
      "step": 695
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0001755,
      "loss": 3.1308,
      "step": 696
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.00017541666666666668,
      "loss": 3.1051,
      "step": 697
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.00017533333333333336,
      "loss": 2.984,
      "step": 698
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.00017525,
      "loss": 3.1246,
      "step": 699
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.00017516666666666668,
      "loss": 3.0903,
      "step": 700
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.00017508333333333332,
      "loss": 2.8254,
      "step": 701
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.000175,
      "loss": 3.1464,
      "step": 702
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.00017491666666666667,
      "loss": 3.0278,
      "step": 703
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.00017483333333333335,
      "loss": 3.2144,
      "step": 704
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.00017475000000000002,
      "loss": 3.0404,
      "step": 705
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.00017466666666666667,
      "loss": 3.3106,
      "step": 706
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.00017458333333333334,
      "loss": 2.9674,
      "step": 707
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.0001745,
      "loss": 3.0512,
      "step": 708
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.00017441666666666666,
      "loss": 3.2708,
      "step": 709
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.00017433333333333336,
      "loss": 3.123,
      "step": 710
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.00017425,
      "loss": 2.9646,
      "step": 711
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.00017416666666666668,
      "loss": 3.2467,
      "step": 712
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.00017408333333333333,
      "loss": 3.1956,
      "step": 713
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.000174,
      "loss": 3.1583,
      "step": 714
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.00017391666666666667,
      "loss": 3.2709,
      "step": 715
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.00017383333333333335,
      "loss": 3.0785,
      "step": 716
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.00017375000000000002,
      "loss": 3.0051,
      "step": 717
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.00017366666666666667,
      "loss": 3.2014,
      "step": 718
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.00017358333333333334,
      "loss": 3.3946,
      "step": 719
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.00017350000000000002,
      "loss": 2.9765,
      "step": 720
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.00017341666666666666,
      "loss": 3.107,
      "step": 721
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.00017333333333333334,
      "loss": 3.0102,
      "step": 722
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.00017325,
      "loss": 3.2201,
      "step": 723
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.00017316666666666668,
      "loss": 3.3516,
      "step": 724
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.00017308333333333333,
      "loss": 3.0058,
      "step": 725
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.000173,
      "loss": 3.2433,
      "step": 726
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.00017291666666666668,
      "loss": 2.9353,
      "step": 727
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.00017283333333333332,
      "loss": 3.0171,
      "step": 728
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.00017275000000000002,
      "loss": 3.1897,
      "step": 729
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.00017266666666666667,
      "loss": 3.1262,
      "step": 730
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.00017258333333333335,
      "loss": 2.9752,
      "step": 731
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.00017250000000000002,
      "loss": 3.1324,
      "step": 732
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.00017241666666666667,
      "loss": 3.1843,
      "step": 733
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.00017233333333333334,
      "loss": 3.041,
      "step": 734
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.00017225,
      "loss": 2.8194,
      "step": 735
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.00017216666666666669,
      "loss": 3.0767,
      "step": 736
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.00017208333333333336,
      "loss": 2.9889,
      "step": 737
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.000172,
      "loss": 3.117,
      "step": 738
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.00017191666666666668,
      "loss": 2.9015,
      "step": 739
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.00017183333333333333,
      "loss": 3.0339,
      "step": 740
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.00017175,
      "loss": 3.134,
      "step": 741
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.00017166666666666667,
      "loss": 3.3562,
      "step": 742
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.00017158333333333335,
      "loss": 3.2198,
      "step": 743
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.00017150000000000002,
      "loss": 3.1937,
      "step": 744
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.00017141666666666667,
      "loss": 2.8347,
      "step": 745
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.00017133333333333334,
      "loss": 3.2446,
      "step": 746
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.00017125,
      "loss": 2.9342,
      "step": 747
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.00017116666666666666,
      "loss": 3.2072,
      "step": 748
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.00017108333333333336,
      "loss": 3.1507,
      "step": 749
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.000171,
      "loss": 3.0762,
      "step": 750
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.00017091666666666668,
      "loss": 3.4243,
      "step": 751
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.00017083333333333333,
      "loss": 3.2407,
      "step": 752
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.00017075,
      "loss": 2.9459,
      "step": 753
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.00017066666666666668,
      "loss": 3.1771,
      "step": 754
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.00017058333333333335,
      "loss": 3.279,
      "step": 755
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.00017050000000000002,
      "loss": 3.0043,
      "step": 756
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.00017041666666666667,
      "loss": 3.0001,
      "step": 757
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.00017033333333333334,
      "loss": 3.0147,
      "step": 758
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.00017025,
      "loss": 3.2099,
      "step": 759
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.00017016666666666666,
      "loss": 3.0712,
      "step": 760
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.00017008333333333334,
      "loss": 3.179,
      "step": 761
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.00017,
      "loss": 3.1192,
      "step": 762
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.00016991666666666669,
      "loss": 2.8221,
      "step": 763
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.00016983333333333333,
      "loss": 2.9827,
      "step": 764
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.00016975,
      "loss": 2.9999,
      "step": 765
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.00016966666666666668,
      "loss": 3.0718,
      "step": 766
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.00016958333333333333,
      "loss": 3.028,
      "step": 767
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.00016950000000000003,
      "loss": 3.259,
      "step": 768
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.00016941666666666667,
      "loss": 3.2999,
      "step": 769
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.00016933333333333335,
      "loss": 3.2561,
      "step": 770
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.00016925,
      "loss": 3.117,
      "step": 771
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.00016916666666666667,
      "loss": 3.1121,
      "step": 772
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.00016908333333333334,
      "loss": 2.9997,
      "step": 773
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.00016900000000000002,
      "loss": 3.1673,
      "step": 774
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0001689166666666667,
      "loss": 3.1398,
      "step": 775
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.00016883333333333334,
      "loss": 3.303,
      "step": 776
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.00016875,
      "loss": 2.9653,
      "step": 777
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.00016866666666666668,
      "loss": 3.1465,
      "step": 778
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.00016858333333333333,
      "loss": 2.9532,
      "step": 779
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0001685,
      "loss": 3.0489,
      "step": 780
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.00016841666666666668,
      "loss": 2.9129,
      "step": 781
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.00016833333333333335,
      "loss": 3.2911,
      "step": 782
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.00016825000000000002,
      "loss": 3.1786,
      "step": 783
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.00016816666666666667,
      "loss": 3.0502,
      "step": 784
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.00016808333333333334,
      "loss": 2.91,
      "step": 785
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.000168,
      "loss": 2.9431,
      "step": 786
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.00016791666666666666,
      "loss": 3.1969,
      "step": 787
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.00016783333333333334,
      "loss": 3.2769,
      "step": 788
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.00016775,
      "loss": 2.954,
      "step": 789
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.00016766666666666669,
      "loss": 3.038,
      "step": 790
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.00016758333333333333,
      "loss": 3.2509,
      "step": 791
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0001675,
      "loss": 3.2601,
      "step": 792
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.00016741666666666668,
      "loss": 3.0271,
      "step": 793
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.00016733333333333335,
      "loss": 3.2821,
      "step": 794
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.00016725000000000003,
      "loss": 3.2047,
      "step": 795
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.00016716666666666667,
      "loss": 2.9806,
      "step": 796
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.00016708333333333335,
      "loss": 3.1595,
      "step": 797
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.000167,
      "loss": 2.9857,
      "step": 798
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.00016691666666666667,
      "loss": 3.033,
      "step": 799
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.00016683333333333334,
      "loss": 3.1198,
      "step": 800
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.00016675000000000001,
      "loss": 3.0547,
      "step": 801
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0001666666666666667,
      "loss": 3.218,
      "step": 802
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.00016658333333333333,
      "loss": 3.0681,
      "step": 803
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0001665,
      "loss": 3.0178,
      "step": 804
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.00016641666666666666,
      "loss": 3.1464,
      "step": 805
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.00016633333333333333,
      "loss": 3.0447,
      "step": 806
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.00016625000000000003,
      "loss": 2.9751,
      "step": 807
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.00016616666666666668,
      "loss": 2.8381,
      "step": 808
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.00016608333333333335,
      "loss": 3.043,
      "step": 809
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.000166,
      "loss": 2.9557,
      "step": 810
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.00016591666666666667,
      "loss": 3.1101,
      "step": 811
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.00016583333333333334,
      "loss": 3.0524,
      "step": 812
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.00016575000000000002,
      "loss": 3.3245,
      "step": 813
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0001656666666666667,
      "loss": 3.1102,
      "step": 814
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.00016558333333333334,
      "loss": 3.1234,
      "step": 815
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0001655,
      "loss": 3.142,
      "step": 816
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.00016541666666666666,
      "loss": 3.173,
      "step": 817
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.00016533333333333333,
      "loss": 3.2885,
      "step": 818
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.00016525,
      "loss": 2.853,
      "step": 819
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.00016516666666666668,
      "loss": 2.9527,
      "step": 820
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.00016508333333333335,
      "loss": 3.1656,
      "step": 821
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.000165,
      "loss": 2.8028,
      "step": 822
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.00016491666666666667,
      "loss": 3.0192,
      "step": 823
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.00016483333333333335,
      "loss": 3.0643,
      "step": 824
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.00016475,
      "loss": 3.0939,
      "step": 825
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.00016466666666666667,
      "loss": 3.1546,
      "step": 826
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.00016458333333333334,
      "loss": 3.1513,
      "step": 827
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.00016450000000000001,
      "loss": 2.9462,
      "step": 828
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0001644166666666667,
      "loss": 2.9651,
      "step": 829
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.00016433333333333333,
      "loss": 3.0419,
      "step": 830
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.00016425,
      "loss": 3.2793,
      "step": 831
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.00016416666666666668,
      "loss": 3.24,
      "step": 832
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.00016408333333333336,
      "loss": 3.2364,
      "step": 833
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.000164,
      "loss": 3.2408,
      "step": 834
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.00016391666666666668,
      "loss": 3.1081,
      "step": 835
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.00016383333333333335,
      "loss": 3.049,
      "step": 836
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.00016375,
      "loss": 3.2833,
      "step": 837
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.00016366666666666667,
      "loss": 2.8748,
      "step": 838
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.00016358333333333334,
      "loss": 3.1935,
      "step": 839
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.00016350000000000002,
      "loss": 3.0226,
      "step": 840
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0001634166666666667,
      "loss": 3.1653,
      "step": 841
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.00016333333333333334,
      "loss": 3.1843,
      "step": 842
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.00016325,
      "loss": 3.0936,
      "step": 843
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.00016316666666666666,
      "loss": 3.0324,
      "step": 844
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.00016308333333333333,
      "loss": 3.0598,
      "step": 845
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.000163,
      "loss": 3.1954,
      "step": 846
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.00016291666666666668,
      "loss": 3.2221,
      "step": 847
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.00016283333333333335,
      "loss": 2.7321,
      "step": 848
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.00016275,
      "loss": 3.1297,
      "step": 849
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.00016266666666666667,
      "loss": 3.084,
      "step": 850
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.00016258333333333332,
      "loss": 3.1002,
      "step": 851
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.00016250000000000002,
      "loss": 2.964,
      "step": 852
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.0001624166666666667,
      "loss": 3.2304,
      "step": 853
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.00016233333333333334,
      "loss": 3.1177,
      "step": 854
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.00016225000000000001,
      "loss": 3.2084,
      "step": 855
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.00016216666666666666,
      "loss": 3.2923,
      "step": 856
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.00016208333333333333,
      "loss": 3.3188,
      "step": 857
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.000162,
      "loss": 3.1847,
      "step": 858
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.00016191666666666668,
      "loss": 3.0957,
      "step": 859
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.00016183333333333335,
      "loss": 3.1799,
      "step": 860
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.00016175,
      "loss": 3.1355,
      "step": 861
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.00016166666666666668,
      "loss": 3.0327,
      "step": 862
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.00016158333333333332,
      "loss": 3.0817,
      "step": 863
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0001615,
      "loss": 3.187,
      "step": 864
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0001614166666666667,
      "loss": 3.1528,
      "step": 865
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.00016133333333333334,
      "loss": 3.1807,
      "step": 866
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.00016125000000000002,
      "loss": 3.2117,
      "step": 867
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.00016116666666666666,
      "loss": 3.2394,
      "step": 868
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.00016108333333333334,
      "loss": 3.2018,
      "step": 869
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.000161,
      "loss": 3.0546,
      "step": 870
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.00016091666666666668,
      "loss": 3.2054,
      "step": 871
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.00016083333333333336,
      "loss": 2.8787,
      "step": 872
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.00016075,
      "loss": 2.9268,
      "step": 873
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.00016066666666666668,
      "loss": 3.1894,
      "step": 874
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.00016058333333333332,
      "loss": 3.0069,
      "step": 875
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0001605,
      "loss": 2.9428,
      "step": 876
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.00016041666666666667,
      "loss": 2.9963,
      "step": 877
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.00016033333333333335,
      "loss": 2.9805,
      "step": 878
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.00016025000000000002,
      "loss": 2.9801,
      "step": 879
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.00016016666666666667,
      "loss": 3.1744,
      "step": 880
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.00016008333333333334,
      "loss": 3.1727,
      "step": 881
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.00016,
      "loss": 3.1068,
      "step": 882
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.00015991666666666666,
      "loss": 3.4132,
      "step": 883
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.00015983333333333333,
      "loss": 2.9537,
      "step": 884
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.00015975,
      "loss": 2.8851,
      "step": 885
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.00015966666666666668,
      "loss": 3.0875,
      "step": 886
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.00015958333333333335,
      "loss": 3.0364,
      "step": 887
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0001595,
      "loss": 2.8979,
      "step": 888
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.00015941666666666667,
      "loss": 3.2708,
      "step": 889
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.00015933333333333332,
      "loss": 3.0162,
      "step": 890
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.00015925000000000002,
      "loss": 3.1936,
      "step": 891
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.00015916666666666667,
      "loss": 2.9045,
      "step": 892
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.00015908333333333334,
      "loss": 3.2236,
      "step": 893
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.00015900000000000002,
      "loss": 3.0213,
      "step": 894
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.00015891666666666666,
      "loss": 3.0852,
      "step": 895
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.00015883333333333334,
      "loss": 3.1309,
      "step": 896
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.00015875,
      "loss": 3.0177,
      "step": 897
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.00015866666666666668,
      "loss": 3.2321,
      "step": 898
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.00015858333333333336,
      "loss": 3.0633,
      "step": 899
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0001585,
      "loss": 3.1816,
      "step": 900
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.00015841666666666668,
      "loss": 3.05,
      "step": 901
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.00015833333333333332,
      "loss": 3.2604,
      "step": 902
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.00015825,
      "loss": 3.1324,
      "step": 903
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0001581666666666667,
      "loss": 3.1295,
      "step": 904
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.00015808333333333335,
      "loss": 3.1505,
      "step": 905
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.00015800000000000002,
      "loss": 3.0379,
      "step": 906
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.00015791666666666667,
      "loss": 3.0305,
      "step": 907
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.00015783333333333334,
      "loss": 2.9666,
      "step": 908
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.00015774999999999999,
      "loss": 2.9175,
      "step": 909
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.00015766666666666669,
      "loss": 3.1114,
      "step": 910
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.00015758333333333336,
      "loss": 3.0755,
      "step": 911
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0001575,
      "loss": 3.1389,
      "step": 912
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.00015741666666666668,
      "loss": 2.9317,
      "step": 913
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.00015733333333333333,
      "loss": 3.0604,
      "step": 914
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.00015725,
      "loss": 3.1112,
      "step": 915
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.00015716666666666667,
      "loss": 3.0011,
      "step": 916
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.00015708333333333335,
      "loss": 3.1321,
      "step": 917
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.00015700000000000002,
      "loss": 3.0238,
      "step": 918
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.00015691666666666667,
      "loss": 3.1891,
      "step": 919
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.00015683333333333334,
      "loss": 3.1789,
      "step": 920
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.00015675,
      "loss": 3.2048,
      "step": 921
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.00015666666666666666,
      "loss": 3.0504,
      "step": 922
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.00015658333333333334,
      "loss": 3.1231,
      "step": 923
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.0001565,
      "loss": 3.1946,
      "step": 924
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.00015641666666666668,
      "loss": 2.9838,
      "step": 925
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.00015633333333333333,
      "loss": 3.16,
      "step": 926
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.00015625,
      "loss": 2.9799,
      "step": 927
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.00015616666666666668,
      "loss": 3.0879,
      "step": 928
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.00015608333333333332,
      "loss": 3.0368,
      "step": 929
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.00015600000000000002,
      "loss": 3.1113,
      "step": 930
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.00015591666666666667,
      "loss": 3.0955,
      "step": 931
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.00015583333333333334,
      "loss": 3.0213,
      "step": 932
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.00015575000000000002,
      "loss": 3.0065,
      "step": 933
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.00015566666666666666,
      "loss": 3.1897,
      "step": 934
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.00015558333333333334,
      "loss": 3.022,
      "step": 935
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.0001555,
      "loss": 3.1574,
      "step": 936
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.00015541666666666669,
      "loss": 3.1303,
      "step": 937
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.00015533333333333333,
      "loss": 3.1515,
      "step": 938
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.00015525,
      "loss": 2.9005,
      "step": 939
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.00015516666666666668,
      "loss": 2.9382,
      "step": 940
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.00015508333333333333,
      "loss": 3.2671,
      "step": 941
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.000155,
      "loss": 3.1655,
      "step": 942
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.00015491666666666667,
      "loss": 3.1089,
      "step": 943
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.00015483333333333335,
      "loss": 2.8937,
      "step": 944
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.00015475000000000002,
      "loss": 3.3066,
      "step": 945
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.00015466666666666667,
      "loss": 3.2124,
      "step": 946
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.00015458333333333334,
      "loss": 2.8976,
      "step": 947
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.0001545,
      "loss": 3.0317,
      "step": 948
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0001544166666666667,
      "loss": 3.0843,
      "step": 949
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.00015433333333333334,
      "loss": 3.1298,
      "step": 950
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.00015425,
      "loss": 3.1258,
      "step": 951
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.00015416666666666668,
      "loss": 3.0418,
      "step": 952
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.00015408333333333333,
      "loss": 3.048,
      "step": 953
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.000154,
      "loss": 3.1631,
      "step": 954
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.00015391666666666668,
      "loss": 3.1227,
      "step": 955
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.00015383333333333335,
      "loss": 3.135,
      "step": 956
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.00015375000000000002,
      "loss": 2.9361,
      "step": 957
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.00015366666666666667,
      "loss": 3.145,
      "step": 958
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.00015358333333333334,
      "loss": 3.0285,
      "step": 959
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0001535,
      "loss": 3.1257,
      "step": 960
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.00015341666666666666,
      "loss": 2.9906,
      "step": 961
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.00015333333333333334,
      "loss": 2.9526,
      "step": 962
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.00015325,
      "loss": 2.9873,
      "step": 963
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.00015316666666666669,
      "loss": 3.1429,
      "step": 964
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.00015308333333333333,
      "loss": 3.1624,
      "step": 965
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.000153,
      "loss": 3.118,
      "step": 966
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.00015291666666666665,
      "loss": 2.8361,
      "step": 967
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.00015283333333333335,
      "loss": 3.1575,
      "step": 968
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.00015275000000000003,
      "loss": 2.9728,
      "step": 969
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.00015266666666666667,
      "loss": 3.1647,
      "step": 970
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.00015258333333333335,
      "loss": 3.1999,
      "step": 971
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0001525,
      "loss": 3.1317,
      "step": 972
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.00015241666666666667,
      "loss": 3.265,
      "step": 973
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.00015233333333333334,
      "loss": 3.1305,
      "step": 974
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.00015225000000000001,
      "loss": 3.1706,
      "step": 975
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0001521666666666667,
      "loss": 3.1613,
      "step": 976
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.00015208333333333333,
      "loss": 3.2374,
      "step": 977
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.000152,
      "loss": 3.1312,
      "step": 978
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.00015191666666666668,
      "loss": 3.2455,
      "step": 979
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.00015183333333333333,
      "loss": 3.0979,
      "step": 980
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.00015175,
      "loss": 3.1895,
      "step": 981
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.00015166666666666668,
      "loss": 2.972,
      "step": 982
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.00015158333333333335,
      "loss": 3.2832,
      "step": 983
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0001515,
      "loss": 3.0895,
      "step": 984
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.00015141666666666667,
      "loss": 3.116,
      "step": 985
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.00015133333333333334,
      "loss": 3.0764,
      "step": 986
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.00015125,
      "loss": 3.0453,
      "step": 987
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0001511666666666667,
      "loss": 3.3089,
      "step": 988
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.00015108333333333334,
      "loss": 3.0693,
      "step": 989
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.000151,
      "loss": 3.0882,
      "step": 990
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.00015091666666666668,
      "loss": 2.957,
      "step": 991
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.00015083333333333333,
      "loss": 3.0583,
      "step": 992
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.00015075,
      "loss": 3.1149,
      "step": 993
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.00015066666666666668,
      "loss": 3.1932,
      "step": 994
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.00015058333333333335,
      "loss": 3.1433,
      "step": 995
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0001505,
      "loss": 3.159,
      "step": 996
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.00015041666666666667,
      "loss": 3.1527,
      "step": 997
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.00015033333333333335,
      "loss": 3.039,
      "step": 998
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.00015025,
      "loss": 3.2745,
      "step": 999
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.00015016666666666667,
      "loss": 3.2554,
      "step": 1000
    }
  ],
  "logging_steps": 1,
  "max_steps": 2800,
  "num_train_epochs": 4,
  "save_steps": 500,
  "total_flos": 4.041719667228672e+16,
  "trial_name": null,
  "trial_params": null
}
