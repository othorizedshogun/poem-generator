{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.753303964757709,
  "eval_steps": 500,
  "global_step": 2500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0,
      "learning_rate": 5.000000000000001e-07,
      "loss": 3.4837,
      "step": 1
    },
    {
      "epoch": 0.0,
      "learning_rate": 1.0000000000000002e-06,
      "loss": 3.421,
      "step": 2
    },
    {
      "epoch": 0.0,
      "learning_rate": 1.5e-06,
      "loss": 3.4057,
      "step": 3
    },
    {
      "epoch": 0.0,
      "learning_rate": 2.0000000000000003e-06,
      "loss": 3.4035,
      "step": 4
    },
    {
      "epoch": 0.01,
      "learning_rate": 2.5e-06,
      "loss": 3.2612,
      "step": 5
    },
    {
      "epoch": 0.01,
      "learning_rate": 3e-06,
      "loss": 3.4662,
      "step": 6
    },
    {
      "epoch": 0.01,
      "learning_rate": 3.5000000000000004e-06,
      "loss": 3.4528,
      "step": 7
    },
    {
      "epoch": 0.01,
      "learning_rate": 4.000000000000001e-06,
      "loss": 3.2216,
      "step": 8
    },
    {
      "epoch": 0.01,
      "learning_rate": 4.5e-06,
      "loss": 3.5331,
      "step": 9
    },
    {
      "epoch": 0.01,
      "learning_rate": 5e-06,
      "loss": 3.4739,
      "step": 10
    },
    {
      "epoch": 0.01,
      "learning_rate": 5.500000000000001e-06,
      "loss": 3.8404,
      "step": 11
    },
    {
      "epoch": 0.01,
      "learning_rate": 6e-06,
      "loss": 3.8214,
      "step": 12
    },
    {
      "epoch": 0.01,
      "learning_rate": 6.5000000000000004e-06,
      "loss": 3.5681,
      "step": 13
    },
    {
      "epoch": 0.02,
      "learning_rate": 7.000000000000001e-06,
      "loss": 3.4257,
      "step": 14
    },
    {
      "epoch": 0.02,
      "learning_rate": 7.5e-06,
      "loss": 3.4143,
      "step": 15
    },
    {
      "epoch": 0.02,
      "learning_rate": 8.000000000000001e-06,
      "loss": 3.4768,
      "step": 16
    },
    {
      "epoch": 0.02,
      "learning_rate": 8.500000000000002e-06,
      "loss": 3.5127,
      "step": 17
    },
    {
      "epoch": 0.02,
      "learning_rate": 9e-06,
      "loss": 3.2998,
      "step": 18
    },
    {
      "epoch": 0.02,
      "learning_rate": 9.5e-06,
      "loss": 3.2866,
      "step": 19
    },
    {
      "epoch": 0.02,
      "learning_rate": 1e-05,
      "loss": 3.4027,
      "step": 20
    },
    {
      "epoch": 0.02,
      "learning_rate": 1.05e-05,
      "loss": 3.4313,
      "step": 21
    },
    {
      "epoch": 0.02,
      "learning_rate": 1.1000000000000001e-05,
      "loss": 3.1273,
      "step": 22
    },
    {
      "epoch": 0.03,
      "learning_rate": 1.1500000000000002e-05,
      "loss": 3.0616,
      "step": 23
    },
    {
      "epoch": 0.03,
      "learning_rate": 1.2e-05,
      "loss": 3.4465,
      "step": 24
    },
    {
      "epoch": 0.03,
      "learning_rate": 1.25e-05,
      "loss": 3.1692,
      "step": 25
    },
    {
      "epoch": 0.03,
      "learning_rate": 1.3000000000000001e-05,
      "loss": 3.2481,
      "step": 26
    },
    {
      "epoch": 0.03,
      "learning_rate": 1.3500000000000001e-05,
      "loss": 3.4275,
      "step": 27
    },
    {
      "epoch": 0.03,
      "learning_rate": 1.4000000000000001e-05,
      "loss": 3.3356,
      "step": 28
    },
    {
      "epoch": 0.03,
      "learning_rate": 1.45e-05,
      "loss": 3.5024,
      "step": 29
    },
    {
      "epoch": 0.03,
      "learning_rate": 1.5e-05,
      "loss": 3.3726,
      "step": 30
    },
    {
      "epoch": 0.03,
      "learning_rate": 1.55e-05,
      "loss": 3.4327,
      "step": 31
    },
    {
      "epoch": 0.04,
      "learning_rate": 1.6000000000000003e-05,
      "loss": 3.4416,
      "step": 32
    },
    {
      "epoch": 0.04,
      "learning_rate": 1.65e-05,
      "loss": 3.5425,
      "step": 33
    },
    {
      "epoch": 0.04,
      "learning_rate": 1.7000000000000003e-05,
      "loss": 3.217,
      "step": 34
    },
    {
      "epoch": 0.04,
      "learning_rate": 1.75e-05,
      "loss": 3.283,
      "step": 35
    },
    {
      "epoch": 0.04,
      "learning_rate": 1.8e-05,
      "loss": 3.483,
      "step": 36
    },
    {
      "epoch": 0.04,
      "learning_rate": 1.85e-05,
      "loss": 3.555,
      "step": 37
    },
    {
      "epoch": 0.04,
      "learning_rate": 1.9e-05,
      "loss": 3.407,
      "step": 38
    },
    {
      "epoch": 0.04,
      "learning_rate": 1.9500000000000003e-05,
      "loss": 3.2687,
      "step": 39
    },
    {
      "epoch": 0.04,
      "learning_rate": 2e-05,
      "loss": 3.5258,
      "step": 40
    },
    {
      "epoch": 0.05,
      "learning_rate": 2.05e-05,
      "loss": 3.3584,
      "step": 41
    },
    {
      "epoch": 0.05,
      "learning_rate": 2.1e-05,
      "loss": 3.3977,
      "step": 42
    },
    {
      "epoch": 0.05,
      "learning_rate": 2.15e-05,
      "loss": 3.5133,
      "step": 43
    },
    {
      "epoch": 0.05,
      "learning_rate": 2.2000000000000003e-05,
      "loss": 3.4043,
      "step": 44
    },
    {
      "epoch": 0.05,
      "learning_rate": 2.25e-05,
      "loss": 3.2414,
      "step": 45
    },
    {
      "epoch": 0.05,
      "learning_rate": 2.3000000000000003e-05,
      "loss": 3.3189,
      "step": 46
    },
    {
      "epoch": 0.05,
      "learning_rate": 2.35e-05,
      "loss": 3.339,
      "step": 47
    },
    {
      "epoch": 0.05,
      "learning_rate": 2.4e-05,
      "loss": 3.356,
      "step": 48
    },
    {
      "epoch": 0.05,
      "learning_rate": 2.45e-05,
      "loss": 3.3845,
      "step": 49
    },
    {
      "epoch": 0.06,
      "learning_rate": 2.5e-05,
      "loss": 3.4047,
      "step": 50
    },
    {
      "epoch": 0.06,
      "learning_rate": 2.5500000000000003e-05,
      "loss": 3.4075,
      "step": 51
    },
    {
      "epoch": 0.06,
      "learning_rate": 2.6000000000000002e-05,
      "loss": 3.1971,
      "step": 52
    },
    {
      "epoch": 0.06,
      "learning_rate": 2.6500000000000004e-05,
      "loss": 3.2538,
      "step": 53
    },
    {
      "epoch": 0.06,
      "learning_rate": 2.7000000000000002e-05,
      "loss": 3.5962,
      "step": 54
    },
    {
      "epoch": 0.06,
      "learning_rate": 2.7500000000000004e-05,
      "loss": 3.4584,
      "step": 55
    },
    {
      "epoch": 0.06,
      "learning_rate": 2.8000000000000003e-05,
      "loss": 3.461,
      "step": 56
    },
    {
      "epoch": 0.06,
      "learning_rate": 2.8499999999999998e-05,
      "loss": 3.4684,
      "step": 57
    },
    {
      "epoch": 0.06,
      "learning_rate": 2.9e-05,
      "loss": 3.4149,
      "step": 58
    },
    {
      "epoch": 0.06,
      "learning_rate": 2.95e-05,
      "loss": 3.4266,
      "step": 59
    },
    {
      "epoch": 0.07,
      "learning_rate": 3e-05,
      "loss": 3.5096,
      "step": 60
    },
    {
      "epoch": 0.07,
      "learning_rate": 3.05e-05,
      "loss": 3.4488,
      "step": 61
    },
    {
      "epoch": 0.07,
      "learning_rate": 3.1e-05,
      "loss": 3.3184,
      "step": 62
    },
    {
      "epoch": 0.07,
      "learning_rate": 3.15e-05,
      "loss": 3.2574,
      "step": 63
    },
    {
      "epoch": 0.07,
      "learning_rate": 3.2000000000000005e-05,
      "loss": 3.19,
      "step": 64
    },
    {
      "epoch": 0.07,
      "learning_rate": 3.2500000000000004e-05,
      "loss": 3.3165,
      "step": 65
    },
    {
      "epoch": 0.07,
      "learning_rate": 3.3e-05,
      "loss": 3.1784,
      "step": 66
    },
    {
      "epoch": 0.07,
      "learning_rate": 3.35e-05,
      "loss": 3.3827,
      "step": 67
    },
    {
      "epoch": 0.07,
      "learning_rate": 3.4000000000000007e-05,
      "loss": 3.1006,
      "step": 68
    },
    {
      "epoch": 0.08,
      "learning_rate": 3.45e-05,
      "loss": 3.3479,
      "step": 69
    },
    {
      "epoch": 0.08,
      "learning_rate": 3.5e-05,
      "loss": 3.5415,
      "step": 70
    },
    {
      "epoch": 0.08,
      "learning_rate": 3.55e-05,
      "loss": 3.3923,
      "step": 71
    },
    {
      "epoch": 0.08,
      "learning_rate": 3.6e-05,
      "loss": 3.2877,
      "step": 72
    },
    {
      "epoch": 0.08,
      "learning_rate": 3.65e-05,
      "loss": 3.3294,
      "step": 73
    },
    {
      "epoch": 0.08,
      "learning_rate": 3.7e-05,
      "loss": 3.2899,
      "step": 74
    },
    {
      "epoch": 0.08,
      "learning_rate": 3.7500000000000003e-05,
      "loss": 3.4446,
      "step": 75
    },
    {
      "epoch": 0.08,
      "learning_rate": 3.8e-05,
      "loss": 3.1973,
      "step": 76
    },
    {
      "epoch": 0.08,
      "learning_rate": 3.85e-05,
      "loss": 3.2875,
      "step": 77
    },
    {
      "epoch": 0.09,
      "learning_rate": 3.9000000000000006e-05,
      "loss": 3.4138,
      "step": 78
    },
    {
      "epoch": 0.09,
      "learning_rate": 3.9500000000000005e-05,
      "loss": 3.0923,
      "step": 79
    },
    {
      "epoch": 0.09,
      "learning_rate": 4e-05,
      "loss": 3.2303,
      "step": 80
    },
    {
      "epoch": 0.09,
      "learning_rate": 4.05e-05,
      "loss": 3.2053,
      "step": 81
    },
    {
      "epoch": 0.09,
      "learning_rate": 4.1e-05,
      "loss": 3.1835,
      "step": 82
    },
    {
      "epoch": 0.09,
      "learning_rate": 4.15e-05,
      "loss": 3.3369,
      "step": 83
    },
    {
      "epoch": 0.09,
      "learning_rate": 4.2e-05,
      "loss": 3.3185,
      "step": 84
    },
    {
      "epoch": 0.09,
      "learning_rate": 4.25e-05,
      "loss": 3.3051,
      "step": 85
    },
    {
      "epoch": 0.09,
      "learning_rate": 4.3e-05,
      "loss": 3.3068,
      "step": 86
    },
    {
      "epoch": 0.1,
      "learning_rate": 4.35e-05,
      "loss": 3.216,
      "step": 87
    },
    {
      "epoch": 0.1,
      "learning_rate": 4.4000000000000006e-05,
      "loss": 3.3608,
      "step": 88
    },
    {
      "epoch": 0.1,
      "learning_rate": 4.4500000000000004e-05,
      "loss": 3.2391,
      "step": 89
    },
    {
      "epoch": 0.1,
      "learning_rate": 4.5e-05,
      "loss": 3.2755,
      "step": 90
    },
    {
      "epoch": 0.1,
      "learning_rate": 4.55e-05,
      "loss": 3.0971,
      "step": 91
    },
    {
      "epoch": 0.1,
      "learning_rate": 4.600000000000001e-05,
      "loss": 3.2637,
      "step": 92
    },
    {
      "epoch": 0.1,
      "learning_rate": 4.6500000000000005e-05,
      "loss": 3.3819,
      "step": 93
    },
    {
      "epoch": 0.1,
      "learning_rate": 4.7e-05,
      "loss": 3.4177,
      "step": 94
    },
    {
      "epoch": 0.1,
      "learning_rate": 4.75e-05,
      "loss": 3.3461,
      "step": 95
    },
    {
      "epoch": 0.11,
      "learning_rate": 4.8e-05,
      "loss": 3.3624,
      "step": 96
    },
    {
      "epoch": 0.11,
      "learning_rate": 4.85e-05,
      "loss": 3.3241,
      "step": 97
    },
    {
      "epoch": 0.11,
      "learning_rate": 4.9e-05,
      "loss": 3.463,
      "step": 98
    },
    {
      "epoch": 0.11,
      "learning_rate": 4.9500000000000004e-05,
      "loss": 3.197,
      "step": 99
    },
    {
      "epoch": 0.11,
      "learning_rate": 5e-05,
      "loss": 3.3392,
      "step": 100
    },
    {
      "epoch": 0.11,
      "learning_rate": 5.05e-05,
      "loss": 3.2443,
      "step": 101
    },
    {
      "epoch": 0.11,
      "learning_rate": 5.1000000000000006e-05,
      "loss": 3.4178,
      "step": 102
    },
    {
      "epoch": 0.11,
      "learning_rate": 5.1500000000000005e-05,
      "loss": 3.389,
      "step": 103
    },
    {
      "epoch": 0.11,
      "learning_rate": 5.2000000000000004e-05,
      "loss": 3.2211,
      "step": 104
    },
    {
      "epoch": 0.12,
      "learning_rate": 5.25e-05,
      "loss": 3.3312,
      "step": 105
    },
    {
      "epoch": 0.12,
      "learning_rate": 5.25e-05,
      "loss": 3.4114,
      "step": 106
    },
    {
      "epoch": 0.12,
      "learning_rate": 5.300000000000001e-05,
      "loss": 3.2385,
      "step": 107
    },
    {
      "epoch": 0.12,
      "learning_rate": 5.3500000000000006e-05,
      "loss": 3.2976,
      "step": 108
    },
    {
      "epoch": 0.12,
      "learning_rate": 5.4000000000000005e-05,
      "loss": 3.1615,
      "step": 109
    },
    {
      "epoch": 0.12,
      "learning_rate": 5.45e-05,
      "loss": 3.4048,
      "step": 110
    },
    {
      "epoch": 0.12,
      "learning_rate": 5.500000000000001e-05,
      "loss": 3.4051,
      "step": 111
    },
    {
      "epoch": 0.12,
      "learning_rate": 5.550000000000001e-05,
      "loss": 3.2261,
      "step": 112
    },
    {
      "epoch": 0.12,
      "learning_rate": 5.6000000000000006e-05,
      "loss": 3.3704,
      "step": 113
    },
    {
      "epoch": 0.13,
      "learning_rate": 5.65e-05,
      "loss": 3.1891,
      "step": 114
    },
    {
      "epoch": 0.13,
      "learning_rate": 5.6999999999999996e-05,
      "loss": 3.3325,
      "step": 115
    },
    {
      "epoch": 0.13,
      "learning_rate": 5.7499999999999995e-05,
      "loss": 3.3737,
      "step": 116
    },
    {
      "epoch": 0.13,
      "learning_rate": 5.8e-05,
      "loss": 3.318,
      "step": 117
    },
    {
      "epoch": 0.13,
      "learning_rate": 5.85e-05,
      "loss": 3.3254,
      "step": 118
    },
    {
      "epoch": 0.13,
      "learning_rate": 5.9e-05,
      "loss": 3.415,
      "step": 119
    },
    {
      "epoch": 0.13,
      "learning_rate": 5.95e-05,
      "loss": 3.2399,
      "step": 120
    },
    {
      "epoch": 0.13,
      "learning_rate": 6e-05,
      "loss": 3.5728,
      "step": 121
    },
    {
      "epoch": 0.13,
      "learning_rate": 6.05e-05,
      "loss": 3.4162,
      "step": 122
    },
    {
      "epoch": 0.14,
      "learning_rate": 6.1e-05,
      "loss": 3.3026,
      "step": 123
    },
    {
      "epoch": 0.14,
      "learning_rate": 6.15e-05,
      "loss": 3.2586,
      "step": 124
    },
    {
      "epoch": 0.14,
      "learning_rate": 6.2e-05,
      "loss": 3.2891,
      "step": 125
    },
    {
      "epoch": 0.14,
      "learning_rate": 6.25e-05,
      "loss": 3.3074,
      "step": 126
    },
    {
      "epoch": 0.14,
      "learning_rate": 6.3e-05,
      "loss": 3.1975,
      "step": 127
    },
    {
      "epoch": 0.14,
      "learning_rate": 6.35e-05,
      "loss": 3.4335,
      "step": 128
    },
    {
      "epoch": 0.14,
      "learning_rate": 6.400000000000001e-05,
      "loss": 3.2166,
      "step": 129
    },
    {
      "epoch": 0.14,
      "learning_rate": 6.450000000000001e-05,
      "loss": 3.5692,
      "step": 130
    },
    {
      "epoch": 0.14,
      "learning_rate": 6.500000000000001e-05,
      "loss": 3.1113,
      "step": 131
    },
    {
      "epoch": 0.15,
      "learning_rate": 6.55e-05,
      "loss": 3.1528,
      "step": 132
    },
    {
      "epoch": 0.15,
      "learning_rate": 6.6e-05,
      "loss": 3.401,
      "step": 133
    },
    {
      "epoch": 0.15,
      "learning_rate": 6.65e-05,
      "loss": 3.0415,
      "step": 134
    },
    {
      "epoch": 0.15,
      "learning_rate": 6.7e-05,
      "loss": 3.2036,
      "step": 135
    },
    {
      "epoch": 0.15,
      "learning_rate": 6.750000000000001e-05,
      "loss": 3.1422,
      "step": 136
    },
    {
      "epoch": 0.15,
      "learning_rate": 6.800000000000001e-05,
      "loss": 3.0997,
      "step": 137
    },
    {
      "epoch": 0.15,
      "learning_rate": 6.850000000000001e-05,
      "loss": 3.3726,
      "step": 138
    },
    {
      "epoch": 0.15,
      "learning_rate": 6.9e-05,
      "loss": 3.1453,
      "step": 139
    },
    {
      "epoch": 0.15,
      "learning_rate": 6.95e-05,
      "loss": 3.2419,
      "step": 140
    },
    {
      "epoch": 0.16,
      "learning_rate": 7e-05,
      "loss": 3.1056,
      "step": 141
    },
    {
      "epoch": 0.16,
      "learning_rate": 7.05e-05,
      "loss": 3.3981,
      "step": 142
    },
    {
      "epoch": 0.16,
      "learning_rate": 7.1e-05,
      "loss": 3.2783,
      "step": 143
    },
    {
      "epoch": 0.16,
      "learning_rate": 7.15e-05,
      "loss": 3.1214,
      "step": 144
    },
    {
      "epoch": 0.16,
      "learning_rate": 7.2e-05,
      "loss": 3.2591,
      "step": 145
    },
    {
      "epoch": 0.16,
      "learning_rate": 7.25e-05,
      "loss": 3.3375,
      "step": 146
    },
    {
      "epoch": 0.16,
      "learning_rate": 7.3e-05,
      "loss": 3.1939,
      "step": 147
    },
    {
      "epoch": 0.16,
      "learning_rate": 7.35e-05,
      "loss": 3.3885,
      "step": 148
    },
    {
      "epoch": 0.16,
      "learning_rate": 7.4e-05,
      "loss": 3.1786,
      "step": 149
    },
    {
      "epoch": 0.17,
      "learning_rate": 7.450000000000001e-05,
      "loss": 3.2437,
      "step": 150
    },
    {
      "epoch": 0.17,
      "learning_rate": 7.500000000000001e-05,
      "loss": 3.1655,
      "step": 151
    },
    {
      "epoch": 0.17,
      "learning_rate": 7.55e-05,
      "loss": 3.2501,
      "step": 152
    },
    {
      "epoch": 0.17,
      "learning_rate": 7.6e-05,
      "loss": 3.1039,
      "step": 153
    },
    {
      "epoch": 0.17,
      "learning_rate": 7.65e-05,
      "loss": 3.0422,
      "step": 154
    },
    {
      "epoch": 0.17,
      "learning_rate": 7.7e-05,
      "loss": 3.2224,
      "step": 155
    },
    {
      "epoch": 0.17,
      "learning_rate": 7.75e-05,
      "loss": 3.3688,
      "step": 156
    },
    {
      "epoch": 0.17,
      "learning_rate": 7.800000000000001e-05,
      "loss": 3.18,
      "step": 157
    },
    {
      "epoch": 0.17,
      "learning_rate": 7.850000000000001e-05,
      "loss": 3.3193,
      "step": 158
    },
    {
      "epoch": 0.18,
      "learning_rate": 7.900000000000001e-05,
      "loss": 3.0143,
      "step": 159
    },
    {
      "epoch": 0.18,
      "learning_rate": 7.950000000000001e-05,
      "loss": 3.3041,
      "step": 160
    },
    {
      "epoch": 0.18,
      "learning_rate": 8e-05,
      "loss": 3.0795,
      "step": 161
    },
    {
      "epoch": 0.18,
      "learning_rate": 8.05e-05,
      "loss": 3.3209,
      "step": 162
    },
    {
      "epoch": 0.18,
      "learning_rate": 8.1e-05,
      "loss": 3.0228,
      "step": 163
    },
    {
      "epoch": 0.18,
      "learning_rate": 8.15e-05,
      "loss": 3.2272,
      "step": 164
    },
    {
      "epoch": 0.18,
      "learning_rate": 8.2e-05,
      "loss": 3.3444,
      "step": 165
    },
    {
      "epoch": 0.18,
      "learning_rate": 8.25e-05,
      "loss": 3.1973,
      "step": 166
    },
    {
      "epoch": 0.18,
      "learning_rate": 8.3e-05,
      "loss": 3.2665,
      "step": 167
    },
    {
      "epoch": 0.19,
      "learning_rate": 8.35e-05,
      "loss": 3.1086,
      "step": 168
    },
    {
      "epoch": 0.19,
      "learning_rate": 8.4e-05,
      "loss": 3.0447,
      "step": 169
    },
    {
      "epoch": 0.19,
      "learning_rate": 8.450000000000001e-05,
      "loss": 3.1282,
      "step": 170
    },
    {
      "epoch": 0.19,
      "learning_rate": 8.5e-05,
      "loss": 2.8976,
      "step": 171
    },
    {
      "epoch": 0.19,
      "learning_rate": 8.55e-05,
      "loss": 3.0891,
      "step": 172
    },
    {
      "epoch": 0.19,
      "learning_rate": 8.6e-05,
      "loss": 3.0724,
      "step": 173
    },
    {
      "epoch": 0.19,
      "learning_rate": 8.65e-05,
      "loss": 3.1737,
      "step": 174
    },
    {
      "epoch": 0.19,
      "learning_rate": 8.7e-05,
      "loss": 3.0374,
      "step": 175
    },
    {
      "epoch": 0.19,
      "learning_rate": 8.75e-05,
      "loss": 3.3311,
      "step": 176
    },
    {
      "epoch": 0.19,
      "learning_rate": 8.800000000000001e-05,
      "loss": 3.2377,
      "step": 177
    },
    {
      "epoch": 0.2,
      "learning_rate": 8.850000000000001e-05,
      "loss": 3.0481,
      "step": 178
    },
    {
      "epoch": 0.2,
      "learning_rate": 8.900000000000001e-05,
      "loss": 3.1262,
      "step": 179
    },
    {
      "epoch": 0.2,
      "learning_rate": 8.950000000000001e-05,
      "loss": 3.1508,
      "step": 180
    },
    {
      "epoch": 0.2,
      "learning_rate": 9e-05,
      "loss": 3.0747,
      "step": 181
    },
    {
      "epoch": 0.2,
      "learning_rate": 9.05e-05,
      "loss": 3.2756,
      "step": 182
    },
    {
      "epoch": 0.2,
      "learning_rate": 9.1e-05,
      "loss": 3.1552,
      "step": 183
    },
    {
      "epoch": 0.2,
      "learning_rate": 9.15e-05,
      "loss": 2.9463,
      "step": 184
    },
    {
      "epoch": 0.2,
      "learning_rate": 9.200000000000001e-05,
      "loss": 3.1245,
      "step": 185
    },
    {
      "epoch": 0.2,
      "learning_rate": 9.250000000000001e-05,
      "loss": 3.2724,
      "step": 186
    },
    {
      "epoch": 0.21,
      "learning_rate": 9.300000000000001e-05,
      "loss": 3.2059,
      "step": 187
    },
    {
      "epoch": 0.21,
      "learning_rate": 9.350000000000001e-05,
      "loss": 3.218,
      "step": 188
    },
    {
      "epoch": 0.21,
      "learning_rate": 9.4e-05,
      "loss": 3.2485,
      "step": 189
    },
    {
      "epoch": 0.21,
      "learning_rate": 9.449999999999999e-05,
      "loss": 3.1483,
      "step": 190
    },
    {
      "epoch": 0.21,
      "learning_rate": 9.5e-05,
      "loss": 3.3004,
      "step": 191
    },
    {
      "epoch": 0.21,
      "learning_rate": 9.55e-05,
      "loss": 3.2341,
      "step": 192
    },
    {
      "epoch": 0.21,
      "learning_rate": 9.6e-05,
      "loss": 3.3174,
      "step": 193
    },
    {
      "epoch": 0.21,
      "learning_rate": 9.65e-05,
      "loss": 3.1397,
      "step": 194
    },
    {
      "epoch": 0.21,
      "learning_rate": 9.7e-05,
      "loss": 3.2256,
      "step": 195
    },
    {
      "epoch": 0.22,
      "learning_rate": 9.75e-05,
      "loss": 3.3872,
      "step": 196
    },
    {
      "epoch": 0.22,
      "learning_rate": 9.8e-05,
      "loss": 3.2314,
      "step": 197
    },
    {
      "epoch": 0.22,
      "learning_rate": 9.850000000000001e-05,
      "loss": 3.3762,
      "step": 198
    },
    {
      "epoch": 0.22,
      "learning_rate": 9.900000000000001e-05,
      "loss": 3.2725,
      "step": 199
    },
    {
      "epoch": 0.22,
      "learning_rate": 9.95e-05,
      "loss": 3.3473,
      "step": 200
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.0001,
      "loss": 3.2964,
      "step": 201
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.00010049999999999999,
      "loss": 3.1219,
      "step": 202
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.000101,
      "loss": 3.2847,
      "step": 203
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.0001015,
      "loss": 3.1519,
      "step": 204
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.00010200000000000001,
      "loss": 3.2043,
      "step": 205
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0001025,
      "loss": 3.2448,
      "step": 206
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.00010300000000000001,
      "loss": 3.0668,
      "step": 207
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0001035,
      "loss": 3.1479,
      "step": 208
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.00010400000000000001,
      "loss": 3.2008,
      "step": 209
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.00010449999999999999,
      "loss": 3.1387,
      "step": 210
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.000105,
      "loss": 3.2166,
      "step": 211
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0001055,
      "loss": 3.2421,
      "step": 212
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.00010600000000000002,
      "loss": 3.2188,
      "step": 213
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.0001065,
      "loss": 3.2448,
      "step": 214
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.00010700000000000001,
      "loss": 3.058,
      "step": 215
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.0001075,
      "loss": 3.045,
      "step": 216
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.00010800000000000001,
      "loss": 3.3385,
      "step": 217
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.00010850000000000001,
      "loss": 3.1991,
      "step": 218
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.000109,
      "loss": 3.0373,
      "step": 219
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.0001095,
      "loss": 3.0968,
      "step": 220
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.00011000000000000002,
      "loss": 3.3251,
      "step": 221
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.0001105,
      "loss": 3.1758,
      "step": 222
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.00011100000000000001,
      "loss": 3.1894,
      "step": 223
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.0001115,
      "loss": 3.0857,
      "step": 224
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.00011200000000000001,
      "loss": 3.1642,
      "step": 225
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.00011250000000000001,
      "loss": 3.0968,
      "step": 226
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.000113,
      "loss": 2.9736,
      "step": 227
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.00011350000000000001,
      "loss": 3.2147,
      "step": 228
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.00011399999999999999,
      "loss": 3.318,
      "step": 229
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.0001145,
      "loss": 3.164,
      "step": 230
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.00011499999999999999,
      "loss": 3.1879,
      "step": 231
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0001155,
      "loss": 3.2429,
      "step": 232
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.000116,
      "loss": 3.0803,
      "step": 233
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.00011650000000000001,
      "loss": 3.1198,
      "step": 234
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.000117,
      "loss": 3.2091,
      "step": 235
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.00011750000000000001,
      "loss": 3.0865,
      "step": 236
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.000118,
      "loss": 3.0288,
      "step": 237
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.00011850000000000001,
      "loss": 2.9757,
      "step": 238
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.000119,
      "loss": 3.1894,
      "step": 239
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.00011950000000000002,
      "loss": 3.1389,
      "step": 240
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.00012,
      "loss": 3.2927,
      "step": 241
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.00012050000000000002,
      "loss": 3.1265,
      "step": 242
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.000121,
      "loss": 3.1089,
      "step": 243
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.00012150000000000001,
      "loss": 3.0466,
      "step": 244
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.000122,
      "loss": 3.3347,
      "step": 245
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.00012250000000000002,
      "loss": 3.1958,
      "step": 246
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.000123,
      "loss": 3.2048,
      "step": 247
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.00012350000000000002,
      "loss": 3.2344,
      "step": 248
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.000124,
      "loss": 3.2287,
      "step": 249
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.00012450000000000002,
      "loss": 3.3119,
      "step": 250
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.000125,
      "loss": 3.1462,
      "step": 251
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0001255,
      "loss": 3.4123,
      "step": 252
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.000126,
      "loss": 3.1005,
      "step": 253
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.00012649999999999998,
      "loss": 3.1302,
      "step": 254
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.000127,
      "loss": 3.2997,
      "step": 255
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0001275,
      "loss": 3.2441,
      "step": 256
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.00012800000000000002,
      "loss": 3.1116,
      "step": 257
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0001285,
      "loss": 3.042,
      "step": 258
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.00012900000000000002,
      "loss": 2.9881,
      "step": 259
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0001295,
      "loss": 3.2656,
      "step": 260
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.00013000000000000002,
      "loss": 3.1139,
      "step": 261
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0001305,
      "loss": 3.1703,
      "step": 262
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.000131,
      "loss": 3.3539,
      "step": 263
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0001315,
      "loss": 3.3371,
      "step": 264
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.000132,
      "loss": 3.0999,
      "step": 265
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0001325,
      "loss": 3.146,
      "step": 266
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.000133,
      "loss": 3.1696,
      "step": 267
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0001335,
      "loss": 3.3061,
      "step": 268
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.000134,
      "loss": 3.1222,
      "step": 269
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.00013450000000000002,
      "loss": 3.1574,
      "step": 270
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.00013500000000000003,
      "loss": 3.1956,
      "step": 271
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.00013550000000000001,
      "loss": 3.0591,
      "step": 272
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.00013600000000000003,
      "loss": 3.2514,
      "step": 273
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0001365,
      "loss": 3.3325,
      "step": 274
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.00013700000000000002,
      "loss": 3.5719,
      "step": 275
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0001375,
      "loss": 3.1753,
      "step": 276
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.000138,
      "loss": 3.126,
      "step": 277
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0001385,
      "loss": 3.0298,
      "step": 278
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.000139,
      "loss": 2.92,
      "step": 279
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0001395,
      "loss": 3.0644,
      "step": 280
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.00014,
      "loss": 3.1589,
      "step": 281
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0001405,
      "loss": 3.2118,
      "step": 282
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.000141,
      "loss": 3.135,
      "step": 283
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0001415,
      "loss": 3.1945,
      "step": 284
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.000142,
      "loss": 3.3117,
      "step": 285
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.00014250000000000002,
      "loss": 3.3859,
      "step": 286
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.000143,
      "loss": 3.1878,
      "step": 287
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.00014350000000000002,
      "loss": 3.2482,
      "step": 288
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.000144,
      "loss": 3.269,
      "step": 289
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.00014450000000000002,
      "loss": 3.191,
      "step": 290
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.000145,
      "loss": 3.0482,
      "step": 291
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0001455,
      "loss": 3.156,
      "step": 292
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.000146,
      "loss": 3.2083,
      "step": 293
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0001465,
      "loss": 3.0206,
      "step": 294
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.000147,
      "loss": 3.1008,
      "step": 295
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0001475,
      "loss": 3.1501,
      "step": 296
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.000148,
      "loss": 3.2987,
      "step": 297
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0001485,
      "loss": 3.2169,
      "step": 298
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.00014900000000000002,
      "loss": 2.8615,
      "step": 299
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.00014950000000000003,
      "loss": 3.1662,
      "step": 300
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.00014950000000000003,
      "loss": 3.2025,
      "step": 301
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.00015000000000000001,
      "loss": 2.98,
      "step": 302
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0001505,
      "loss": 3.0858,
      "step": 303
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.000151,
      "loss": 3.2243,
      "step": 304
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0001515,
      "loss": 3.3312,
      "step": 305
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.000152,
      "loss": 3.3387,
      "step": 306
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0001525,
      "loss": 3.1555,
      "step": 307
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.000153,
      "loss": 3.1382,
      "step": 308
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0001535,
      "loss": 3.0223,
      "step": 309
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.000154,
      "loss": 3.0775,
      "step": 310
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0001545,
      "loss": 3.1185,
      "step": 311
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.000155,
      "loss": 3.1943,
      "step": 312
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0001555,
      "loss": 3.0685,
      "step": 313
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.00015600000000000002,
      "loss": 3.2339,
      "step": 314
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0001565,
      "loss": 3.1234,
      "step": 315
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.00015700000000000002,
      "loss": 3.1988,
      "step": 316
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0001575,
      "loss": 3.0659,
      "step": 317
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.00015800000000000002,
      "loss": 3.1671,
      "step": 318
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0001585,
      "loss": 2.9668,
      "step": 319
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.00015900000000000002,
      "loss": 3.1925,
      "step": 320
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0001595,
      "loss": 3.1224,
      "step": 321
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.00016,
      "loss": 2.9899,
      "step": 322
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0001605,
      "loss": 3.1518,
      "step": 323
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.000161,
      "loss": 2.9331,
      "step": 324
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0001615,
      "loss": 2.9472,
      "step": 325
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.000162,
      "loss": 3.1517,
      "step": 326
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.00016250000000000002,
      "loss": 3.2345,
      "step": 327
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.000163,
      "loss": 3.2624,
      "step": 328
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.00016350000000000002,
      "loss": 3.055,
      "step": 329
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.000164,
      "loss": 3.2863,
      "step": 330
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.00016450000000000001,
      "loss": 2.948,
      "step": 331
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.000165,
      "loss": 3.1152,
      "step": 332
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0001655,
      "loss": 3.2037,
      "step": 333
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.000166,
      "loss": 3.2969,
      "step": 334
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0001665,
      "loss": 3.2525,
      "step": 335
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.000167,
      "loss": 3.3967,
      "step": 336
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0001675,
      "loss": 3.0961,
      "step": 337
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.000168,
      "loss": 3.2891,
      "step": 338
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0001685,
      "loss": 3.2225,
      "step": 339
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.00016900000000000002,
      "loss": 3.0833,
      "step": 340
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.00016950000000000003,
      "loss": 3.189,
      "step": 341
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.00017,
      "loss": 2.9255,
      "step": 342
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.00017050000000000002,
      "loss": 3.0358,
      "step": 343
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.000171,
      "loss": 3.0805,
      "step": 344
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.00017150000000000002,
      "loss": 3.0267,
      "step": 345
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.000172,
      "loss": 3.1641,
      "step": 346
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.00017250000000000002,
      "loss": 2.877,
      "step": 347
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.000173,
      "loss": 3.0657,
      "step": 348
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.00017350000000000002,
      "loss": 3.1227,
      "step": 349
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.000174,
      "loss": 2.9308,
      "step": 350
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0001745,
      "loss": 3.1013,
      "step": 351
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.000175,
      "loss": 3.1758,
      "step": 352
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0001755,
      "loss": 3.2208,
      "step": 353
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.00017600000000000002,
      "loss": 2.8883,
      "step": 354
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0001765,
      "loss": 3.0894,
      "step": 355
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.00017700000000000002,
      "loss": 3.2612,
      "step": 356
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0001775,
      "loss": 3.0926,
      "step": 357
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.00017800000000000002,
      "loss": 3.2505,
      "step": 358
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0001785,
      "loss": 3.1683,
      "step": 359
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.00017900000000000001,
      "loss": 3.1289,
      "step": 360
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0001795,
      "loss": 3.2693,
      "step": 361
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.00018,
      "loss": 2.8895,
      "step": 362
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0001805,
      "loss": 3.3443,
      "step": 363
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.000181,
      "loss": 3.1815,
      "step": 364
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0001815,
      "loss": 2.9466,
      "step": 365
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.000182,
      "loss": 2.9765,
      "step": 366
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0001825,
      "loss": 3.1332,
      "step": 367
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.000183,
      "loss": 3.1003,
      "step": 368
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.00018350000000000002,
      "loss": 3.1302,
      "step": 369
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.00018400000000000003,
      "loss": 3.2624,
      "step": 370
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0001845,
      "loss": 3.1461,
      "step": 371
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.00018500000000000002,
      "loss": 3.0751,
      "step": 372
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0001855,
      "loss": 3.2355,
      "step": 373
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.00018600000000000002,
      "loss": 3.2009,
      "step": 374
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0001865,
      "loss": 3.076,
      "step": 375
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.00018700000000000002,
      "loss": 3.1778,
      "step": 376
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0001875,
      "loss": 3.153,
      "step": 377
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.000188,
      "loss": 3.0317,
      "step": 378
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0001885,
      "loss": 2.9516,
      "step": 379
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.00018899999999999999,
      "loss": 3.3719,
      "step": 380
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0001895,
      "loss": 2.9289,
      "step": 381
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.00019,
      "loss": 3.0248,
      "step": 382
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.00019050000000000002,
      "loss": 3.3353,
      "step": 383
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.000191,
      "loss": 3.1736,
      "step": 384
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.00019150000000000002,
      "loss": 3.2677,
      "step": 385
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.000192,
      "loss": 3.0463,
      "step": 386
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.00019250000000000002,
      "loss": 3.1592,
      "step": 387
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.000193,
      "loss": 3.1369,
      "step": 388
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.00019350000000000001,
      "loss": 3.0891,
      "step": 389
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.000194,
      "loss": 3.2986,
      "step": 390
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0001945,
      "loss": 3.1368,
      "step": 391
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.000195,
      "loss": 3.2303,
      "step": 392
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0001955,
      "loss": 3.202,
      "step": 393
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.000196,
      "loss": 3.3576,
      "step": 394
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0001965,
      "loss": 3.2352,
      "step": 395
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.00019700000000000002,
      "loss": 3.0549,
      "step": 396
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.00019750000000000003,
      "loss": 3.344,
      "step": 397
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.00019800000000000002,
      "loss": 3.3654,
      "step": 398
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.00019850000000000003,
      "loss": 3.0266,
      "step": 399
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.000199,
      "loss": 3.0726,
      "step": 400
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.00019950000000000002,
      "loss": 3.2329,
      "step": 401
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0002,
      "loss": 3.3064,
      "step": 402
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.00019991666666666668,
      "loss": 3.2487,
      "step": 403
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.00019983333333333333,
      "loss": 3.1877,
      "step": 404
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.00019975,
      "loss": 3.1208,
      "step": 405
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.00019966666666666668,
      "loss": 3.2677,
      "step": 406
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.00019958333333333335,
      "loss": 3.2764,
      "step": 407
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.00019950000000000002,
      "loss": 3.1373,
      "step": 408
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.00019941666666666667,
      "loss": 3.3844,
      "step": 409
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.00019933333333333334,
      "loss": 2.8854,
      "step": 410
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.00019925,
      "loss": 3.2518,
      "step": 411
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.0001991666666666667,
      "loss": 3.1625,
      "step": 412
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.00019908333333333334,
      "loss": 3.1968,
      "step": 413
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.000199,
      "loss": 3.249,
      "step": 414
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.00019891666666666669,
      "loss": 3.1986,
      "step": 415
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.00019883333333333333,
      "loss": 2.8994,
      "step": 416
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.00019875,
      "loss": 2.9902,
      "step": 417
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.00019866666666666668,
      "loss": 3.056,
      "step": 418
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.00019858333333333335,
      "loss": 3.0654,
      "step": 419
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.00019850000000000003,
      "loss": 3.0973,
      "step": 420
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.00019841666666666667,
      "loss": 3.2271,
      "step": 421
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.00019833333333333335,
      "loss": 2.8813,
      "step": 422
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.00019825,
      "loss": 3.3083,
      "step": 423
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.00019816666666666667,
      "loss": 2.9093,
      "step": 424
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.00019808333333333334,
      "loss": 3.1347,
      "step": 425
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.00019800000000000002,
      "loss": 3.1135,
      "step": 426
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0001979166666666667,
      "loss": 3.1862,
      "step": 427
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.00019783333333333334,
      "loss": 3.112,
      "step": 428
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.00019775,
      "loss": 3.1532,
      "step": 429
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.00019766666666666666,
      "loss": 3.164,
      "step": 430
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.00019758333333333333,
      "loss": 3.3704,
      "step": 431
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.00019750000000000003,
      "loss": 3.1579,
      "step": 432
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.00019741666666666668,
      "loss": 3.2616,
      "step": 433
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.00019733333333333335,
      "loss": 2.8825,
      "step": 434
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.00019725,
      "loss": 2.9931,
      "step": 435
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.00019716666666666667,
      "loss": 3.1423,
      "step": 436
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.00019708333333333334,
      "loss": 3.1078,
      "step": 437
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.00019700000000000002,
      "loss": 3.2367,
      "step": 438
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0001969166666666667,
      "loss": 3.3632,
      "step": 439
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.00019683333333333334,
      "loss": 2.9918,
      "step": 440
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.00019675,
      "loss": 2.9814,
      "step": 441
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.00019666666666666666,
      "loss": 3.0347,
      "step": 442
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.00019658333333333333,
      "loss": 3.2375,
      "step": 443
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0001965,
      "loss": 3.0128,
      "step": 444
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.00019641666666666668,
      "loss": 2.9279,
      "step": 445
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.00019633333333333335,
      "loss": 3.2032,
      "step": 446
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.00019625,
      "loss": 3.1441,
      "step": 447
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.00019616666666666667,
      "loss": 3.1155,
      "step": 448
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.00019608333333333335,
      "loss": 3.2429,
      "step": 449
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.000196,
      "loss": 3.1095,
      "step": 450
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.0001959166666666667,
      "loss": 3.2229,
      "step": 451
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.00019583333333333334,
      "loss": 3.0008,
      "step": 452
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.00019575000000000001,
      "loss": 2.9273,
      "step": 453
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.0001956666666666667,
      "loss": 3.2133,
      "step": 454
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.00019558333333333333,
      "loss": 3.2556,
      "step": 455
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.0001955,
      "loss": 3.1096,
      "step": 456
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.00019541666666666668,
      "loss": 3.2994,
      "step": 457
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.00019533333333333336,
      "loss": 3.2379,
      "step": 458
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.00019525,
      "loss": 2.9204,
      "step": 459
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.00019516666666666668,
      "loss": 3.1473,
      "step": 460
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.00019508333333333335,
      "loss": 2.9051,
      "step": 461
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.000195,
      "loss": 3.0339,
      "step": 462
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.00019491666666666667,
      "loss": 3.1965,
      "step": 463
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.00019483333333333334,
      "loss": 3.028,
      "step": 464
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.00019475000000000002,
      "loss": 3.053,
      "step": 465
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0001946666666666667,
      "loss": 3.2151,
      "step": 466
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.00019458333333333334,
      "loss": 3.2955,
      "step": 467
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0001945,
      "loss": 3.2537,
      "step": 468
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.00019441666666666666,
      "loss": 3.0061,
      "step": 469
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.00019433333333333333,
      "loss": 3.0548,
      "step": 470
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.00019425,
      "loss": 3.2172,
      "step": 471
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.00019416666666666668,
      "loss": 3.1668,
      "step": 472
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.00019408333333333335,
      "loss": 3.0447,
      "step": 473
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.000194,
      "loss": 3.2887,
      "step": 474
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.00019391666666666667,
      "loss": 3.1029,
      "step": 475
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.00019383333333333335,
      "loss": 3.0803,
      "step": 476
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.00019375000000000002,
      "loss": 3.1904,
      "step": 477
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0001936666666666667,
      "loss": 3.0892,
      "step": 478
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.00019358333333333334,
      "loss": 3.2538,
      "step": 479
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.00019350000000000001,
      "loss": 3.0454,
      "step": 480
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.00019341666666666666,
      "loss": 3.0355,
      "step": 481
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.00019333333333333333,
      "loss": 3.287,
      "step": 482
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.00019325,
      "loss": 3.1825,
      "step": 483
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.00019316666666666668,
      "loss": 2.9524,
      "step": 484
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.00019308333333333336,
      "loss": 3.0549,
      "step": 485
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.000193,
      "loss": 3.1543,
      "step": 486
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.00019291666666666668,
      "loss": 3.1311,
      "step": 487
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.00019283333333333332,
      "loss": 3.2027,
      "step": 488
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.00019275,
      "loss": 3.0914,
      "step": 489
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0001926666666666667,
      "loss": 3.286,
      "step": 490
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.00019258333333333334,
      "loss": 3.4909,
      "step": 491
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.00019250000000000002,
      "loss": 3.1086,
      "step": 492
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.00019241666666666666,
      "loss": 2.9693,
      "step": 493
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.00019233333333333334,
      "loss": 3.1278,
      "step": 494
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.00019225,
      "loss": 2.9684,
      "step": 495
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.00019216666666666668,
      "loss": 3.1756,
      "step": 496
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.00019208333333333336,
      "loss": 3.1901,
      "step": 497
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.000192,
      "loss": 3.1362,
      "step": 498
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.00019191666666666668,
      "loss": 3.0186,
      "step": 499
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.00019183333333333333,
      "loss": 3.1948,
      "step": 500
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.00019175,
      "loss": 2.9911,
      "step": 501
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.00019166666666666667,
      "loss": 3.3073,
      "step": 502
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.00019158333333333335,
      "loss": 3.0707,
      "step": 503
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.00019150000000000002,
      "loss": 3.2033,
      "step": 504
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.00019141666666666667,
      "loss": 2.9172,
      "step": 505
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.00019133333333333334,
      "loss": 3.0061,
      "step": 506
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.00019125000000000001,
      "loss": 2.8103,
      "step": 507
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.00019116666666666666,
      "loss": 3.0941,
      "step": 508
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.00019108333333333333,
      "loss": 3.1632,
      "step": 509
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.000191,
      "loss": 3.1602,
      "step": 510
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.00019091666666666668,
      "loss": 3.1715,
      "step": 511
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.00019083333333333336,
      "loss": 3.1601,
      "step": 512
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.00019075,
      "loss": 3.3094,
      "step": 513
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.00019066666666666668,
      "loss": 3.0643,
      "step": 514
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.00019058333333333335,
      "loss": 3.242,
      "step": 515
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.00019050000000000002,
      "loss": 3.2405,
      "step": 516
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.00019041666666666667,
      "loss": 3.2657,
      "step": 517
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.00019033333333333334,
      "loss": 3.2502,
      "step": 518
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.00019025000000000002,
      "loss": 3.0628,
      "step": 519
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.00019016666666666666,
      "loss": 3.2714,
      "step": 520
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.00019008333333333334,
      "loss": 3.2683,
      "step": 521
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.00019,
      "loss": 2.8685,
      "step": 522
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.00018991666666666668,
      "loss": 3.3374,
      "step": 523
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.00018983333333333336,
      "loss": 3.1404,
      "step": 524
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.00018975,
      "loss": 2.9565,
      "step": 525
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.00018966666666666668,
      "loss": 3.3039,
      "step": 526
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.00018958333333333332,
      "loss": 3.0118,
      "step": 527
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0001895,
      "loss": 3.1713,
      "step": 528
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0001894166666666667,
      "loss": 3.2394,
      "step": 529
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.00018933333333333335,
      "loss": 3.4396,
      "step": 530
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.00018925000000000002,
      "loss": 3.0608,
      "step": 531
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.00018916666666666667,
      "loss": 3.1532,
      "step": 532
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.00018908333333333334,
      "loss": 3.0446,
      "step": 533
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.00018899999999999999,
      "loss": 3.0096,
      "step": 534
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0001889166666666667,
      "loss": 3.0937,
      "step": 535
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.00018883333333333336,
      "loss": 2.7893,
      "step": 536
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.00018875,
      "loss": 2.9423,
      "step": 537
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.00018866666666666668,
      "loss": 2.9897,
      "step": 538
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.00018858333333333333,
      "loss": 3.2154,
      "step": 539
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0001885,
      "loss": 3.3286,
      "step": 540
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.00018841666666666667,
      "loss": 3.2616,
      "step": 541
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.00018833333333333335,
      "loss": 2.8734,
      "step": 542
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.00018825000000000002,
      "loss": 3.0555,
      "step": 543
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.00018816666666666667,
      "loss": 3.0744,
      "step": 544
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.00018808333333333334,
      "loss": 3.1786,
      "step": 545
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.000188,
      "loss": 3.1658,
      "step": 546
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.00018791666666666666,
      "loss": 3.1072,
      "step": 547
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.00018783333333333336,
      "loss": 3.3071,
      "step": 548
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.00018775,
      "loss": 2.9953,
      "step": 549
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.00018766666666666668,
      "loss": 2.9944,
      "step": 550
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.00018758333333333333,
      "loss": 2.9885,
      "step": 551
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0001875,
      "loss": 3.1398,
      "step": 552
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.00018741666666666668,
      "loss": 3.2432,
      "step": 553
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.00018733333333333335,
      "loss": 2.898,
      "step": 554
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.00018725000000000002,
      "loss": 3.0153,
      "step": 555
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.00018716666666666667,
      "loss": 3.0847,
      "step": 556
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.00018708333333333335,
      "loss": 3.1915,
      "step": 557
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.00018700000000000002,
      "loss": 3.0973,
      "step": 558
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.00018691666666666667,
      "loss": 3.2881,
      "step": 559
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.00018683333333333334,
      "loss": 3.1489,
      "step": 560
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.00018675,
      "loss": 2.9541,
      "step": 561
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0001866666666666667,
      "loss": 3.17,
      "step": 562
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.00018658333333333333,
      "loss": 2.9544,
      "step": 563
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0001865,
      "loss": 3.1946,
      "step": 564
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.00018641666666666668,
      "loss": 3.1237,
      "step": 565
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.00018633333333333333,
      "loss": 2.9903,
      "step": 566
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.00018625,
      "loss": 3.2424,
      "step": 567
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.00018616666666666667,
      "loss": 3.2924,
      "step": 568
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.00018608333333333335,
      "loss": 3.2195,
      "step": 569
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.00018600000000000002,
      "loss": 2.9847,
      "step": 570
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.00018591666666666667,
      "loss": 3.1821,
      "step": 571
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.00018583333333333334,
      "loss": 3.1406,
      "step": 572
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.00018575,
      "loss": 3.1026,
      "step": 573
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0001856666666666667,
      "loss": 2.9785,
      "step": 574
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.00018558333333333334,
      "loss": 3.1906,
      "step": 575
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0001855,
      "loss": 2.9733,
      "step": 576
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.00018541666666666668,
      "loss": 3.1344,
      "step": 577
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.00018533333333333333,
      "loss": 3.0288,
      "step": 578
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.00018525,
      "loss": 2.866,
      "step": 579
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.00018516666666666668,
      "loss": 3.0403,
      "step": 580
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.00018508333333333335,
      "loss": 3.0926,
      "step": 581
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.00018500000000000002,
      "loss": 2.7793,
      "step": 582
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.00018491666666666667,
      "loss": 3.1829,
      "step": 583
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.00018483333333333334,
      "loss": 3.0862,
      "step": 584
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.00018475,
      "loss": 3.0297,
      "step": 585
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.00018466666666666666,
      "loss": 3.0663,
      "step": 586
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.00018458333333333337,
      "loss": 3.0284,
      "step": 587
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.0001845,
      "loss": 3.0813,
      "step": 588
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.00018441666666666669,
      "loss": 3.0581,
      "step": 589
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.00018433333333333333,
      "loss": 3.1747,
      "step": 590
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.00018425,
      "loss": 3.3473,
      "step": 591
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.00018416666666666665,
      "loss": 3.1362,
      "step": 592
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.00018408333333333335,
      "loss": 3.2398,
      "step": 593
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.00018400000000000003,
      "loss": 3.0792,
      "step": 594
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.00018391666666666667,
      "loss": 3.2092,
      "step": 595
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.00018383333333333335,
      "loss": 3.1521,
      "step": 596
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.00018375,
      "loss": 3.19,
      "step": 597
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.00018366666666666667,
      "loss": 3.0843,
      "step": 598
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.00018358333333333334,
      "loss": 3.2631,
      "step": 599
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.00018350000000000002,
      "loss": 3.4045,
      "step": 600
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0001834166666666667,
      "loss": 3.0856,
      "step": 601
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.00018333333333333334,
      "loss": 2.9735,
      "step": 602
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.00018325,
      "loss": 3.0062,
      "step": 603
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.00018316666666666668,
      "loss": 2.9515,
      "step": 604
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.00018308333333333333,
      "loss": 2.836,
      "step": 605
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.000183,
      "loss": 3.0887,
      "step": 606
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.00018291666666666668,
      "loss": 3.0756,
      "step": 607
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.00018283333333333335,
      "loss": 2.9091,
      "step": 608
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.00018275,
      "loss": 2.9762,
      "step": 609
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.00018266666666666667,
      "loss": 3.0895,
      "step": 610
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.00018258333333333334,
      "loss": 3.2134,
      "step": 611
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0001825,
      "loss": 2.77,
      "step": 612
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0001824166666666667,
      "loss": 3.0621,
      "step": 613
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.00018233333333333334,
      "loss": 3.1063,
      "step": 614
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.00018225,
      "loss": 3.0853,
      "step": 615
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.00018216666666666669,
      "loss": 3.1944,
      "step": 616
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.00018208333333333333,
      "loss": 2.9188,
      "step": 617
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.000182,
      "loss": 3.0811,
      "step": 618
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.00018191666666666668,
      "loss": 3.2267,
      "step": 619
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.00018183333333333335,
      "loss": 3.1752,
      "step": 620
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.00018175,
      "loss": 3.1577,
      "step": 621
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.00018166666666666667,
      "loss": 3.0698,
      "step": 622
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.00018158333333333335,
      "loss": 3.0914,
      "step": 623
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0001815,
      "loss": 2.9552,
      "step": 624
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.00018141666666666667,
      "loss": 3.1264,
      "step": 625
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.00018133333333333334,
      "loss": 3.0775,
      "step": 626
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.00018125000000000001,
      "loss": 3.1918,
      "step": 627
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0001811666666666667,
      "loss": 3.0475,
      "step": 628
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.00018108333333333333,
      "loss": 3.3861,
      "step": 629
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.000181,
      "loss": 3.0957,
      "step": 630
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.00018091666666666666,
      "loss": 3.0136,
      "step": 631
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.00018083333333333336,
      "loss": 3.0731,
      "step": 632
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.00018075000000000003,
      "loss": 3.0461,
      "step": 633
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.00018066666666666668,
      "loss": 3.1179,
      "step": 634
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.00018058333333333335,
      "loss": 3.3075,
      "step": 635
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0001805,
      "loss": 3.1076,
      "step": 636
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.00018041666666666667,
      "loss": 3.0993,
      "step": 637
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.00018033333333333334,
      "loss": 3.071,
      "step": 638
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.00018025000000000002,
      "loss": 2.9756,
      "step": 639
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0001801666666666667,
      "loss": 3.37,
      "step": 640
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.00018008333333333334,
      "loss": 3.2455,
      "step": 641
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.00018,
      "loss": 3.2893,
      "step": 642
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.00017991666666666666,
      "loss": 3.1021,
      "step": 643
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.00017983333333333333,
      "loss": 3.2015,
      "step": 644
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.00017975,
      "loss": 2.8772,
      "step": 645
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.00017966666666666668,
      "loss": 3.1684,
      "step": 646
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.00017958333333333335,
      "loss": 3.2191,
      "step": 647
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0001795,
      "loss": 3.1662,
      "step": 648
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.00017941666666666667,
      "loss": 3.1853,
      "step": 649
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.00017933333333333332,
      "loss": 2.9695,
      "step": 650
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.00017925000000000002,
      "loss": 3.3718,
      "step": 651
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0001791666666666667,
      "loss": 3.0911,
      "step": 652
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.00017908333333333334,
      "loss": 3.1409,
      "step": 653
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.00017900000000000001,
      "loss": 3.0816,
      "step": 654
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.00017891666666666666,
      "loss": 2.9976,
      "step": 655
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.00017883333333333333,
      "loss": 3.2605,
      "step": 656
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.00017875,
      "loss": 2.7676,
      "step": 657
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.00017866666666666668,
      "loss": 3.08,
      "step": 658
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.00017858333333333336,
      "loss": 3.2878,
      "step": 659
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.0001785,
      "loss": 2.9639,
      "step": 660
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.00017841666666666668,
      "loss": 2.7917,
      "step": 661
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.00017833333333333335,
      "loss": 3.0824,
      "step": 662
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.00017825,
      "loss": 2.8887,
      "step": 663
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.00017816666666666667,
      "loss": 3.0749,
      "step": 664
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.00017808333333333334,
      "loss": 2.9557,
      "step": 665
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.00017800000000000002,
      "loss": 3.1738,
      "step": 666
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.00017791666666666666,
      "loss": 3.1663,
      "step": 667
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.00017783333333333334,
      "loss": 3.1368,
      "step": 668
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.00017775,
      "loss": 2.7942,
      "step": 669
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.00017766666666666666,
      "loss": 2.8912,
      "step": 670
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.00017758333333333336,
      "loss": 3.2722,
      "step": 671
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0001775,
      "loss": 3.2528,
      "step": 672
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.00017741666666666668,
      "loss": 3.0499,
      "step": 673
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.00017733333333333335,
      "loss": 2.944,
      "step": 674
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.00017725,
      "loss": 3.1623,
      "step": 675
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.00017716666666666667,
      "loss": 3.071,
      "step": 676
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.00017708333333333335,
      "loss": 3.1783,
      "step": 677
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.00017700000000000002,
      "loss": 3.213,
      "step": 678
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0001769166666666667,
      "loss": 2.934,
      "step": 679
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.00017683333333333334,
      "loss": 3.1454,
      "step": 680
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.00017675000000000001,
      "loss": 3.0469,
      "step": 681
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.00017666666666666666,
      "loss": 3.0375,
      "step": 682
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.00017658333333333333,
      "loss": 3.0781,
      "step": 683
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0001765,
      "loss": 3.077,
      "step": 684
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.00017641666666666668,
      "loss": 3.2565,
      "step": 685
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.00017633333333333335,
      "loss": 3.51,
      "step": 686
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.00017625,
      "loss": 3.0282,
      "step": 687
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.00017616666666666668,
      "loss": 3.2056,
      "step": 688
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.00017608333333333332,
      "loss": 3.2414,
      "step": 689
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.00017600000000000002,
      "loss": 3.0809,
      "step": 690
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0001759166666666667,
      "loss": 3.1584,
      "step": 691
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.00017583333333333334,
      "loss": 3.17,
      "step": 692
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.00017575000000000002,
      "loss": 3.0493,
      "step": 693
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.00017566666666666666,
      "loss": 3.3097,
      "step": 694
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.00017558333333333334,
      "loss": 3.0682,
      "step": 695
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0001755,
      "loss": 3.1308,
      "step": 696
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.00017541666666666668,
      "loss": 3.1051,
      "step": 697
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.00017533333333333336,
      "loss": 2.984,
      "step": 698
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.00017525,
      "loss": 3.1246,
      "step": 699
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.00017516666666666668,
      "loss": 3.0903,
      "step": 700
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.00017508333333333332,
      "loss": 2.8254,
      "step": 701
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.000175,
      "loss": 3.1464,
      "step": 702
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.00017491666666666667,
      "loss": 3.0278,
      "step": 703
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.00017483333333333335,
      "loss": 3.2144,
      "step": 704
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.00017475000000000002,
      "loss": 3.0404,
      "step": 705
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.00017466666666666667,
      "loss": 3.3106,
      "step": 706
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.00017458333333333334,
      "loss": 2.9674,
      "step": 707
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.0001745,
      "loss": 3.0512,
      "step": 708
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.00017441666666666666,
      "loss": 3.2708,
      "step": 709
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.00017433333333333336,
      "loss": 3.123,
      "step": 710
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.00017425,
      "loss": 2.9646,
      "step": 711
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.00017416666666666668,
      "loss": 3.2467,
      "step": 712
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.00017408333333333333,
      "loss": 3.1956,
      "step": 713
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.000174,
      "loss": 3.1583,
      "step": 714
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.00017391666666666667,
      "loss": 3.2709,
      "step": 715
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.00017383333333333335,
      "loss": 3.0785,
      "step": 716
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.00017375000000000002,
      "loss": 3.0051,
      "step": 717
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.00017366666666666667,
      "loss": 3.2014,
      "step": 718
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.00017358333333333334,
      "loss": 3.3946,
      "step": 719
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.00017350000000000002,
      "loss": 2.9765,
      "step": 720
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.00017341666666666666,
      "loss": 3.107,
      "step": 721
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.00017333333333333334,
      "loss": 3.0102,
      "step": 722
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.00017325,
      "loss": 3.2201,
      "step": 723
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.00017316666666666668,
      "loss": 3.3516,
      "step": 724
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.00017308333333333333,
      "loss": 3.0058,
      "step": 725
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.000173,
      "loss": 3.2433,
      "step": 726
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.00017291666666666668,
      "loss": 2.9353,
      "step": 727
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.00017283333333333332,
      "loss": 3.0171,
      "step": 728
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.00017275000000000002,
      "loss": 3.1897,
      "step": 729
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.00017266666666666667,
      "loss": 3.1262,
      "step": 730
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.00017258333333333335,
      "loss": 2.9752,
      "step": 731
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.00017250000000000002,
      "loss": 3.1324,
      "step": 732
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.00017241666666666667,
      "loss": 3.1843,
      "step": 733
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.00017233333333333334,
      "loss": 3.041,
      "step": 734
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.00017225,
      "loss": 2.8194,
      "step": 735
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.00017216666666666669,
      "loss": 3.0767,
      "step": 736
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.00017208333333333336,
      "loss": 2.9889,
      "step": 737
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.000172,
      "loss": 3.117,
      "step": 738
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.00017191666666666668,
      "loss": 2.9015,
      "step": 739
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.00017183333333333333,
      "loss": 3.0339,
      "step": 740
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.00017175,
      "loss": 3.134,
      "step": 741
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.00017166666666666667,
      "loss": 3.3562,
      "step": 742
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.00017158333333333335,
      "loss": 3.2198,
      "step": 743
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.00017150000000000002,
      "loss": 3.1937,
      "step": 744
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.00017141666666666667,
      "loss": 2.8347,
      "step": 745
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.00017133333333333334,
      "loss": 3.2446,
      "step": 746
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.00017125,
      "loss": 2.9342,
      "step": 747
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.00017116666666666666,
      "loss": 3.2072,
      "step": 748
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.00017108333333333336,
      "loss": 3.1507,
      "step": 749
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.000171,
      "loss": 3.0762,
      "step": 750
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.00017091666666666668,
      "loss": 3.4243,
      "step": 751
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.00017083333333333333,
      "loss": 3.2407,
      "step": 752
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.00017075,
      "loss": 2.9459,
      "step": 753
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.00017066666666666668,
      "loss": 3.1771,
      "step": 754
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.00017058333333333335,
      "loss": 3.279,
      "step": 755
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.00017050000000000002,
      "loss": 3.0043,
      "step": 756
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.00017041666666666667,
      "loss": 3.0001,
      "step": 757
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.00017033333333333334,
      "loss": 3.0147,
      "step": 758
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.00017025,
      "loss": 3.2099,
      "step": 759
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.00017016666666666666,
      "loss": 3.0712,
      "step": 760
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.00017008333333333334,
      "loss": 3.179,
      "step": 761
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.00017,
      "loss": 3.1192,
      "step": 762
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.00016991666666666669,
      "loss": 2.8221,
      "step": 763
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.00016983333333333333,
      "loss": 2.9827,
      "step": 764
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.00016975,
      "loss": 2.9999,
      "step": 765
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.00016966666666666668,
      "loss": 3.0718,
      "step": 766
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.00016958333333333333,
      "loss": 3.028,
      "step": 767
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.00016950000000000003,
      "loss": 3.259,
      "step": 768
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.00016941666666666667,
      "loss": 3.2999,
      "step": 769
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.00016933333333333335,
      "loss": 3.2561,
      "step": 770
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.00016925,
      "loss": 3.117,
      "step": 771
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.00016916666666666667,
      "loss": 3.1121,
      "step": 772
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.00016908333333333334,
      "loss": 2.9997,
      "step": 773
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.00016900000000000002,
      "loss": 3.1673,
      "step": 774
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0001689166666666667,
      "loss": 3.1398,
      "step": 775
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.00016883333333333334,
      "loss": 3.303,
      "step": 776
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.00016875,
      "loss": 2.9653,
      "step": 777
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.00016866666666666668,
      "loss": 3.1465,
      "step": 778
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.00016858333333333333,
      "loss": 2.9532,
      "step": 779
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0001685,
      "loss": 3.0489,
      "step": 780
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.00016841666666666668,
      "loss": 2.9129,
      "step": 781
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.00016833333333333335,
      "loss": 3.2911,
      "step": 782
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.00016825000000000002,
      "loss": 3.1786,
      "step": 783
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.00016816666666666667,
      "loss": 3.0502,
      "step": 784
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.00016808333333333334,
      "loss": 2.91,
      "step": 785
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.000168,
      "loss": 2.9431,
      "step": 786
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.00016791666666666666,
      "loss": 3.1969,
      "step": 787
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.00016783333333333334,
      "loss": 3.2769,
      "step": 788
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.00016775,
      "loss": 2.954,
      "step": 789
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.00016766666666666669,
      "loss": 3.038,
      "step": 790
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.00016758333333333333,
      "loss": 3.2509,
      "step": 791
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0001675,
      "loss": 3.2601,
      "step": 792
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.00016741666666666668,
      "loss": 3.0271,
      "step": 793
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.00016733333333333335,
      "loss": 3.2821,
      "step": 794
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.00016725000000000003,
      "loss": 3.2047,
      "step": 795
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.00016716666666666667,
      "loss": 2.9806,
      "step": 796
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.00016708333333333335,
      "loss": 3.1595,
      "step": 797
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.000167,
      "loss": 2.9857,
      "step": 798
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.00016691666666666667,
      "loss": 3.033,
      "step": 799
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.00016683333333333334,
      "loss": 3.1198,
      "step": 800
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.00016675000000000001,
      "loss": 3.0547,
      "step": 801
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0001666666666666667,
      "loss": 3.218,
      "step": 802
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.00016658333333333333,
      "loss": 3.0681,
      "step": 803
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0001665,
      "loss": 3.0178,
      "step": 804
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.00016641666666666666,
      "loss": 3.1464,
      "step": 805
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.00016633333333333333,
      "loss": 3.0447,
      "step": 806
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.00016625000000000003,
      "loss": 2.9751,
      "step": 807
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.00016616666666666668,
      "loss": 2.8381,
      "step": 808
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.00016608333333333335,
      "loss": 3.043,
      "step": 809
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.000166,
      "loss": 2.9557,
      "step": 810
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.00016591666666666667,
      "loss": 3.1101,
      "step": 811
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.00016583333333333334,
      "loss": 3.0524,
      "step": 812
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.00016575000000000002,
      "loss": 3.3245,
      "step": 813
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0001656666666666667,
      "loss": 3.1102,
      "step": 814
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.00016558333333333334,
      "loss": 3.1234,
      "step": 815
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0001655,
      "loss": 3.142,
      "step": 816
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.00016541666666666666,
      "loss": 3.173,
      "step": 817
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.00016533333333333333,
      "loss": 3.2885,
      "step": 818
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.00016525,
      "loss": 2.853,
      "step": 819
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.00016516666666666668,
      "loss": 2.9527,
      "step": 820
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.00016508333333333335,
      "loss": 3.1656,
      "step": 821
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.000165,
      "loss": 2.8028,
      "step": 822
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.00016491666666666667,
      "loss": 3.0192,
      "step": 823
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.00016483333333333335,
      "loss": 3.0643,
      "step": 824
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.00016475,
      "loss": 3.0939,
      "step": 825
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.00016466666666666667,
      "loss": 3.1546,
      "step": 826
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.00016458333333333334,
      "loss": 3.1513,
      "step": 827
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.00016450000000000001,
      "loss": 2.9462,
      "step": 828
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0001644166666666667,
      "loss": 2.9651,
      "step": 829
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.00016433333333333333,
      "loss": 3.0419,
      "step": 830
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.00016425,
      "loss": 3.2793,
      "step": 831
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.00016416666666666668,
      "loss": 3.24,
      "step": 832
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.00016408333333333336,
      "loss": 3.2364,
      "step": 833
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.000164,
      "loss": 3.2408,
      "step": 834
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.00016391666666666668,
      "loss": 3.1081,
      "step": 835
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.00016383333333333335,
      "loss": 3.049,
      "step": 836
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.00016375,
      "loss": 3.2833,
      "step": 837
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.00016366666666666667,
      "loss": 2.8748,
      "step": 838
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.00016358333333333334,
      "loss": 3.1935,
      "step": 839
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.00016350000000000002,
      "loss": 3.0226,
      "step": 840
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0001634166666666667,
      "loss": 3.1653,
      "step": 841
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.00016333333333333334,
      "loss": 3.1843,
      "step": 842
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.00016325,
      "loss": 3.0936,
      "step": 843
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.00016316666666666666,
      "loss": 3.0324,
      "step": 844
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.00016308333333333333,
      "loss": 3.0598,
      "step": 845
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.000163,
      "loss": 3.1954,
      "step": 846
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.00016291666666666668,
      "loss": 3.2221,
      "step": 847
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.00016283333333333335,
      "loss": 2.7321,
      "step": 848
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.00016275,
      "loss": 3.1297,
      "step": 849
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.00016266666666666667,
      "loss": 3.084,
      "step": 850
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.00016258333333333332,
      "loss": 3.1002,
      "step": 851
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.00016250000000000002,
      "loss": 2.964,
      "step": 852
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.0001624166666666667,
      "loss": 3.2304,
      "step": 853
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.00016233333333333334,
      "loss": 3.1177,
      "step": 854
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.00016225000000000001,
      "loss": 3.2084,
      "step": 855
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.00016216666666666666,
      "loss": 3.2923,
      "step": 856
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.00016208333333333333,
      "loss": 3.3188,
      "step": 857
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.000162,
      "loss": 3.1847,
      "step": 858
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.00016191666666666668,
      "loss": 3.0957,
      "step": 859
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.00016183333333333335,
      "loss": 3.1799,
      "step": 860
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.00016175,
      "loss": 3.1355,
      "step": 861
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.00016166666666666668,
      "loss": 3.0327,
      "step": 862
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.00016158333333333332,
      "loss": 3.0817,
      "step": 863
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0001615,
      "loss": 3.187,
      "step": 864
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0001614166666666667,
      "loss": 3.1528,
      "step": 865
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.00016133333333333334,
      "loss": 3.1807,
      "step": 866
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.00016125000000000002,
      "loss": 3.2117,
      "step": 867
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.00016116666666666666,
      "loss": 3.2394,
      "step": 868
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.00016108333333333334,
      "loss": 3.2018,
      "step": 869
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.000161,
      "loss": 3.0546,
      "step": 870
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.00016091666666666668,
      "loss": 3.2054,
      "step": 871
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.00016083333333333336,
      "loss": 2.8787,
      "step": 872
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.00016075,
      "loss": 2.9268,
      "step": 873
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.00016066666666666668,
      "loss": 3.1894,
      "step": 874
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.00016058333333333332,
      "loss": 3.0069,
      "step": 875
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0001605,
      "loss": 2.9428,
      "step": 876
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.00016041666666666667,
      "loss": 2.9963,
      "step": 877
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.00016033333333333335,
      "loss": 2.9805,
      "step": 878
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.00016025000000000002,
      "loss": 2.9801,
      "step": 879
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.00016016666666666667,
      "loss": 3.1744,
      "step": 880
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.00016008333333333334,
      "loss": 3.1727,
      "step": 881
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.00016,
      "loss": 3.1068,
      "step": 882
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.00015991666666666666,
      "loss": 3.4132,
      "step": 883
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.00015983333333333333,
      "loss": 2.9537,
      "step": 884
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.00015975,
      "loss": 2.8851,
      "step": 885
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.00015966666666666668,
      "loss": 3.0875,
      "step": 886
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.00015958333333333335,
      "loss": 3.0364,
      "step": 887
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0001595,
      "loss": 2.8979,
      "step": 888
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.00015941666666666667,
      "loss": 3.2708,
      "step": 889
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.00015933333333333332,
      "loss": 3.0162,
      "step": 890
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.00015925000000000002,
      "loss": 3.1936,
      "step": 891
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.00015916666666666667,
      "loss": 2.9045,
      "step": 892
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.00015908333333333334,
      "loss": 3.2236,
      "step": 893
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.00015900000000000002,
      "loss": 3.0213,
      "step": 894
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.00015891666666666666,
      "loss": 3.0852,
      "step": 895
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.00015883333333333334,
      "loss": 3.1309,
      "step": 896
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.00015875,
      "loss": 3.0177,
      "step": 897
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.00015866666666666668,
      "loss": 3.2321,
      "step": 898
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.00015858333333333336,
      "loss": 3.0633,
      "step": 899
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0001585,
      "loss": 3.1816,
      "step": 900
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.00015841666666666668,
      "loss": 3.05,
      "step": 901
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.00015833333333333332,
      "loss": 3.2604,
      "step": 902
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.00015825,
      "loss": 3.1324,
      "step": 903
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0001581666666666667,
      "loss": 3.1295,
      "step": 904
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.00015808333333333335,
      "loss": 3.1505,
      "step": 905
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.00015800000000000002,
      "loss": 3.0379,
      "step": 906
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.00015791666666666667,
      "loss": 3.0305,
      "step": 907
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.00015783333333333334,
      "loss": 2.9666,
      "step": 908
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.00015774999999999999,
      "loss": 2.9175,
      "step": 909
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.00015766666666666669,
      "loss": 3.1114,
      "step": 910
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.00015758333333333336,
      "loss": 3.0755,
      "step": 911
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0001575,
      "loss": 3.1389,
      "step": 912
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.00015741666666666668,
      "loss": 2.9317,
      "step": 913
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.00015733333333333333,
      "loss": 3.0604,
      "step": 914
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.00015725,
      "loss": 3.1112,
      "step": 915
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.00015716666666666667,
      "loss": 3.0011,
      "step": 916
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.00015708333333333335,
      "loss": 3.1321,
      "step": 917
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.00015700000000000002,
      "loss": 3.0238,
      "step": 918
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.00015691666666666667,
      "loss": 3.1891,
      "step": 919
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.00015683333333333334,
      "loss": 3.1789,
      "step": 920
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.00015675,
      "loss": 3.2048,
      "step": 921
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.00015666666666666666,
      "loss": 3.0504,
      "step": 922
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.00015658333333333334,
      "loss": 3.1231,
      "step": 923
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.0001565,
      "loss": 3.1946,
      "step": 924
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.00015641666666666668,
      "loss": 2.9838,
      "step": 925
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.00015633333333333333,
      "loss": 3.16,
      "step": 926
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.00015625,
      "loss": 2.9799,
      "step": 927
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.00015616666666666668,
      "loss": 3.0879,
      "step": 928
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.00015608333333333332,
      "loss": 3.0368,
      "step": 929
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.00015600000000000002,
      "loss": 3.1113,
      "step": 930
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.00015591666666666667,
      "loss": 3.0955,
      "step": 931
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.00015583333333333334,
      "loss": 3.0213,
      "step": 932
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.00015575000000000002,
      "loss": 3.0065,
      "step": 933
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.00015566666666666666,
      "loss": 3.1897,
      "step": 934
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.00015558333333333334,
      "loss": 3.022,
      "step": 935
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.0001555,
      "loss": 3.1574,
      "step": 936
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.00015541666666666669,
      "loss": 3.1303,
      "step": 937
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.00015533333333333333,
      "loss": 3.1515,
      "step": 938
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.00015525,
      "loss": 2.9005,
      "step": 939
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.00015516666666666668,
      "loss": 2.9382,
      "step": 940
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.00015508333333333333,
      "loss": 3.2671,
      "step": 941
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.000155,
      "loss": 3.1655,
      "step": 942
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.00015491666666666667,
      "loss": 3.1089,
      "step": 943
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.00015483333333333335,
      "loss": 2.8937,
      "step": 944
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.00015475000000000002,
      "loss": 3.3066,
      "step": 945
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.00015466666666666667,
      "loss": 3.2124,
      "step": 946
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.00015458333333333334,
      "loss": 2.8976,
      "step": 947
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.0001545,
      "loss": 3.0317,
      "step": 948
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0001544166666666667,
      "loss": 3.0843,
      "step": 949
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.00015433333333333334,
      "loss": 3.1298,
      "step": 950
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.00015425,
      "loss": 3.1258,
      "step": 951
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.00015416666666666668,
      "loss": 3.0418,
      "step": 952
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.00015408333333333333,
      "loss": 3.048,
      "step": 953
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.000154,
      "loss": 3.1631,
      "step": 954
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.00015391666666666668,
      "loss": 3.1227,
      "step": 955
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.00015383333333333335,
      "loss": 3.135,
      "step": 956
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.00015375000000000002,
      "loss": 2.9361,
      "step": 957
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.00015366666666666667,
      "loss": 3.145,
      "step": 958
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.00015358333333333334,
      "loss": 3.0285,
      "step": 959
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0001535,
      "loss": 3.1257,
      "step": 960
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.00015341666666666666,
      "loss": 2.9906,
      "step": 961
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.00015333333333333334,
      "loss": 2.9526,
      "step": 962
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.00015325,
      "loss": 2.9873,
      "step": 963
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.00015316666666666669,
      "loss": 3.1429,
      "step": 964
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.00015308333333333333,
      "loss": 3.1624,
      "step": 965
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.000153,
      "loss": 3.118,
      "step": 966
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.00015291666666666665,
      "loss": 2.8361,
      "step": 967
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.00015283333333333335,
      "loss": 3.1575,
      "step": 968
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.00015275000000000003,
      "loss": 2.9728,
      "step": 969
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.00015266666666666667,
      "loss": 3.1647,
      "step": 970
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.00015258333333333335,
      "loss": 3.1999,
      "step": 971
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0001525,
      "loss": 3.1317,
      "step": 972
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.00015241666666666667,
      "loss": 3.265,
      "step": 973
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.00015233333333333334,
      "loss": 3.1305,
      "step": 974
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.00015225000000000001,
      "loss": 3.1706,
      "step": 975
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0001521666666666667,
      "loss": 3.1613,
      "step": 976
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.00015208333333333333,
      "loss": 3.2374,
      "step": 977
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.000152,
      "loss": 3.1312,
      "step": 978
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.00015191666666666668,
      "loss": 3.2455,
      "step": 979
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.00015183333333333333,
      "loss": 3.0979,
      "step": 980
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.00015175,
      "loss": 3.1895,
      "step": 981
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.00015166666666666668,
      "loss": 2.972,
      "step": 982
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.00015158333333333335,
      "loss": 3.2832,
      "step": 983
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0001515,
      "loss": 3.0895,
      "step": 984
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.00015141666666666667,
      "loss": 3.116,
      "step": 985
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.00015133333333333334,
      "loss": 3.0764,
      "step": 986
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.00015125,
      "loss": 3.0453,
      "step": 987
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0001511666666666667,
      "loss": 3.3089,
      "step": 988
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.00015108333333333334,
      "loss": 3.0693,
      "step": 989
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.000151,
      "loss": 3.0882,
      "step": 990
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.00015091666666666668,
      "loss": 2.957,
      "step": 991
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.00015083333333333333,
      "loss": 3.0583,
      "step": 992
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.00015075,
      "loss": 3.1149,
      "step": 993
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.00015066666666666668,
      "loss": 3.1932,
      "step": 994
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.00015058333333333335,
      "loss": 3.1433,
      "step": 995
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0001505,
      "loss": 3.159,
      "step": 996
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.00015041666666666667,
      "loss": 3.1527,
      "step": 997
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.00015033333333333335,
      "loss": 3.039,
      "step": 998
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.00015025,
      "loss": 3.2745,
      "step": 999
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.00015016666666666667,
      "loss": 3.2554,
      "step": 1000
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.00015008333333333334,
      "loss": 3.0529,
      "step": 1001
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.00015000000000000001,
      "loss": 3.3249,
      "step": 1002
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0001499166666666667,
      "loss": 3.1142,
      "step": 1003
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.00014983333333333333,
      "loss": 3.1083,
      "step": 1004
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.00014975,
      "loss": 3.1534,
      "step": 1005
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.00014966666666666665,
      "loss": 2.935,
      "step": 1006
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.00014958333333333336,
      "loss": 3.0566,
      "step": 1007
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.00014950000000000003,
      "loss": 3.2274,
      "step": 1008
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.00014941666666666668,
      "loss": 2.974,
      "step": 1009
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.00014933333333333335,
      "loss": 2.9174,
      "step": 1010
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.00014925,
      "loss": 3.0119,
      "step": 1011
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.00014916666666666667,
      "loss": 2.9945,
      "step": 1012
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.00014908333333333334,
      "loss": 3.2034,
      "step": 1013
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.00014900000000000002,
      "loss": 3.0983,
      "step": 1014
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0001489166666666667,
      "loss": 3.2729,
      "step": 1015
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.00014883333333333334,
      "loss": 3.064,
      "step": 1016
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.00014875,
      "loss": 3.119,
      "step": 1017
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.00014866666666666666,
      "loss": 3.2163,
      "step": 1018
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.00014858333333333333,
      "loss": 3.1876,
      "step": 1019
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0001485,
      "loss": 3.2461,
      "step": 1020
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.00014841666666666668,
      "loss": 3.0425,
      "step": 1021
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.00014833333333333335,
      "loss": 3.1371,
      "step": 1022
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.00014825,
      "loss": 2.8595,
      "step": 1023
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.00014816666666666667,
      "loss": 2.9788,
      "step": 1024
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.00014808333333333332,
      "loss": 2.9527,
      "step": 1025
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.000148,
      "loss": 3.2945,
      "step": 1026
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0001479166666666667,
      "loss": 3.0101,
      "step": 1027
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.00014783333333333334,
      "loss": 3.1091,
      "step": 1028
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.00014775,
      "loss": 2.8845,
      "step": 1029
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.00014766666666666666,
      "loss": 3.1218,
      "step": 1030
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.00014758333333333333,
      "loss": 3.0771,
      "step": 1031
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0001475,
      "loss": 3.0697,
      "step": 1032
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.00014741666666666668,
      "loss": 3.1854,
      "step": 1033
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.00014733333333333335,
      "loss": 3.1593,
      "step": 1034
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.00014725,
      "loss": 2.987,
      "step": 1035
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.00014716666666666668,
      "loss": 2.8859,
      "step": 1036
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.00014708333333333335,
      "loss": 3.1464,
      "step": 1037
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.000147,
      "loss": 3.097,
      "step": 1038
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.00014691666666666667,
      "loss": 3.0252,
      "step": 1039
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.00014683333333333334,
      "loss": 3.1018,
      "step": 1040
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.00014675000000000002,
      "loss": 3.0997,
      "step": 1041
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.00014666666666666666,
      "loss": 3.0645,
      "step": 1042
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.00014658333333333334,
      "loss": 3.1116,
      "step": 1043
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0001465,
      "loss": 3.0503,
      "step": 1044
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.00014641666666666666,
      "loss": 3.183,
      "step": 1045
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.00014633333333333336,
      "loss": 3.0127,
      "step": 1046
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.00014625,
      "loss": 3.2083,
      "step": 1047
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.00014616666666666668,
      "loss": 3.1448,
      "step": 1048
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.00014608333333333335,
      "loss": 2.9265,
      "step": 1049
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.000146,
      "loss": 3.1545,
      "step": 1050
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.00014591666666666667,
      "loss": 3.2342,
      "step": 1051
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.00014583333333333335,
      "loss": 2.8761,
      "step": 1052
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.00014575000000000002,
      "loss": 3.2329,
      "step": 1053
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0001456666666666667,
      "loss": 3.1114,
      "step": 1054
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.00014558333333333334,
      "loss": 3.1608,
      "step": 1055
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0001455,
      "loss": 2.9311,
      "step": 1056
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.00014541666666666666,
      "loss": 3.1714,
      "step": 1057
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.00014533333333333333,
      "loss": 3.0416,
      "step": 1058
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.00014525,
      "loss": 3.0712,
      "step": 1059
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.00014516666666666668,
      "loss": 3.0865,
      "step": 1060
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.00014508333333333335,
      "loss": 3.147,
      "step": 1061
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.000145,
      "loss": 3.3141,
      "step": 1062
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.00014491666666666667,
      "loss": 2.9327,
      "step": 1063
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.00014483333333333332,
      "loss": 3.2917,
      "step": 1064
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.00014475,
      "loss": 3.2077,
      "step": 1065
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0001446666666666667,
      "loss": 2.963,
      "step": 1066
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.00014458333333333334,
      "loss": 3.1415,
      "step": 1067
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.00014450000000000002,
      "loss": 2.9021,
      "step": 1068
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.00014441666666666666,
      "loss": 3.1511,
      "step": 1069
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.00014433333333333334,
      "loss": 3.0656,
      "step": 1070
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.00014425,
      "loss": 3.2168,
      "step": 1071
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.00014416666666666668,
      "loss": 3.0189,
      "step": 1072
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.00014408333333333336,
      "loss": 3.0747,
      "step": 1073
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.000144,
      "loss": 3.0807,
      "step": 1074
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.00014391666666666668,
      "loss": 3.0409,
      "step": 1075
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.00014383333333333332,
      "loss": 3.1961,
      "step": 1076
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.00014375,
      "loss": 3.0116,
      "step": 1077
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.00014366666666666667,
      "loss": 3.071,
      "step": 1078
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.00014358333333333334,
      "loss": 3.0288,
      "step": 1079
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.00014350000000000002,
      "loss": 2.9996,
      "step": 1080
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.00014341666666666667,
      "loss": 2.9805,
      "step": 1081
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.00014333333333333334,
      "loss": 3.0896,
      "step": 1082
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.00014325,
      "loss": 3.1468,
      "step": 1083
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.00014316666666666666,
      "loss": 3.0997,
      "step": 1084
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.00014308333333333336,
      "loss": 3.1081,
      "step": 1085
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.000143,
      "loss": 2.9374,
      "step": 1086
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.00014291666666666668,
      "loss": 2.9655,
      "step": 1087
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.00014283333333333333,
      "loss": 3.2079,
      "step": 1088
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.00014275,
      "loss": 3.2942,
      "step": 1089
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.00014266666666666667,
      "loss": 3.0628,
      "step": 1090
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.00014258333333333335,
      "loss": 3.301,
      "step": 1091
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.00014250000000000002,
      "loss": 3.1704,
      "step": 1092
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.00014241666666666667,
      "loss": 3.1679,
      "step": 1093
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.00014233333333333334,
      "loss": 3.1545,
      "step": 1094
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.00014225000000000002,
      "loss": 3.1247,
      "step": 1095
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.00014216666666666666,
      "loss": 2.8254,
      "step": 1096
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.00014208333333333334,
      "loss": 2.8923,
      "step": 1097
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.000142,
      "loss": 3.1801,
      "step": 1098
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.00014191666666666668,
      "loss": 3.351,
      "step": 1099
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.00014183333333333333,
      "loss": 3.2442,
      "step": 1100
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.00014175,
      "loss": 3.193,
      "step": 1101
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.00014166666666666668,
      "loss": 2.8738,
      "step": 1102
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.00014158333333333332,
      "loss": 3.0067,
      "step": 1103
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0001415,
      "loss": 3.1035,
      "step": 1104
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.00014141666666666667,
      "loss": 3.1849,
      "step": 1105
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.00014133333333333334,
      "loss": 3.0775,
      "step": 1106
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.00014125000000000002,
      "loss": 2.9556,
      "step": 1107
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.00014116666666666666,
      "loss": 3.256,
      "step": 1108
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.00014108333333333334,
      "loss": 2.9816,
      "step": 1109
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.000141,
      "loss": 3.0897,
      "step": 1110
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.00014091666666666669,
      "loss": 3.1094,
      "step": 1111
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.00014083333333333336,
      "loss": 3.1983,
      "step": 1112
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.00014075,
      "loss": 3.1498,
      "step": 1113
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.00014066666666666668,
      "loss": 3.0176,
      "step": 1114
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.00014058333333333333,
      "loss": 3.072,
      "step": 1115
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0001405,
      "loss": 3.1414,
      "step": 1116
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.00014041666666666667,
      "loss": 3.103,
      "step": 1117
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.00014033333333333335,
      "loss": 3.1477,
      "step": 1118
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.00014025000000000002,
      "loss": 2.9142,
      "step": 1119
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.00014016666666666667,
      "loss": 3.2381,
      "step": 1120
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.00014008333333333334,
      "loss": 3.1029,
      "step": 1121
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.00014,
      "loss": 3.1026,
      "step": 1122
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.00013991666666666666,
      "loss": 3.1278,
      "step": 1123
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.00013983333333333336,
      "loss": 3.1226,
      "step": 1124
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.00013975,
      "loss": 3.0696,
      "step": 1125
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.00013966666666666668,
      "loss": 3.1133,
      "step": 1126
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.00013958333333333333,
      "loss": 3.2783,
      "step": 1127
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0001395,
      "loss": 2.9871,
      "step": 1128
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.00013941666666666668,
      "loss": 3.1758,
      "step": 1129
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.00013933333333333335,
      "loss": 3.0832,
      "step": 1130
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.00013925000000000002,
      "loss": 3.0544,
      "step": 1131
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.00013916666666666667,
      "loss": 2.9522,
      "step": 1132
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.00013908333333333334,
      "loss": 3.0577,
      "step": 1133
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.000139,
      "loss": 3.2444,
      "step": 1134
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.00013891666666666666,
      "loss": 2.978,
      "step": 1135
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.00013883333333333334,
      "loss": 3.0743,
      "step": 1136
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.00013875,
      "loss": 3.1646,
      "step": 1137
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.00013866666666666669,
      "loss": 3.0803,
      "step": 1138
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.00013858333333333333,
      "loss": 2.9602,
      "step": 1139
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0001385,
      "loss": 3.2362,
      "step": 1140
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.00013841666666666668,
      "loss": 3.0308,
      "step": 1141
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.00013833333333333333,
      "loss": 3.3607,
      "step": 1142
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.00013825,
      "loss": 3.1573,
      "step": 1143
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.00013816666666666667,
      "loss": 2.902,
      "step": 1144
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.00013808333333333335,
      "loss": 3.1402,
      "step": 1145
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.000138,
      "loss": 3.126,
      "step": 1146
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.00013791666666666667,
      "loss": 2.8637,
      "step": 1147
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.00013783333333333334,
      "loss": 3.1144,
      "step": 1148
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.00013775000000000001,
      "loss": 2.9703,
      "step": 1149
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0001376666666666667,
      "loss": 3.0802,
      "step": 1150
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.00013758333333333333,
      "loss": 3.0367,
      "step": 1151
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0001375,
      "loss": 3.2273,
      "step": 1152
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.00013741666666666668,
      "loss": 3.1072,
      "step": 1153
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.00013733333333333333,
      "loss": 3.0547,
      "step": 1154
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.00013725,
      "loss": 3.1079,
      "step": 1155
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.00013716666666666668,
      "loss": 3.0452,
      "step": 1156
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.00013708333333333335,
      "loss": 3.0119,
      "step": 1157
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.00013700000000000002,
      "loss": 2.7526,
      "step": 1158
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.00013691666666666667,
      "loss": 3.1354,
      "step": 1159
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.00013683333333333334,
      "loss": 3.0992,
      "step": 1160
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.00013675,
      "loss": 3.1766,
      "step": 1161
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.00013666666666666666,
      "loss": 3.0296,
      "step": 1162
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.00013658333333333334,
      "loss": 3.0319,
      "step": 1163
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0001365,
      "loss": 2.9806,
      "step": 1164
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.00013641666666666668,
      "loss": 3.0953,
      "step": 1165
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.00013633333333333333,
      "loss": 2.9164,
      "step": 1166
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.00013625,
      "loss": 3.0588,
      "step": 1167
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.00013616666666666665,
      "loss": 3.0981,
      "step": 1168
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.00013608333333333335,
      "loss": 3.0694,
      "step": 1169
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.00013600000000000003,
      "loss": 3.1201,
      "step": 1170
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.00013591666666666667,
      "loss": 3.0791,
      "step": 1171
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.00013583333333333335,
      "loss": 3.1253,
      "step": 1172
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.00013575,
      "loss": 2.9938,
      "step": 1173
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.00013566666666666667,
      "loss": 2.9812,
      "step": 1174
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.00013558333333333334,
      "loss": 3.25,
      "step": 1175
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.00013550000000000001,
      "loss": 3.3423,
      "step": 1176
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0001354166666666667,
      "loss": 3.1038,
      "step": 1177
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.00013533333333333333,
      "loss": 3.1338,
      "step": 1178
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.00013525,
      "loss": 3.3289,
      "step": 1179
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.00013516666666666665,
      "loss": 3.0334,
      "step": 1180
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.00013508333333333333,
      "loss": 3.1146,
      "step": 1181
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.00013500000000000003,
      "loss": 3.1862,
      "step": 1182
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.00013491666666666668,
      "loss": 3.0853,
      "step": 1183
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.00013483333333333335,
      "loss": 3.0084,
      "step": 1184
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.00013475,
      "loss": 3.1602,
      "step": 1185
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.00013466666666666667,
      "loss": 3.1741,
      "step": 1186
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.00013458333333333334,
      "loss": 2.9757,
      "step": 1187
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.00013450000000000002,
      "loss": 3.1136,
      "step": 1188
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0001344166666666667,
      "loss": 2.9871,
      "step": 1189
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.00013433333333333334,
      "loss": 3.1726,
      "step": 1190
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.00013425,
      "loss": 3.0198,
      "step": 1191
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.00013416666666666666,
      "loss": 3.0342,
      "step": 1192
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.00013408333333333333,
      "loss": 3.1095,
      "step": 1193
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.000134,
      "loss": 3.1504,
      "step": 1194
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.00013391666666666668,
      "loss": 2.9651,
      "step": 1195
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.00013383333333333335,
      "loss": 3.117,
      "step": 1196
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.00013375,
      "loss": 3.0628,
      "step": 1197
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.00013366666666666667,
      "loss": 3.1409,
      "step": 1198
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.00013358333333333335,
      "loss": 2.9718,
      "step": 1199
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0001335,
      "loss": 3.2105,
      "step": 1200
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.00013341666666666667,
      "loss": 2.6855,
      "step": 1201
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.00013333333333333334,
      "loss": 3.1796,
      "step": 1202
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.00013325,
      "loss": 3.096,
      "step": 1203
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0001331666666666667,
      "loss": 2.9885,
      "step": 1204
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.00013308333333333333,
      "loss": 3.0799,
      "step": 1205
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.000133,
      "loss": 3.1156,
      "step": 1206
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.00013291666666666665,
      "loss": 3.0181,
      "step": 1207
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.00013283333333333335,
      "loss": 3.1096,
      "step": 1208
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.00013275,
      "loss": 3.3031,
      "step": 1209
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.00013266666666666667,
      "loss": 2.8504,
      "step": 1210
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.00013258333333333335,
      "loss": 3.1169,
      "step": 1211
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0001325,
      "loss": 3.2363,
      "step": 1212
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.00013241666666666667,
      "loss": 2.9888,
      "step": 1213
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.00013233333333333334,
      "loss": 3.0979,
      "step": 1214
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.00013225000000000002,
      "loss": 2.9938,
      "step": 1215
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.0001321666666666667,
      "loss": 3.0141,
      "step": 1216
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.00013208333333333334,
      "loss": 2.9671,
      "step": 1217
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.000132,
      "loss": 2.8635,
      "step": 1218
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.00013191666666666666,
      "loss": 3.0695,
      "step": 1219
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.00013183333333333333,
      "loss": 3.0031,
      "step": 1220
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.00013175,
      "loss": 3.0503,
      "step": 1221
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.00013166666666666668,
      "loss": 2.8908,
      "step": 1222
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.00013158333333333335,
      "loss": 3.1355,
      "step": 1223
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0001315,
      "loss": 3.1237,
      "step": 1224
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.00013141666666666667,
      "loss": 2.9681,
      "step": 1225
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.00013133333333333332,
      "loss": 3.0668,
      "step": 1226
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.00013125000000000002,
      "loss": 3.1004,
      "step": 1227
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0001311666666666667,
      "loss": 2.8377,
      "step": 1228
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.00013108333333333334,
      "loss": 2.8185,
      "step": 1229
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.000131,
      "loss": 2.9717,
      "step": 1230
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.00013091666666666666,
      "loss": 3.1309,
      "step": 1231
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.00013083333333333333,
      "loss": 3.1315,
      "step": 1232
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.00013075,
      "loss": 2.9615,
      "step": 1233
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.00013066666666666668,
      "loss": 2.9548,
      "step": 1234
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.00013058333333333335,
      "loss": 2.9157,
      "step": 1235
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.0001305,
      "loss": 3.2823,
      "step": 1236
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.00013041666666666667,
      "loss": 3.1289,
      "step": 1237
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.00013033333333333332,
      "loss": 3.1499,
      "step": 1238
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.00013025,
      "loss": 3.1587,
      "step": 1239
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.00013016666666666667,
      "loss": 3.2819,
      "step": 1240
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.00013008333333333334,
      "loss": 3.1864,
      "step": 1241
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.00013000000000000002,
      "loss": 3.2276,
      "step": 1242
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.00012991666666666666,
      "loss": 3.2212,
      "step": 1243
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.00012983333333333334,
      "loss": 3.0575,
      "step": 1244
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.00012975,
      "loss": 2.9892,
      "step": 1245
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.00012966666666666666,
      "loss": 3.2286,
      "step": 1246
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.00012958333333333336,
      "loss": 3.165,
      "step": 1247
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.0001295,
      "loss": 3.2122,
      "step": 1248
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.00012941666666666668,
      "loss": 2.9848,
      "step": 1249
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.00012933333333333332,
      "loss": 2.9871,
      "step": 1250
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.00012925,
      "loss": 3.1758,
      "step": 1251
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.00012916666666666667,
      "loss": 2.9683,
      "step": 1252
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.00012908333333333334,
      "loss": 2.9177,
      "step": 1253
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.00012900000000000002,
      "loss": 3.0266,
      "step": 1254
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.00012891666666666667,
      "loss": 3.1783,
      "step": 1255
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.00012883333333333334,
      "loss": 3.195,
      "step": 1256
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.00012875,
      "loss": 3.1703,
      "step": 1257
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.00012866666666666666,
      "loss": 3.0874,
      "step": 1258
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.00012858333333333333,
      "loss": 2.9114,
      "step": 1259
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.0001285,
      "loss": 2.95,
      "step": 1260
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.00012841666666666668,
      "loss": 3.1984,
      "step": 1261
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.00012833333333333335,
      "loss": 3.0254,
      "step": 1262
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.00012825,
      "loss": 3.144,
      "step": 1263
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.00012816666666666667,
      "loss": 3.0989,
      "step": 1264
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.00012808333333333332,
      "loss": 3.1982,
      "step": 1265
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.00012800000000000002,
      "loss": 3.0034,
      "step": 1266
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.00012791666666666667,
      "loss": 2.9259,
      "step": 1267
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.00012783333333333334,
      "loss": 2.8694,
      "step": 1268
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.00012775000000000002,
      "loss": 3.2149,
      "step": 1269
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.00012766666666666666,
      "loss": 3.2231,
      "step": 1270
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.00012758333333333334,
      "loss": 3.0008,
      "step": 1271
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.0001275,
      "loss": 2.9311,
      "step": 1272
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.00012741666666666668,
      "loss": 3.1321,
      "step": 1273
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.00012733333333333336,
      "loss": 3.09,
      "step": 1274
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.00012725,
      "loss": 2.9588,
      "step": 1275
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.00012716666666666668,
      "loss": 2.9198,
      "step": 1276
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.00012708333333333332,
      "loss": 3.1612,
      "step": 1277
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.000127,
      "loss": 3.036,
      "step": 1278
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.00012691666666666667,
      "loss": 3.2858,
      "step": 1279
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.00012683333333333334,
      "loss": 2.9922,
      "step": 1280
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.00012675000000000002,
      "loss": 3.0099,
      "step": 1281
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.00012666666666666666,
      "loss": 2.8792,
      "step": 1282
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.00012658333333333334,
      "loss": 2.9783,
      "step": 1283
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.00012649999999999998,
      "loss": 3.0914,
      "step": 1284
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.00012641666666666669,
      "loss": 2.7458,
      "step": 1285
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.00012633333333333336,
      "loss": 3.1599,
      "step": 1286
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.00012625,
      "loss": 2.9518,
      "step": 1287
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.00012616666666666668,
      "loss": 2.9054,
      "step": 1288
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.00012608333333333333,
      "loss": 3.1568,
      "step": 1289
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.000126,
      "loss": 3.0269,
      "step": 1290
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.00012591666666666667,
      "loss": 2.993,
      "step": 1291
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.00012583333333333335,
      "loss": 3.161,
      "step": 1292
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.00012575000000000002,
      "loss": 3.1109,
      "step": 1293
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.00012566666666666667,
      "loss": 3.265,
      "step": 1294
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.00012558333333333334,
      "loss": 3.2554,
      "step": 1295
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.0001255,
      "loss": 3.1131,
      "step": 1296
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.00012541666666666666,
      "loss": 3.0075,
      "step": 1297
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.00012533333333333334,
      "loss": 3.1448,
      "step": 1298
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.00012525,
      "loss": 2.9093,
      "step": 1299
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.00012516666666666668,
      "loss": 3.048,
      "step": 1300
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.00012508333333333333,
      "loss": 3.2013,
      "step": 1301
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.000125,
      "loss": 2.9592,
      "step": 1302
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.00012491666666666668,
      "loss": 3.2742,
      "step": 1303
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.00012483333333333332,
      "loss": 3.0403,
      "step": 1304
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.00012475000000000002,
      "loss": 2.9251,
      "step": 1305
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.00012466666666666667,
      "loss": 3.2129,
      "step": 1306
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.00012458333333333334,
      "loss": 3.1572,
      "step": 1307
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.00012450000000000002,
      "loss": 3.1831,
      "step": 1308
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.00012441666666666666,
      "loss": 3.3777,
      "step": 1309
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.00012433333333333334,
      "loss": 3.1427,
      "step": 1310
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.00012425,
      "loss": 3.1697,
      "step": 1311
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.00012416666666666669,
      "loss": 3.0698,
      "step": 1312
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.00012408333333333333,
      "loss": 2.9551,
      "step": 1313
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.000124,
      "loss": 3.132,
      "step": 1314
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.00012391666666666668,
      "loss": 3.0741,
      "step": 1315
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.00012383333333333333,
      "loss": 2.9987,
      "step": 1316
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.00012375,
      "loss": 3.0988,
      "step": 1317
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.00012366666666666667,
      "loss": 3.0277,
      "step": 1318
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.00012358333333333335,
      "loss": 3.1642,
      "step": 1319
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.00012350000000000002,
      "loss": 3.2232,
      "step": 1320
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.00012341666666666667,
      "loss": 2.9545,
      "step": 1321
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.00012333333333333334,
      "loss": 2.968,
      "step": 1322
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.00012325,
      "loss": 2.9926,
      "step": 1323
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.0001231666666666667,
      "loss": 3.1578,
      "step": 1324
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.00012308333333333333,
      "loss": 3.0148,
      "step": 1325
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.000123,
      "loss": 3.3504,
      "step": 1326
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.00012291666666666668,
      "loss": 2.9692,
      "step": 1327
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.00012283333333333333,
      "loss": 3.1179,
      "step": 1328
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.00012275,
      "loss": 3.1917,
      "step": 1329
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.00012266666666666668,
      "loss": 2.9425,
      "step": 1330
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.00012258333333333335,
      "loss": 3.3232,
      "step": 1331
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.00012250000000000002,
      "loss": 2.9612,
      "step": 1332
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.00012241666666666667,
      "loss": 3.0832,
      "step": 1333
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.00012233333333333334,
      "loss": 3.0806,
      "step": 1334
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.00012225,
      "loss": 3.1148,
      "step": 1335
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.00012216666666666666,
      "loss": 2.9413,
      "step": 1336
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.00012208333333333334,
      "loss": 3.0372,
      "step": 1337
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.000122,
      "loss": 2.9788,
      "step": 1338
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.00012191666666666668,
      "loss": 3.0243,
      "step": 1339
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.00012183333333333333,
      "loss": 3.1952,
      "step": 1340
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.00012175,
      "loss": 3.0513,
      "step": 1341
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.00012166666666666667,
      "loss": 2.9015,
      "step": 1342
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.00012158333333333334,
      "loss": 3.0072,
      "step": 1343
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.00012150000000000001,
      "loss": 2.8997,
      "step": 1344
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.00012141666666666667,
      "loss": 3.1597,
      "step": 1345
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.00012133333333333335,
      "loss": 3.1394,
      "step": 1346
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.00012124999999999999,
      "loss": 3.199,
      "step": 1347
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.00012116666666666667,
      "loss": 3.2274,
      "step": 1348
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.00012108333333333335,
      "loss": 2.8643,
      "step": 1349
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.000121,
      "loss": 3.0274,
      "step": 1350
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.00012091666666666667,
      "loss": 3.0756,
      "step": 1351
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.00012083333333333333,
      "loss": 3.0755,
      "step": 1352
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.00012075000000000001,
      "loss": 3.118,
      "step": 1353
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.00012066666666666668,
      "loss": 3.216,
      "step": 1354
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.00012058333333333334,
      "loss": 2.9958,
      "step": 1355
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.00012050000000000002,
      "loss": 3.1492,
      "step": 1356
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.00012041666666666666,
      "loss": 2.8609,
      "step": 1357
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.00012033333333333335,
      "loss": 3.2041,
      "step": 1358
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.00012025,
      "loss": 3.256,
      "step": 1359
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.00012016666666666667,
      "loss": 2.9634,
      "step": 1360
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.00012008333333333334,
      "loss": 3.1916,
      "step": 1361
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.00012,
      "loss": 2.9343,
      "step": 1362
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.00011991666666666668,
      "loss": 3.1025,
      "step": 1363
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.00011983333333333334,
      "loss": 2.9045,
      "step": 1364
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.00011975000000000001,
      "loss": 2.9744,
      "step": 1365
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.00011966666666666668,
      "loss": 2.9428,
      "step": 1366
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.00011958333333333333,
      "loss": 3.0763,
      "step": 1367
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.00011950000000000002,
      "loss": 3.0212,
      "step": 1368
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.00011941666666666666,
      "loss": 2.9828,
      "step": 1369
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.00011933333333333334,
      "loss": 3.0791,
      "step": 1370
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.00011925,
      "loss": 2.8868,
      "step": 1371
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.00011916666666666667,
      "loss": 3.3713,
      "step": 1372
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.00011908333333333335,
      "loss": 3.1583,
      "step": 1373
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.000119,
      "loss": 3.2741,
      "step": 1374
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.00011891666666666668,
      "loss": 3.1119,
      "step": 1375
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.00011883333333333333,
      "loss": 3.0522,
      "step": 1376
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.00011875,
      "loss": 3.0335,
      "step": 1377
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.00011866666666666669,
      "loss": 3.0601,
      "step": 1378
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.00011858333333333333,
      "loss": 2.7936,
      "step": 1379
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.00011850000000000001,
      "loss": 2.9719,
      "step": 1380
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.00011841666666666667,
      "loss": 3.1763,
      "step": 1381
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.00011833333333333334,
      "loss": 2.9538,
      "step": 1382
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.00011825000000000001,
      "loss": 3.0443,
      "step": 1383
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.00011816666666666667,
      "loss": 2.9197,
      "step": 1384
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.00011808333333333335,
      "loss": 3.245,
      "step": 1385
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.000118,
      "loss": 3.1615,
      "step": 1386
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.00011791666666666667,
      "loss": 3.1073,
      "step": 1387
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.00011783333333333333,
      "loss": 3.0393,
      "step": 1388
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.00011775,
      "loss": 3.2281,
      "step": 1389
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.00011766666666666668,
      "loss": 3.1997,
      "step": 1390
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.00011758333333333334,
      "loss": 3.0807,
      "step": 1391
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.00011750000000000001,
      "loss": 3.2998,
      "step": 1392
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.00011741666666666667,
      "loss": 3.2171,
      "step": 1393
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.00011733333333333334,
      "loss": 3.0374,
      "step": 1394
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.00011725000000000002,
      "loss": 3.0425,
      "step": 1395
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.00011716666666666666,
      "loss": 3.081,
      "step": 1396
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.00011708333333333335,
      "loss": 2.9897,
      "step": 1397
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.000117,
      "loss": 3.1168,
      "step": 1398
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.00011691666666666667,
      "loss": 3.2268,
      "step": 1399
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.00011683333333333333,
      "loss": 3.1416,
      "step": 1400
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.00011675,
      "loss": 3.2122,
      "step": 1401
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.00011666666666666668,
      "loss": 3.0951,
      "step": 1402
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.00011658333333333334,
      "loss": 3.0038,
      "step": 1403
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.00011650000000000001,
      "loss": 3.1369,
      "step": 1404
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.00011641666666666666,
      "loss": 2.9925,
      "step": 1405
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.00011633333333333333,
      "loss": 3.1994,
      "step": 1406
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.00011625000000000002,
      "loss": 3.1748,
      "step": 1407
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.00011616666666666667,
      "loss": 2.9535,
      "step": 1408
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.00011608333333333334,
      "loss": 3.1501,
      "step": 1409
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.000116,
      "loss": 3.0699,
      "step": 1410
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.00011591666666666667,
      "loss": 3.1725,
      "step": 1411
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.00011583333333333335,
      "loss": 3.0375,
      "step": 1412
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.00011575000000000001,
      "loss": 3.1789,
      "step": 1413
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.00011566666666666668,
      "loss": 3.1274,
      "step": 1414
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.00011558333333333333,
      "loss": 3.0081,
      "step": 1415
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.0001155,
      "loss": 3.0029,
      "step": 1416
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.00011541666666666666,
      "loss": 3.2944,
      "step": 1417
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.00011533333333333334,
      "loss": 2.9304,
      "step": 1418
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.00011525000000000001,
      "loss": 3.1023,
      "step": 1419
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.00011516666666666667,
      "loss": 2.8524,
      "step": 1420
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.00011508333333333334,
      "loss": 3.2131,
      "step": 1421
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.00011499999999999999,
      "loss": 3.0801,
      "step": 1422
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.00011491666666666668,
      "loss": 3.0256,
      "step": 1423
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.00011483333333333335,
      "loss": 2.9651,
      "step": 1424
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.00011475,
      "loss": 3.1263,
      "step": 1425
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.00011466666666666667,
      "loss": 3.1928,
      "step": 1426
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.00011458333333333333,
      "loss": 3.1636,
      "step": 1427
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.0001145,
      "loss": 2.9139,
      "step": 1428
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.00011441666666666668,
      "loss": 3.0248,
      "step": 1429
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.00011433333333333334,
      "loss": 3.295,
      "step": 1430
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.00011425000000000001,
      "loss": 2.9461,
      "step": 1431
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.00011416666666666667,
      "loss": 3.1307,
      "step": 1432
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.00011408333333333335,
      "loss": 3.0392,
      "step": 1433
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.00011399999999999999,
      "loss": 3.1335,
      "step": 1434
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.00011391666666666667,
      "loss": 3.3561,
      "step": 1435
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.00011383333333333335,
      "loss": 3.0667,
      "step": 1436
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.00011375,
      "loss": 2.7698,
      "step": 1437
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.00011366666666666667,
      "loss": 3.0215,
      "step": 1438
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.00011358333333333333,
      "loss": 3.0681,
      "step": 1439
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.00011350000000000001,
      "loss": 2.9773,
      "step": 1440
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.00011341666666666668,
      "loss": 3.0148,
      "step": 1441
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.00011333333333333334,
      "loss": 2.9116,
      "step": 1442
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.00011325000000000002,
      "loss": 3.0186,
      "step": 1443
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.00011316666666666666,
      "loss": 2.9762,
      "step": 1444
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.00011308333333333334,
      "loss": 2.9826,
      "step": 1445
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.000113,
      "loss": 3.0737,
      "step": 1446
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.00011291666666666667,
      "loss": 3.0502,
      "step": 1447
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.00011283333333333334,
      "loss": 3.1506,
      "step": 1448
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.00011275,
      "loss": 3.0755,
      "step": 1449
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.00011266666666666668,
      "loss": 3.2036,
      "step": 1450
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.00011258333333333332,
      "loss": 3.0085,
      "step": 1451
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.00011250000000000001,
      "loss": 2.9592,
      "step": 1452
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.00011241666666666668,
      "loss": 3.0456,
      "step": 1453
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.00011233333333333333,
      "loss": 3.1065,
      "step": 1454
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.00011225,
      "loss": 3.0931,
      "step": 1455
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.00011216666666666666,
      "loss": 3.1079,
      "step": 1456
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.00011208333333333334,
      "loss": 3.0708,
      "step": 1457
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.00011200000000000001,
      "loss": 3.059,
      "step": 1458
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.00011191666666666667,
      "loss": 3.0739,
      "step": 1459
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.00011183333333333335,
      "loss": 3.0312,
      "step": 1460
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.00011175,
      "loss": 2.9054,
      "step": 1461
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.00011166666666666668,
      "loss": 3.0829,
      "step": 1462
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.00011158333333333333,
      "loss": 3.056,
      "step": 1463
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.0001115,
      "loss": 3.0173,
      "step": 1464
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.00011141666666666669,
      "loss": 3.2423,
      "step": 1465
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.00011133333333333333,
      "loss": 3.0303,
      "step": 1466
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.00011125000000000001,
      "loss": 3.1514,
      "step": 1467
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.00011116666666666667,
      "loss": 2.9241,
      "step": 1468
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.00011108333333333334,
      "loss": 3.0607,
      "step": 1469
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.00011100000000000001,
      "loss": 3.2475,
      "step": 1470
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.00011091666666666667,
      "loss": 3.0121,
      "step": 1471
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.00011083333333333335,
      "loss": 2.93,
      "step": 1472
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.00011075,
      "loss": 2.8806,
      "step": 1473
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.00011066666666666667,
      "loss": 3.1259,
      "step": 1474
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.00011058333333333333,
      "loss": 3.156,
      "step": 1475
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.0001105,
      "loss": 3.2595,
      "step": 1476
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.00011041666666666668,
      "loss": 2.8922,
      "step": 1477
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.00011033333333333334,
      "loss": 3.1673,
      "step": 1478
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.00011025000000000001,
      "loss": 3.1506,
      "step": 1479
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.00011016666666666666,
      "loss": 2.9634,
      "step": 1480
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.00011008333333333334,
      "loss": 3.1,
      "step": 1481
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.00011000000000000002,
      "loss": 3.1797,
      "step": 1482
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.00010991666666666666,
      "loss": 3.0951,
      "step": 1483
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.00010983333333333334,
      "loss": 3.1907,
      "step": 1484
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00010975,
      "loss": 3.1826,
      "step": 1485
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00010966666666666667,
      "loss": 2.9011,
      "step": 1486
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00010958333333333335,
      "loss": 2.7997,
      "step": 1487
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.0001095,
      "loss": 3.0872,
      "step": 1488
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00010941666666666668,
      "loss": 3.216,
      "step": 1489
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00010933333333333333,
      "loss": 3.2214,
      "step": 1490
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00010925000000000001,
      "loss": 2.9818,
      "step": 1491
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00010916666666666666,
      "loss": 3.1159,
      "step": 1492
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00010908333333333333,
      "loss": 3.3617,
      "step": 1493
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.000109,
      "loss": 2.8687,
      "step": 1494
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.00010891666666666667,
      "loss": 2.7681,
      "step": 1495
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.00010883333333333334,
      "loss": 3.1526,
      "step": 1496
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.00010875,
      "loss": 3.2638,
      "step": 1497
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.00010866666666666667,
      "loss": 2.9007,
      "step": 1498
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.00010858333333333335,
      "loss": 2.8726,
      "step": 1499
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.00010850000000000001,
      "loss": 3.0822,
      "step": 1500
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.00010841666666666668,
      "loss": 3.1747,
      "step": 1501
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.00010833333333333333,
      "loss": 2.9231,
      "step": 1502
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.00010825,
      "loss": 3.0517,
      "step": 1503
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.00010816666666666669,
      "loss": 3.2206,
      "step": 1504
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.00010808333333333334,
      "loss": 2.9267,
      "step": 1505
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.00010800000000000001,
      "loss": 3.1899,
      "step": 1506
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.00010791666666666667,
      "loss": 3.1319,
      "step": 1507
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.00010783333333333334,
      "loss": 3.2811,
      "step": 1508
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.00010774999999999999,
      "loss": 3.1519,
      "step": 1509
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.00010766666666666668,
      "loss": 3.2951,
      "step": 1510
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.00010758333333333335,
      "loss": 3.252,
      "step": 1511
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.0001075,
      "loss": 2.7919,
      "step": 1512
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.00010741666666666667,
      "loss": 2.9093,
      "step": 1513
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.00010733333333333333,
      "loss": 3.0625,
      "step": 1514
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.00010725,
      "loss": 2.9152,
      "step": 1515
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.00010716666666666668,
      "loss": 3.077,
      "step": 1516
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.00010708333333333334,
      "loss": 2.8434,
      "step": 1517
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.00010700000000000001,
      "loss": 2.8257,
      "step": 1518
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.00010691666666666666,
      "loss": 2.8077,
      "step": 1519
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.00010683333333333335,
      "loss": 3.2056,
      "step": 1520
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.00010674999999999999,
      "loss": 3.0253,
      "step": 1521
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.00010666666666666667,
      "loss": 2.9187,
      "step": 1522
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.00010658333333333334,
      "loss": 3.2655,
      "step": 1523
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.0001065,
      "loss": 3.0879,
      "step": 1524
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.00010641666666666667,
      "loss": 3.1359,
      "step": 1525
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.00010633333333333333,
      "loss": 3.2006,
      "step": 1526
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.00010625000000000001,
      "loss": 3.2645,
      "step": 1527
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.00010616666666666668,
      "loss": 3.125,
      "step": 1528
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.00010608333333333333,
      "loss": 2.9552,
      "step": 1529
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.00010600000000000002,
      "loss": 3.075,
      "step": 1530
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.00010591666666666666,
      "loss": 3.1792,
      "step": 1531
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.00010583333333333334,
      "loss": 3.1753,
      "step": 1532
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.00010575000000000001,
      "loss": 3.007,
      "step": 1533
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.00010566666666666667,
      "loss": 3.1309,
      "step": 1534
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.00010558333333333334,
      "loss": 2.863,
      "step": 1535
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.0001055,
      "loss": 2.9718,
      "step": 1536
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.00010541666666666668,
      "loss": 3.1656,
      "step": 1537
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.00010533333333333332,
      "loss": 3.043,
      "step": 1538
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.00010525000000000001,
      "loss": 2.8954,
      "step": 1539
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00010516666666666668,
      "loss": 3.2106,
      "step": 1540
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00010508333333333333,
      "loss": 3.1563,
      "step": 1541
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.000105,
      "loss": 2.9309,
      "step": 1542
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00010491666666666666,
      "loss": 3.2508,
      "step": 1543
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00010483333333333334,
      "loss": 3.0063,
      "step": 1544
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00010475000000000001,
      "loss": 3.1419,
      "step": 1545
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00010466666666666667,
      "loss": 3.072,
      "step": 1546
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00010458333333333335,
      "loss": 3.0622,
      "step": 1547
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00010449999999999999,
      "loss": 3.0149,
      "step": 1548
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00010441666666666668,
      "loss": 3.0455,
      "step": 1549
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00010433333333333333,
      "loss": 3.0841,
      "step": 1550
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00010425,
      "loss": 2.9962,
      "step": 1551
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00010416666666666667,
      "loss": 3.1322,
      "step": 1552
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00010408333333333333,
      "loss": 2.7443,
      "step": 1553
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00010400000000000001,
      "loss": 3.077,
      "step": 1554
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00010391666666666667,
      "loss": 3.1444,
      "step": 1555
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00010383333333333334,
      "loss": 2.9605,
      "step": 1556
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00010375000000000001,
      "loss": 3.0512,
      "step": 1557
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.00010366666666666666,
      "loss": 3.2351,
      "step": 1558
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.00010358333333333335,
      "loss": 3.0765,
      "step": 1559
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.0001035,
      "loss": 3.1378,
      "step": 1560
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.00010341666666666667,
      "loss": 3.1459,
      "step": 1561
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.00010333333333333334,
      "loss": 3.2418,
      "step": 1562
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.00010325,
      "loss": 2.9996,
      "step": 1563
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.00010316666666666668,
      "loss": 2.9962,
      "step": 1564
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.00010308333333333334,
      "loss": 3.1793,
      "step": 1565
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.00010300000000000001,
      "loss": 2.9638,
      "step": 1566
    },
    {
      "epoch": 1.73,
      "learning_rate": 0.00010291666666666666,
      "loss": 3.1517,
      "step": 1567
    },
    {
      "epoch": 1.73,
      "learning_rate": 0.00010283333333333334,
      "loss": 3.1048,
      "step": 1568
    },
    {
      "epoch": 1.73,
      "learning_rate": 0.00010275000000000002,
      "loss": 3.2085,
      "step": 1569
    },
    {
      "epoch": 1.73,
      "learning_rate": 0.00010266666666666666,
      "loss": 3.0769,
      "step": 1570
    },
    {
      "epoch": 1.73,
      "learning_rate": 0.00010258333333333334,
      "loss": 3.0395,
      "step": 1571
    },
    {
      "epoch": 1.73,
      "learning_rate": 0.0001025,
      "loss": 3.1866,
      "step": 1572
    },
    {
      "epoch": 1.73,
      "learning_rate": 0.00010241666666666667,
      "loss": 2.8468,
      "step": 1573
    },
    {
      "epoch": 1.73,
      "learning_rate": 0.00010233333333333335,
      "loss": 3.135,
      "step": 1574
    },
    {
      "epoch": 1.73,
      "learning_rate": 0.00010225,
      "loss": 3.0262,
      "step": 1575
    },
    {
      "epoch": 1.74,
      "learning_rate": 0.00010216666666666668,
      "loss": 3.3148,
      "step": 1576
    },
    {
      "epoch": 1.74,
      "learning_rate": 0.00010208333333333333,
      "loss": 3.0925,
      "step": 1577
    },
    {
      "epoch": 1.74,
      "learning_rate": 0.00010200000000000001,
      "loss": 3.2323,
      "step": 1578
    },
    {
      "epoch": 1.74,
      "learning_rate": 0.00010191666666666669,
      "loss": 3.1303,
      "step": 1579
    },
    {
      "epoch": 1.74,
      "learning_rate": 0.00010183333333333333,
      "loss": 3.1653,
      "step": 1580
    },
    {
      "epoch": 1.74,
      "learning_rate": 0.00010175,
      "loss": 3.0742,
      "step": 1581
    },
    {
      "epoch": 1.74,
      "learning_rate": 0.00010166666666666667,
      "loss": 3.1351,
      "step": 1582
    },
    {
      "epoch": 1.74,
      "learning_rate": 0.00010158333333333334,
      "loss": 3.1869,
      "step": 1583
    },
    {
      "epoch": 1.74,
      "learning_rate": 0.0001015,
      "loss": 2.9347,
      "step": 1584
    },
    {
      "epoch": 1.75,
      "learning_rate": 0.00010141666666666667,
      "loss": 3.0059,
      "step": 1585
    },
    {
      "epoch": 1.75,
      "learning_rate": 0.00010133333333333335,
      "loss": 3.0761,
      "step": 1586
    },
    {
      "epoch": 1.75,
      "learning_rate": 0.00010125,
      "loss": 3.1468,
      "step": 1587
    },
    {
      "epoch": 1.75,
      "learning_rate": 0.00010116666666666668,
      "loss": 3.3545,
      "step": 1588
    },
    {
      "epoch": 1.75,
      "learning_rate": 0.00010108333333333333,
      "loss": 3.1865,
      "step": 1589
    },
    {
      "epoch": 1.75,
      "learning_rate": 0.000101,
      "loss": 3.0357,
      "step": 1590
    },
    {
      "epoch": 1.75,
      "learning_rate": 0.00010091666666666668,
      "loss": 3.1811,
      "step": 1591
    },
    {
      "epoch": 1.75,
      "learning_rate": 0.00010083333333333334,
      "loss": 3.0286,
      "step": 1592
    },
    {
      "epoch": 1.75,
      "learning_rate": 0.00010075000000000001,
      "loss": 3.2735,
      "step": 1593
    },
    {
      "epoch": 1.76,
      "learning_rate": 0.00010066666666666667,
      "loss": 3.0649,
      "step": 1594
    },
    {
      "epoch": 1.76,
      "learning_rate": 0.00010058333333333334,
      "loss": 2.6653,
      "step": 1595
    },
    {
      "epoch": 1.76,
      "learning_rate": 0.00010049999999999999,
      "loss": 3.2536,
      "step": 1596
    },
    {
      "epoch": 1.76,
      "learning_rate": 0.00010041666666666666,
      "loss": 2.9989,
      "step": 1597
    },
    {
      "epoch": 1.76,
      "learning_rate": 0.00010033333333333335,
      "loss": 2.9456,
      "step": 1598
    },
    {
      "epoch": 1.76,
      "learning_rate": 0.00010025,
      "loss": 3.1304,
      "step": 1599
    },
    {
      "epoch": 1.76,
      "learning_rate": 0.00010016666666666667,
      "loss": 3.186,
      "step": 1600
    },
    {
      "epoch": 1.76,
      "learning_rate": 0.00010008333333333333,
      "loss": 3.0889,
      "step": 1601
    },
    {
      "epoch": 1.76,
      "learning_rate": 0.0001,
      "loss": 3.1598,
      "step": 1602
    },
    {
      "epoch": 1.77,
      "learning_rate": 9.991666666666666e-05,
      "loss": 3.1245,
      "step": 1603
    },
    {
      "epoch": 1.77,
      "learning_rate": 9.983333333333334e-05,
      "loss": 3.2068,
      "step": 1604
    },
    {
      "epoch": 1.77,
      "learning_rate": 9.975000000000001e-05,
      "loss": 2.95,
      "step": 1605
    },
    {
      "epoch": 1.77,
      "learning_rate": 9.966666666666667e-05,
      "loss": 3.0941,
      "step": 1606
    },
    {
      "epoch": 1.77,
      "learning_rate": 9.958333333333335e-05,
      "loss": 2.9638,
      "step": 1607
    },
    {
      "epoch": 1.77,
      "learning_rate": 9.95e-05,
      "loss": 3.0654,
      "step": 1608
    },
    {
      "epoch": 1.77,
      "learning_rate": 9.941666666666667e-05,
      "loss": 3.0082,
      "step": 1609
    },
    {
      "epoch": 1.77,
      "learning_rate": 9.933333333333334e-05,
      "loss": 3.0076,
      "step": 1610
    },
    {
      "epoch": 1.77,
      "learning_rate": 9.925000000000001e-05,
      "loss": 3.1228,
      "step": 1611
    },
    {
      "epoch": 1.78,
      "learning_rate": 9.916666666666667e-05,
      "loss": 2.9779,
      "step": 1612
    },
    {
      "epoch": 1.78,
      "learning_rate": 9.908333333333333e-05,
      "loss": 3.0828,
      "step": 1613
    },
    {
      "epoch": 1.78,
      "learning_rate": 9.900000000000001e-05,
      "loss": 2.8357,
      "step": 1614
    },
    {
      "epoch": 1.78,
      "learning_rate": 9.891666666666667e-05,
      "loss": 3.0978,
      "step": 1615
    },
    {
      "epoch": 1.78,
      "learning_rate": 9.883333333333333e-05,
      "loss": 3.2994,
      "step": 1616
    },
    {
      "epoch": 1.78,
      "learning_rate": 9.875000000000002e-05,
      "loss": 3.1206,
      "step": 1617
    },
    {
      "epoch": 1.78,
      "learning_rate": 9.866666666666668e-05,
      "loss": 3.029,
      "step": 1618
    },
    {
      "epoch": 1.78,
      "learning_rate": 9.858333333333334e-05,
      "loss": 3.0836,
      "step": 1619
    },
    {
      "epoch": 1.78,
      "learning_rate": 9.850000000000001e-05,
      "loss": 3.2623,
      "step": 1620
    },
    {
      "epoch": 1.79,
      "learning_rate": 9.841666666666667e-05,
      "loss": 3.1484,
      "step": 1621
    },
    {
      "epoch": 1.79,
      "learning_rate": 9.833333333333333e-05,
      "loss": 3.2091,
      "step": 1622
    },
    {
      "epoch": 1.79,
      "learning_rate": 9.825e-05,
      "loss": 3.0498,
      "step": 1623
    },
    {
      "epoch": 1.79,
      "learning_rate": 9.816666666666668e-05,
      "loss": 3.2369,
      "step": 1624
    },
    {
      "epoch": 1.79,
      "learning_rate": 9.808333333333334e-05,
      "loss": 3.1724,
      "step": 1625
    },
    {
      "epoch": 1.79,
      "learning_rate": 9.8e-05,
      "loss": 2.9858,
      "step": 1626
    },
    {
      "epoch": 1.79,
      "learning_rate": 9.791666666666667e-05,
      "loss": 3.1002,
      "step": 1627
    },
    {
      "epoch": 1.79,
      "learning_rate": 9.783333333333334e-05,
      "loss": 3.164,
      "step": 1628
    },
    {
      "epoch": 1.79,
      "learning_rate": 9.775e-05,
      "loss": 2.9412,
      "step": 1629
    },
    {
      "epoch": 1.8,
      "learning_rate": 9.766666666666668e-05,
      "loss": 3.0642,
      "step": 1630
    },
    {
      "epoch": 1.8,
      "learning_rate": 9.758333333333334e-05,
      "loss": 2.9549,
      "step": 1631
    },
    {
      "epoch": 1.8,
      "learning_rate": 9.75e-05,
      "loss": 3.2169,
      "step": 1632
    },
    {
      "epoch": 1.8,
      "learning_rate": 9.741666666666667e-05,
      "loss": 3.0361,
      "step": 1633
    },
    {
      "epoch": 1.8,
      "learning_rate": 9.733333333333335e-05,
      "loss": 2.8774,
      "step": 1634
    },
    {
      "epoch": 1.8,
      "learning_rate": 9.725e-05,
      "loss": 3.0569,
      "step": 1635
    },
    {
      "epoch": 1.8,
      "learning_rate": 9.716666666666667e-05,
      "loss": 3.0239,
      "step": 1636
    },
    {
      "epoch": 1.8,
      "learning_rate": 9.708333333333334e-05,
      "loss": 3.1745,
      "step": 1637
    },
    {
      "epoch": 1.8,
      "learning_rate": 9.7e-05,
      "loss": 3.122,
      "step": 1638
    },
    {
      "epoch": 1.81,
      "learning_rate": 9.691666666666667e-05,
      "loss": 3.1936,
      "step": 1639
    },
    {
      "epoch": 1.81,
      "learning_rate": 9.683333333333335e-05,
      "loss": 3.0117,
      "step": 1640
    },
    {
      "epoch": 1.81,
      "learning_rate": 9.675000000000001e-05,
      "loss": 3.0609,
      "step": 1641
    },
    {
      "epoch": 1.81,
      "learning_rate": 9.666666666666667e-05,
      "loss": 3.173,
      "step": 1642
    },
    {
      "epoch": 1.81,
      "learning_rate": 9.658333333333334e-05,
      "loss": 2.891,
      "step": 1643
    },
    {
      "epoch": 1.81,
      "learning_rate": 9.65e-05,
      "loss": 3.0555,
      "step": 1644
    },
    {
      "epoch": 1.81,
      "learning_rate": 9.641666666666666e-05,
      "loss": 3.3439,
      "step": 1645
    },
    {
      "epoch": 1.81,
      "learning_rate": 9.633333333333335e-05,
      "loss": 2.9333,
      "step": 1646
    },
    {
      "epoch": 1.81,
      "learning_rate": 9.625000000000001e-05,
      "loss": 3.0701,
      "step": 1647
    },
    {
      "epoch": 1.81,
      "learning_rate": 9.616666666666667e-05,
      "loss": 2.8768,
      "step": 1648
    },
    {
      "epoch": 1.82,
      "learning_rate": 9.608333333333334e-05,
      "loss": 3.175,
      "step": 1649
    },
    {
      "epoch": 1.82,
      "learning_rate": 9.6e-05,
      "loss": 3.015,
      "step": 1650
    },
    {
      "epoch": 1.82,
      "learning_rate": 9.591666666666666e-05,
      "loss": 2.9156,
      "step": 1651
    },
    {
      "epoch": 1.82,
      "learning_rate": 9.583333333333334e-05,
      "loss": 3.131,
      "step": 1652
    },
    {
      "epoch": 1.82,
      "learning_rate": 9.575000000000001e-05,
      "loss": 3.1369,
      "step": 1653
    },
    {
      "epoch": 1.82,
      "learning_rate": 9.566666666666667e-05,
      "loss": 2.9864,
      "step": 1654
    },
    {
      "epoch": 1.82,
      "learning_rate": 9.558333333333333e-05,
      "loss": 3.0336,
      "step": 1655
    },
    {
      "epoch": 1.82,
      "learning_rate": 9.55e-05,
      "loss": 2.9451,
      "step": 1656
    },
    {
      "epoch": 1.82,
      "learning_rate": 9.541666666666668e-05,
      "loss": 2.96,
      "step": 1657
    },
    {
      "epoch": 1.83,
      "learning_rate": 9.533333333333334e-05,
      "loss": 3.0835,
      "step": 1658
    },
    {
      "epoch": 1.83,
      "learning_rate": 9.525000000000001e-05,
      "loss": 3.0339,
      "step": 1659
    },
    {
      "epoch": 1.83,
      "learning_rate": 9.516666666666667e-05,
      "loss": 3.0733,
      "step": 1660
    },
    {
      "epoch": 1.83,
      "learning_rate": 9.508333333333333e-05,
      "loss": 3.5032,
      "step": 1661
    },
    {
      "epoch": 1.83,
      "learning_rate": 9.5e-05,
      "loss": 3.1548,
      "step": 1662
    },
    {
      "epoch": 1.83,
      "learning_rate": 9.491666666666668e-05,
      "loss": 3.2212,
      "step": 1663
    },
    {
      "epoch": 1.83,
      "learning_rate": 9.483333333333334e-05,
      "loss": 2.9273,
      "step": 1664
    },
    {
      "epoch": 1.83,
      "learning_rate": 9.475e-05,
      "loss": 3.2816,
      "step": 1665
    },
    {
      "epoch": 1.83,
      "learning_rate": 9.466666666666667e-05,
      "loss": 3.0073,
      "step": 1666
    },
    {
      "epoch": 1.84,
      "learning_rate": 9.458333333333333e-05,
      "loss": 3.0945,
      "step": 1667
    },
    {
      "epoch": 1.84,
      "learning_rate": 9.449999999999999e-05,
      "loss": 3.2494,
      "step": 1668
    },
    {
      "epoch": 1.84,
      "learning_rate": 9.441666666666668e-05,
      "loss": 3.3279,
      "step": 1669
    },
    {
      "epoch": 1.84,
      "learning_rate": 9.433333333333334e-05,
      "loss": 3.1444,
      "step": 1670
    },
    {
      "epoch": 1.84,
      "learning_rate": 9.425e-05,
      "loss": 3.1739,
      "step": 1671
    },
    {
      "epoch": 1.84,
      "learning_rate": 9.416666666666667e-05,
      "loss": 3.015,
      "step": 1672
    },
    {
      "epoch": 1.84,
      "learning_rate": 9.408333333333333e-05,
      "loss": 3.1144,
      "step": 1673
    },
    {
      "epoch": 1.84,
      "learning_rate": 9.4e-05,
      "loss": 3.0439,
      "step": 1674
    },
    {
      "epoch": 1.84,
      "learning_rate": 9.391666666666668e-05,
      "loss": 3.2138,
      "step": 1675
    },
    {
      "epoch": 1.85,
      "learning_rate": 9.383333333333334e-05,
      "loss": 3.0343,
      "step": 1676
    },
    {
      "epoch": 1.85,
      "learning_rate": 9.375e-05,
      "loss": 2.9741,
      "step": 1677
    },
    {
      "epoch": 1.85,
      "learning_rate": 9.366666666666668e-05,
      "loss": 3.1651,
      "step": 1678
    },
    {
      "epoch": 1.85,
      "learning_rate": 9.358333333333334e-05,
      "loss": 3.0634,
      "step": 1679
    },
    {
      "epoch": 1.85,
      "learning_rate": 9.350000000000001e-05,
      "loss": 2.8628,
      "step": 1680
    },
    {
      "epoch": 1.85,
      "learning_rate": 9.341666666666667e-05,
      "loss": 2.8972,
      "step": 1681
    },
    {
      "epoch": 1.85,
      "learning_rate": 9.333333333333334e-05,
      "loss": 2.8687,
      "step": 1682
    },
    {
      "epoch": 1.85,
      "learning_rate": 9.325e-05,
      "loss": 2.882,
      "step": 1683
    },
    {
      "epoch": 1.85,
      "learning_rate": 9.316666666666666e-05,
      "loss": 3.1022,
      "step": 1684
    },
    {
      "epoch": 1.86,
      "learning_rate": 9.308333333333334e-05,
      "loss": 2.9977,
      "step": 1685
    },
    {
      "epoch": 1.86,
      "learning_rate": 9.300000000000001e-05,
      "loss": 3.1458,
      "step": 1686
    },
    {
      "epoch": 1.86,
      "learning_rate": 9.291666666666667e-05,
      "loss": 3.2148,
      "step": 1687
    },
    {
      "epoch": 1.86,
      "learning_rate": 9.283333333333334e-05,
      "loss": 3.0942,
      "step": 1688
    },
    {
      "epoch": 1.86,
      "learning_rate": 9.275e-05,
      "loss": 3.1542,
      "step": 1689
    },
    {
      "epoch": 1.86,
      "learning_rate": 9.266666666666666e-05,
      "loss": 2.9396,
      "step": 1690
    },
    {
      "epoch": 1.86,
      "learning_rate": 9.258333333333334e-05,
      "loss": 3.2311,
      "step": 1691
    },
    {
      "epoch": 1.86,
      "learning_rate": 9.250000000000001e-05,
      "loss": 2.9852,
      "step": 1692
    },
    {
      "epoch": 1.86,
      "learning_rate": 9.241666666666667e-05,
      "loss": 2.9114,
      "step": 1693
    },
    {
      "epoch": 1.87,
      "learning_rate": 9.233333333333333e-05,
      "loss": 3.0439,
      "step": 1694
    },
    {
      "epoch": 1.87,
      "learning_rate": 9.225e-05,
      "loss": 3.1678,
      "step": 1695
    },
    {
      "epoch": 1.87,
      "learning_rate": 9.216666666666667e-05,
      "loss": 3.136,
      "step": 1696
    },
    {
      "epoch": 1.87,
      "learning_rate": 9.208333333333333e-05,
      "loss": 3.0629,
      "step": 1697
    },
    {
      "epoch": 1.87,
      "learning_rate": 9.200000000000001e-05,
      "loss": 2.9873,
      "step": 1698
    },
    {
      "epoch": 1.87,
      "learning_rate": 9.191666666666667e-05,
      "loss": 3.0231,
      "step": 1699
    },
    {
      "epoch": 1.87,
      "learning_rate": 9.183333333333333e-05,
      "loss": 2.984,
      "step": 1700
    },
    {
      "epoch": 1.87,
      "learning_rate": 9.175000000000001e-05,
      "loss": 3.0004,
      "step": 1701
    },
    {
      "epoch": 1.87,
      "learning_rate": 9.166666666666667e-05,
      "loss": 2.9063,
      "step": 1702
    },
    {
      "epoch": 1.88,
      "learning_rate": 9.158333333333334e-05,
      "loss": 3.0652,
      "step": 1703
    },
    {
      "epoch": 1.88,
      "learning_rate": 9.15e-05,
      "loss": 3.3102,
      "step": 1704
    },
    {
      "epoch": 1.88,
      "learning_rate": 9.141666666666668e-05,
      "loss": 3.1614,
      "step": 1705
    },
    {
      "epoch": 1.88,
      "learning_rate": 9.133333333333334e-05,
      "loss": 3.2341,
      "step": 1706
    },
    {
      "epoch": 1.88,
      "learning_rate": 9.125e-05,
      "loss": 3.0464,
      "step": 1707
    },
    {
      "epoch": 1.88,
      "learning_rate": 9.116666666666667e-05,
      "loss": 3.1518,
      "step": 1708
    },
    {
      "epoch": 1.88,
      "learning_rate": 9.108333333333334e-05,
      "loss": 3.1404,
      "step": 1709
    },
    {
      "epoch": 1.88,
      "learning_rate": 9.1e-05,
      "loss": 3.0291,
      "step": 1710
    },
    {
      "epoch": 1.88,
      "learning_rate": 9.091666666666668e-05,
      "loss": 3.0216,
      "step": 1711
    },
    {
      "epoch": 1.89,
      "learning_rate": 9.083333333333334e-05,
      "loss": 3.192,
      "step": 1712
    },
    {
      "epoch": 1.89,
      "learning_rate": 9.075e-05,
      "loss": 3.122,
      "step": 1713
    },
    {
      "epoch": 1.89,
      "learning_rate": 9.066666666666667e-05,
      "loss": 2.978,
      "step": 1714
    },
    {
      "epoch": 1.89,
      "learning_rate": 9.058333333333334e-05,
      "loss": 3.1559,
      "step": 1715
    },
    {
      "epoch": 1.89,
      "learning_rate": 9.05e-05,
      "loss": 3.04,
      "step": 1716
    },
    {
      "epoch": 1.89,
      "learning_rate": 9.041666666666668e-05,
      "loss": 2.92,
      "step": 1717
    },
    {
      "epoch": 1.89,
      "learning_rate": 9.033333333333334e-05,
      "loss": 2.8856,
      "step": 1718
    },
    {
      "epoch": 1.89,
      "learning_rate": 9.025e-05,
      "loss": 3.0905,
      "step": 1719
    },
    {
      "epoch": 1.89,
      "learning_rate": 9.016666666666667e-05,
      "loss": 3.101,
      "step": 1720
    },
    {
      "epoch": 1.9,
      "learning_rate": 9.008333333333335e-05,
      "loss": 2.995,
      "step": 1721
    },
    {
      "epoch": 1.9,
      "learning_rate": 9e-05,
      "loss": 3.227,
      "step": 1722
    },
    {
      "epoch": 1.9,
      "learning_rate": 8.991666666666667e-05,
      "loss": 3.0468,
      "step": 1723
    },
    {
      "epoch": 1.9,
      "learning_rate": 8.983333333333334e-05,
      "loss": 3.1006,
      "step": 1724
    },
    {
      "epoch": 1.9,
      "learning_rate": 8.975e-05,
      "loss": 3.0106,
      "step": 1725
    },
    {
      "epoch": 1.9,
      "learning_rate": 8.966666666666666e-05,
      "loss": 3.1179,
      "step": 1726
    },
    {
      "epoch": 1.9,
      "learning_rate": 8.958333333333335e-05,
      "loss": 2.8132,
      "step": 1727
    },
    {
      "epoch": 1.9,
      "learning_rate": 8.950000000000001e-05,
      "loss": 3.0475,
      "step": 1728
    },
    {
      "epoch": 1.9,
      "learning_rate": 8.941666666666667e-05,
      "loss": 3.0288,
      "step": 1729
    },
    {
      "epoch": 1.91,
      "learning_rate": 8.933333333333334e-05,
      "loss": 2.9194,
      "step": 1730
    },
    {
      "epoch": 1.91,
      "learning_rate": 8.925e-05,
      "loss": 3.0273,
      "step": 1731
    },
    {
      "epoch": 1.91,
      "learning_rate": 8.916666666666667e-05,
      "loss": 3.2342,
      "step": 1732
    },
    {
      "epoch": 1.91,
      "learning_rate": 8.908333333333333e-05,
      "loss": 2.9547,
      "step": 1733
    },
    {
      "epoch": 1.91,
      "learning_rate": 8.900000000000001e-05,
      "loss": 2.9091,
      "step": 1734
    },
    {
      "epoch": 1.91,
      "learning_rate": 8.891666666666667e-05,
      "loss": 2.9403,
      "step": 1735
    },
    {
      "epoch": 1.91,
      "learning_rate": 8.883333333333333e-05,
      "loss": 3.1024,
      "step": 1736
    },
    {
      "epoch": 1.91,
      "learning_rate": 8.875e-05,
      "loss": 3.2668,
      "step": 1737
    },
    {
      "epoch": 1.91,
      "learning_rate": 8.866666666666668e-05,
      "loss": 3.1565,
      "step": 1738
    },
    {
      "epoch": 1.92,
      "learning_rate": 8.858333333333334e-05,
      "loss": 3.0317,
      "step": 1739
    },
    {
      "epoch": 1.92,
      "learning_rate": 8.850000000000001e-05,
      "loss": 3.1001,
      "step": 1740
    },
    {
      "epoch": 1.92,
      "learning_rate": 8.841666666666667e-05,
      "loss": 3.1209,
      "step": 1741
    },
    {
      "epoch": 1.92,
      "learning_rate": 8.833333333333333e-05,
      "loss": 3.142,
      "step": 1742
    },
    {
      "epoch": 1.92,
      "learning_rate": 8.825e-05,
      "loss": 2.8756,
      "step": 1743
    },
    {
      "epoch": 1.92,
      "learning_rate": 8.816666666666668e-05,
      "loss": 2.7045,
      "step": 1744
    },
    {
      "epoch": 1.92,
      "learning_rate": 8.808333333333334e-05,
      "loss": 3.1226,
      "step": 1745
    },
    {
      "epoch": 1.92,
      "learning_rate": 8.800000000000001e-05,
      "loss": 3.1153,
      "step": 1746
    },
    {
      "epoch": 1.92,
      "learning_rate": 8.791666666666667e-05,
      "loss": 3.2007,
      "step": 1747
    },
    {
      "epoch": 1.93,
      "learning_rate": 8.783333333333333e-05,
      "loss": 3.1577,
      "step": 1748
    },
    {
      "epoch": 1.93,
      "learning_rate": 8.775e-05,
      "loss": 2.8019,
      "step": 1749
    },
    {
      "epoch": 1.93,
      "learning_rate": 8.766666666666668e-05,
      "loss": 2.9876,
      "step": 1750
    },
    {
      "epoch": 1.93,
      "learning_rate": 8.758333333333334e-05,
      "loss": 3.0929,
      "step": 1751
    },
    {
      "epoch": 1.93,
      "learning_rate": 8.75e-05,
      "loss": 2.905,
      "step": 1752
    },
    {
      "epoch": 1.93,
      "learning_rate": 8.741666666666667e-05,
      "loss": 3.2341,
      "step": 1753
    },
    {
      "epoch": 1.93,
      "learning_rate": 8.733333333333333e-05,
      "loss": 2.9979,
      "step": 1754
    },
    {
      "epoch": 1.93,
      "learning_rate": 8.725e-05,
      "loss": 3.0158,
      "step": 1755
    },
    {
      "epoch": 1.93,
      "learning_rate": 8.716666666666668e-05,
      "loss": 3.1812,
      "step": 1756
    },
    {
      "epoch": 1.94,
      "learning_rate": 8.708333333333334e-05,
      "loss": 3.1916,
      "step": 1757
    },
    {
      "epoch": 1.94,
      "learning_rate": 8.7e-05,
      "loss": 3.0768,
      "step": 1758
    },
    {
      "epoch": 1.94,
      "learning_rate": 8.691666666666667e-05,
      "loss": 3.117,
      "step": 1759
    },
    {
      "epoch": 1.94,
      "learning_rate": 8.683333333333333e-05,
      "loss": 3.0173,
      "step": 1760
    },
    {
      "epoch": 1.94,
      "learning_rate": 8.675000000000001e-05,
      "loss": 3.0227,
      "step": 1761
    },
    {
      "epoch": 1.94,
      "learning_rate": 8.666666666666667e-05,
      "loss": 3.0148,
      "step": 1762
    },
    {
      "epoch": 1.94,
      "learning_rate": 8.658333333333334e-05,
      "loss": 3.1628,
      "step": 1763
    },
    {
      "epoch": 1.94,
      "learning_rate": 8.65e-05,
      "loss": 3.142,
      "step": 1764
    },
    {
      "epoch": 1.94,
      "learning_rate": 8.641666666666666e-05,
      "loss": 3.1864,
      "step": 1765
    },
    {
      "epoch": 1.94,
      "learning_rate": 8.633333333333334e-05,
      "loss": 2.8672,
      "step": 1766
    },
    {
      "epoch": 1.95,
      "learning_rate": 8.625000000000001e-05,
      "loss": 3.0529,
      "step": 1767
    },
    {
      "epoch": 1.95,
      "learning_rate": 8.616666666666667e-05,
      "loss": 3.2233,
      "step": 1768
    },
    {
      "epoch": 1.95,
      "learning_rate": 8.608333333333334e-05,
      "loss": 2.7076,
      "step": 1769
    },
    {
      "epoch": 1.95,
      "learning_rate": 8.6e-05,
      "loss": 3.116,
      "step": 1770
    },
    {
      "epoch": 1.95,
      "learning_rate": 8.591666666666666e-05,
      "loss": 3.2314,
      "step": 1771
    },
    {
      "epoch": 1.95,
      "learning_rate": 8.583333333333334e-05,
      "loss": 3.113,
      "step": 1772
    },
    {
      "epoch": 1.95,
      "learning_rate": 8.575000000000001e-05,
      "loss": 3.1616,
      "step": 1773
    },
    {
      "epoch": 1.95,
      "learning_rate": 8.566666666666667e-05,
      "loss": 2.7166,
      "step": 1774
    },
    {
      "epoch": 1.95,
      "learning_rate": 8.558333333333333e-05,
      "loss": 2.7468,
      "step": 1775
    },
    {
      "epoch": 1.96,
      "learning_rate": 8.55e-05,
      "loss": 3.2648,
      "step": 1776
    },
    {
      "epoch": 1.96,
      "learning_rate": 8.541666666666666e-05,
      "loss": 3.0003,
      "step": 1777
    },
    {
      "epoch": 1.96,
      "learning_rate": 8.533333333333334e-05,
      "loss": 3.059,
      "step": 1778
    },
    {
      "epoch": 1.96,
      "learning_rate": 8.525000000000001e-05,
      "loss": 3.232,
      "step": 1779
    },
    {
      "epoch": 1.96,
      "learning_rate": 8.516666666666667e-05,
      "loss": 3.2013,
      "step": 1780
    },
    {
      "epoch": 1.96,
      "learning_rate": 8.508333333333333e-05,
      "loss": 3.3304,
      "step": 1781
    },
    {
      "epoch": 1.96,
      "learning_rate": 8.5e-05,
      "loss": 3.1892,
      "step": 1782
    },
    {
      "epoch": 1.96,
      "learning_rate": 8.491666666666667e-05,
      "loss": 2.9926,
      "step": 1783
    },
    {
      "epoch": 1.96,
      "learning_rate": 8.483333333333334e-05,
      "loss": 2.9201,
      "step": 1784
    },
    {
      "epoch": 1.97,
      "learning_rate": 8.475000000000001e-05,
      "loss": 3.1996,
      "step": 1785
    },
    {
      "epoch": 1.97,
      "learning_rate": 8.466666666666667e-05,
      "loss": 3.003,
      "step": 1786
    },
    {
      "epoch": 1.97,
      "learning_rate": 8.458333333333333e-05,
      "loss": 3.0512,
      "step": 1787
    },
    {
      "epoch": 1.97,
      "learning_rate": 8.450000000000001e-05,
      "loss": 3.3557,
      "step": 1788
    },
    {
      "epoch": 1.97,
      "learning_rate": 8.441666666666667e-05,
      "loss": 2.8929,
      "step": 1789
    },
    {
      "epoch": 1.97,
      "learning_rate": 8.433333333333334e-05,
      "loss": 3.0686,
      "step": 1790
    },
    {
      "epoch": 1.97,
      "learning_rate": 8.425e-05,
      "loss": 3.1754,
      "step": 1791
    },
    {
      "epoch": 1.97,
      "learning_rate": 8.416666666666668e-05,
      "loss": 3.2468,
      "step": 1792
    },
    {
      "epoch": 1.97,
      "learning_rate": 8.408333333333334e-05,
      "loss": 2.9527,
      "step": 1793
    },
    {
      "epoch": 1.98,
      "learning_rate": 8.4e-05,
      "loss": 3.1575,
      "step": 1794
    },
    {
      "epoch": 1.98,
      "learning_rate": 8.391666666666667e-05,
      "loss": 2.8402,
      "step": 1795
    },
    {
      "epoch": 1.98,
      "learning_rate": 8.383333333333334e-05,
      "loss": 3.2208,
      "step": 1796
    },
    {
      "epoch": 1.98,
      "learning_rate": 8.375e-05,
      "loss": 3.0402,
      "step": 1797
    },
    {
      "epoch": 1.98,
      "learning_rate": 8.366666666666668e-05,
      "loss": 3.1212,
      "step": 1798
    },
    {
      "epoch": 1.98,
      "learning_rate": 8.358333333333334e-05,
      "loss": 2.7903,
      "step": 1799
    },
    {
      "epoch": 1.98,
      "learning_rate": 8.35e-05,
      "loss": 3.1224,
      "step": 1800
    },
    {
      "epoch": 1.98,
      "learning_rate": 8.341666666666667e-05,
      "loss": 2.7926,
      "step": 1801
    },
    {
      "epoch": 1.98,
      "learning_rate": 8.333333333333334e-05,
      "loss": 3.231,
      "step": 1802
    },
    {
      "epoch": 1.99,
      "learning_rate": 8.325e-05,
      "loss": 3.0934,
      "step": 1803
    },
    {
      "epoch": 1.99,
      "learning_rate": 8.316666666666666e-05,
      "loss": 2.8713,
      "step": 1804
    },
    {
      "epoch": 1.99,
      "learning_rate": 8.308333333333334e-05,
      "loss": 3.1015,
      "step": 1805
    },
    {
      "epoch": 1.99,
      "learning_rate": 8.3e-05,
      "loss": 3.0589,
      "step": 1806
    },
    {
      "epoch": 1.99,
      "learning_rate": 8.291666666666667e-05,
      "loss": 3.2509,
      "step": 1807
    },
    {
      "epoch": 1.99,
      "learning_rate": 8.283333333333335e-05,
      "loss": 3.0823,
      "step": 1808
    },
    {
      "epoch": 1.99,
      "learning_rate": 8.275e-05,
      "loss": 3.074,
      "step": 1809
    },
    {
      "epoch": 1.99,
      "learning_rate": 8.266666666666667e-05,
      "loss": 3.0189,
      "step": 1810
    },
    {
      "epoch": 1.99,
      "learning_rate": 8.258333333333334e-05,
      "loss": 3.2412,
      "step": 1811
    },
    {
      "epoch": 2.0,
      "learning_rate": 8.25e-05,
      "loss": 2.9972,
      "step": 1812
    },
    {
      "epoch": 2.0,
      "learning_rate": 8.241666666666667e-05,
      "loss": 3.2461,
      "step": 1813
    },
    {
      "epoch": 2.0,
      "learning_rate": 8.233333333333333e-05,
      "loss": 3.3083,
      "step": 1814
    },
    {
      "epoch": 2.0,
      "learning_rate": 8.225000000000001e-05,
      "loss": 3.0962,
      "step": 1815
    },
    {
      "epoch": 2.0,
      "learning_rate": 8.216666666666667e-05,
      "loss": 3.056,
      "step": 1816
    },
    {
      "epoch": 2.0,
      "learning_rate": 8.208333333333334e-05,
      "loss": 3.13,
      "step": 1817
    },
    {
      "epoch": 2.0,
      "learning_rate": 8.2e-05,
      "loss": 3.1325,
      "step": 1818
    },
    {
      "epoch": 2.0,
      "learning_rate": 8.191666666666667e-05,
      "loss": 3.1638,
      "step": 1819
    },
    {
      "epoch": 2.0,
      "learning_rate": 8.183333333333333e-05,
      "loss": 3.0783,
      "step": 1820
    },
    {
      "epoch": 2.01,
      "learning_rate": 8.175000000000001e-05,
      "loss": 3.1432,
      "step": 1821
    },
    {
      "epoch": 2.01,
      "learning_rate": 8.166666666666667e-05,
      "loss": 3.1022,
      "step": 1822
    },
    {
      "epoch": 2.01,
      "learning_rate": 8.158333333333333e-05,
      "loss": 3.3181,
      "step": 1823
    },
    {
      "epoch": 2.01,
      "learning_rate": 8.15e-05,
      "loss": 2.9547,
      "step": 1824
    },
    {
      "epoch": 2.01,
      "learning_rate": 8.141666666666668e-05,
      "loss": 3.04,
      "step": 1825
    },
    {
      "epoch": 2.01,
      "learning_rate": 8.133333333333334e-05,
      "loss": 3.1694,
      "step": 1826
    },
    {
      "epoch": 2.01,
      "learning_rate": 8.125000000000001e-05,
      "loss": 3.331,
      "step": 1827
    },
    {
      "epoch": 2.01,
      "learning_rate": 8.116666666666667e-05,
      "loss": 2.9104,
      "step": 1828
    },
    {
      "epoch": 2.01,
      "learning_rate": 8.108333333333333e-05,
      "loss": 3.1274,
      "step": 1829
    },
    {
      "epoch": 2.02,
      "learning_rate": 8.1e-05,
      "loss": 2.9829,
      "step": 1830
    },
    {
      "epoch": 2.02,
      "learning_rate": 8.091666666666668e-05,
      "loss": 2.8296,
      "step": 1831
    },
    {
      "epoch": 2.02,
      "learning_rate": 8.083333333333334e-05,
      "loss": 2.6183,
      "step": 1832
    },
    {
      "epoch": 2.02,
      "learning_rate": 8.075e-05,
      "loss": 2.8833,
      "step": 1833
    },
    {
      "epoch": 2.02,
      "learning_rate": 8.066666666666667e-05,
      "loss": 3.0508,
      "step": 1834
    },
    {
      "epoch": 2.02,
      "learning_rate": 8.058333333333333e-05,
      "loss": 2.983,
      "step": 1835
    },
    {
      "epoch": 2.02,
      "learning_rate": 8.05e-05,
      "loss": 2.9264,
      "step": 1836
    },
    {
      "epoch": 2.02,
      "learning_rate": 8.041666666666668e-05,
      "loss": 2.8815,
      "step": 1837
    },
    {
      "epoch": 2.02,
      "learning_rate": 8.033333333333334e-05,
      "loss": 2.9402,
      "step": 1838
    },
    {
      "epoch": 2.03,
      "learning_rate": 8.025e-05,
      "loss": 3.123,
      "step": 1839
    },
    {
      "epoch": 2.03,
      "learning_rate": 8.016666666666667e-05,
      "loss": 2.8292,
      "step": 1840
    },
    {
      "epoch": 2.03,
      "learning_rate": 8.008333333333333e-05,
      "loss": 3.3056,
      "step": 1841
    },
    {
      "epoch": 2.03,
      "learning_rate": 8e-05,
      "loss": 2.9943,
      "step": 1842
    },
    {
      "epoch": 2.03,
      "learning_rate": 7.991666666666667e-05,
      "loss": 3.1367,
      "step": 1843
    },
    {
      "epoch": 2.03,
      "learning_rate": 7.983333333333334e-05,
      "loss": 3.1899,
      "step": 1844
    },
    {
      "epoch": 2.03,
      "learning_rate": 7.975e-05,
      "loss": 3.2381,
      "step": 1845
    },
    {
      "epoch": 2.03,
      "learning_rate": 7.966666666666666e-05,
      "loss": 2.9755,
      "step": 1846
    },
    {
      "epoch": 2.03,
      "learning_rate": 7.958333333333333e-05,
      "loss": 3.1676,
      "step": 1847
    },
    {
      "epoch": 2.04,
      "learning_rate": 7.950000000000001e-05,
      "loss": 3.1562,
      "step": 1848
    },
    {
      "epoch": 2.04,
      "learning_rate": 7.941666666666667e-05,
      "loss": 3.06,
      "step": 1849
    },
    {
      "epoch": 2.04,
      "learning_rate": 7.933333333333334e-05,
      "loss": 3.112,
      "step": 1850
    },
    {
      "epoch": 2.04,
      "learning_rate": 7.925e-05,
      "loss": 3.1787,
      "step": 1851
    },
    {
      "epoch": 2.04,
      "learning_rate": 7.916666666666666e-05,
      "loss": 2.9238,
      "step": 1852
    },
    {
      "epoch": 2.04,
      "learning_rate": 7.908333333333335e-05,
      "loss": 3.1762,
      "step": 1853
    },
    {
      "epoch": 2.04,
      "learning_rate": 7.900000000000001e-05,
      "loss": 3.076,
      "step": 1854
    },
    {
      "epoch": 2.04,
      "learning_rate": 7.891666666666667e-05,
      "loss": 3.305,
      "step": 1855
    },
    {
      "epoch": 2.04,
      "learning_rate": 7.883333333333334e-05,
      "loss": 3.07,
      "step": 1856
    },
    {
      "epoch": 2.05,
      "learning_rate": 7.875e-05,
      "loss": 2.976,
      "step": 1857
    },
    {
      "epoch": 2.05,
      "learning_rate": 7.866666666666666e-05,
      "loss": 3.0355,
      "step": 1858
    },
    {
      "epoch": 2.05,
      "learning_rate": 7.858333333333334e-05,
      "loss": 2.8627,
      "step": 1859
    },
    {
      "epoch": 2.05,
      "learning_rate": 7.850000000000001e-05,
      "loss": 3.1775,
      "step": 1860
    },
    {
      "epoch": 2.05,
      "learning_rate": 7.841666666666667e-05,
      "loss": 3.1016,
      "step": 1861
    },
    {
      "epoch": 2.05,
      "learning_rate": 7.833333333333333e-05,
      "loss": 3.0431,
      "step": 1862
    },
    {
      "epoch": 2.05,
      "learning_rate": 7.825e-05,
      "loss": 2.8437,
      "step": 1863
    },
    {
      "epoch": 2.05,
      "learning_rate": 7.816666666666666e-05,
      "loss": 3.1722,
      "step": 1864
    },
    {
      "epoch": 2.05,
      "learning_rate": 7.808333333333334e-05,
      "loss": 2.9711,
      "step": 1865
    },
    {
      "epoch": 2.06,
      "learning_rate": 7.800000000000001e-05,
      "loss": 3.2786,
      "step": 1866
    },
    {
      "epoch": 2.06,
      "learning_rate": 7.791666666666667e-05,
      "loss": 3.0172,
      "step": 1867
    },
    {
      "epoch": 2.06,
      "learning_rate": 7.783333333333333e-05,
      "loss": 3.1465,
      "step": 1868
    },
    {
      "epoch": 2.06,
      "learning_rate": 7.775e-05,
      "loss": 3.1582,
      "step": 1869
    },
    {
      "epoch": 2.06,
      "learning_rate": 7.766666666666667e-05,
      "loss": 3.2887,
      "step": 1870
    },
    {
      "epoch": 2.06,
      "learning_rate": 7.758333333333334e-05,
      "loss": 3.161,
      "step": 1871
    },
    {
      "epoch": 2.06,
      "learning_rate": 7.75e-05,
      "loss": 2.896,
      "step": 1872
    },
    {
      "epoch": 2.06,
      "learning_rate": 7.741666666666667e-05,
      "loss": 3.2783,
      "step": 1873
    },
    {
      "epoch": 2.06,
      "learning_rate": 7.733333333333333e-05,
      "loss": 3.2606,
      "step": 1874
    },
    {
      "epoch": 2.06,
      "learning_rate": 7.725e-05,
      "loss": 3.0314,
      "step": 1875
    },
    {
      "epoch": 2.07,
      "learning_rate": 7.716666666666667e-05,
      "loss": 3.1875,
      "step": 1876
    },
    {
      "epoch": 2.07,
      "learning_rate": 7.708333333333334e-05,
      "loss": 2.9553,
      "step": 1877
    },
    {
      "epoch": 2.07,
      "learning_rate": 7.7e-05,
      "loss": 3.0961,
      "step": 1878
    },
    {
      "epoch": 2.07,
      "learning_rate": 7.691666666666668e-05,
      "loss": 2.9526,
      "step": 1879
    },
    {
      "epoch": 2.07,
      "learning_rate": 7.683333333333334e-05,
      "loss": 3.2424,
      "step": 1880
    },
    {
      "epoch": 2.07,
      "learning_rate": 7.675e-05,
      "loss": 3.3099,
      "step": 1881
    },
    {
      "epoch": 2.07,
      "learning_rate": 7.666666666666667e-05,
      "loss": 2.9699,
      "step": 1882
    },
    {
      "epoch": 2.07,
      "learning_rate": 7.658333333333334e-05,
      "loss": 3.2188,
      "step": 1883
    },
    {
      "epoch": 2.07,
      "learning_rate": 7.65e-05,
      "loss": 2.9584,
      "step": 1884
    },
    {
      "epoch": 2.08,
      "learning_rate": 7.641666666666668e-05,
      "loss": 3.0644,
      "step": 1885
    },
    {
      "epoch": 2.08,
      "learning_rate": 7.633333333333334e-05,
      "loss": 3.2793,
      "step": 1886
    },
    {
      "epoch": 2.08,
      "learning_rate": 7.625e-05,
      "loss": 3.3943,
      "step": 1887
    },
    {
      "epoch": 2.08,
      "learning_rate": 7.616666666666667e-05,
      "loss": 3.1808,
      "step": 1888
    },
    {
      "epoch": 2.08,
      "learning_rate": 7.608333333333334e-05,
      "loss": 3.2021,
      "step": 1889
    },
    {
      "epoch": 2.08,
      "learning_rate": 7.6e-05,
      "loss": 3.0615,
      "step": 1890
    },
    {
      "epoch": 2.08,
      "learning_rate": 7.591666666666666e-05,
      "loss": 2.9635,
      "step": 1891
    },
    {
      "epoch": 2.08,
      "learning_rate": 7.583333333333334e-05,
      "loss": 3.1055,
      "step": 1892
    },
    {
      "epoch": 2.08,
      "learning_rate": 7.575e-05,
      "loss": 3.0125,
      "step": 1893
    },
    {
      "epoch": 2.09,
      "learning_rate": 7.566666666666667e-05,
      "loss": 3.1055,
      "step": 1894
    },
    {
      "epoch": 2.09,
      "learning_rate": 7.558333333333335e-05,
      "loss": 3.1177,
      "step": 1895
    },
    {
      "epoch": 2.09,
      "learning_rate": 7.55e-05,
      "loss": 3.1036,
      "step": 1896
    },
    {
      "epoch": 2.09,
      "learning_rate": 7.541666666666667e-05,
      "loss": 3.1749,
      "step": 1897
    },
    {
      "epoch": 2.09,
      "learning_rate": 7.533333333333334e-05,
      "loss": 3.0624,
      "step": 1898
    },
    {
      "epoch": 2.09,
      "learning_rate": 7.525e-05,
      "loss": 3.1618,
      "step": 1899
    },
    {
      "epoch": 2.09,
      "learning_rate": 7.516666666666667e-05,
      "loss": 3.0748,
      "step": 1900
    },
    {
      "epoch": 2.09,
      "learning_rate": 7.508333333333333e-05,
      "loss": 3.0975,
      "step": 1901
    },
    {
      "epoch": 2.09,
      "learning_rate": 7.500000000000001e-05,
      "loss": 2.9884,
      "step": 1902
    },
    {
      "epoch": 2.1,
      "learning_rate": 7.491666666666667e-05,
      "loss": 3.0133,
      "step": 1903
    },
    {
      "epoch": 2.1,
      "learning_rate": 7.483333333333333e-05,
      "loss": 3.1666,
      "step": 1904
    },
    {
      "epoch": 2.1,
      "learning_rate": 7.475000000000001e-05,
      "loss": 2.9693,
      "step": 1905
    },
    {
      "epoch": 2.1,
      "learning_rate": 7.466666666666667e-05,
      "loss": 3.0782,
      "step": 1906
    },
    {
      "epoch": 2.1,
      "learning_rate": 7.458333333333333e-05,
      "loss": 3.1079,
      "step": 1907
    },
    {
      "epoch": 2.1,
      "learning_rate": 7.450000000000001e-05,
      "loss": 3.0309,
      "step": 1908
    },
    {
      "epoch": 2.1,
      "learning_rate": 7.441666666666667e-05,
      "loss": 3.1334,
      "step": 1909
    },
    {
      "epoch": 2.1,
      "learning_rate": 7.433333333333333e-05,
      "loss": 2.897,
      "step": 1910
    },
    {
      "epoch": 2.1,
      "learning_rate": 7.425e-05,
      "loss": 3.3443,
      "step": 1911
    },
    {
      "epoch": 2.11,
      "learning_rate": 7.416666666666668e-05,
      "loss": 3.0132,
      "step": 1912
    },
    {
      "epoch": 2.11,
      "learning_rate": 7.408333333333334e-05,
      "loss": 3.1373,
      "step": 1913
    },
    {
      "epoch": 2.11,
      "learning_rate": 7.4e-05,
      "loss": 2.9131,
      "step": 1914
    },
    {
      "epoch": 2.11,
      "learning_rate": 7.391666666666667e-05,
      "loss": 3.0605,
      "step": 1915
    },
    {
      "epoch": 2.11,
      "learning_rate": 7.383333333333333e-05,
      "loss": 3.2202,
      "step": 1916
    },
    {
      "epoch": 2.11,
      "learning_rate": 7.375e-05,
      "loss": 3.1003,
      "step": 1917
    },
    {
      "epoch": 2.11,
      "learning_rate": 7.366666666666668e-05,
      "loss": 3.2198,
      "step": 1918
    },
    {
      "epoch": 2.11,
      "learning_rate": 7.358333333333334e-05,
      "loss": 3.1606,
      "step": 1919
    },
    {
      "epoch": 2.11,
      "learning_rate": 7.35e-05,
      "loss": 3.1279,
      "step": 1920
    },
    {
      "epoch": 2.12,
      "learning_rate": 7.341666666666667e-05,
      "loss": 3.0448,
      "step": 1921
    },
    {
      "epoch": 2.12,
      "learning_rate": 7.333333333333333e-05,
      "loss": 3.032,
      "step": 1922
    },
    {
      "epoch": 2.12,
      "learning_rate": 7.325e-05,
      "loss": 3.178,
      "step": 1923
    },
    {
      "epoch": 2.12,
      "learning_rate": 7.316666666666668e-05,
      "loss": 3.0555,
      "step": 1924
    },
    {
      "epoch": 2.12,
      "learning_rate": 7.308333333333334e-05,
      "loss": 2.9971,
      "step": 1925
    },
    {
      "epoch": 2.12,
      "learning_rate": 7.3e-05,
      "loss": 3.2361,
      "step": 1926
    },
    {
      "epoch": 2.12,
      "learning_rate": 7.291666666666667e-05,
      "loss": 3.0516,
      "step": 1927
    },
    {
      "epoch": 2.12,
      "learning_rate": 7.283333333333335e-05,
      "loss": 2.9983,
      "step": 1928
    },
    {
      "epoch": 2.12,
      "learning_rate": 7.275e-05,
      "loss": 3.0674,
      "step": 1929
    },
    {
      "epoch": 2.13,
      "learning_rate": 7.266666666666667e-05,
      "loss": 2.9164,
      "step": 1930
    },
    {
      "epoch": 2.13,
      "learning_rate": 7.258333333333334e-05,
      "loss": 3.0724,
      "step": 1931
    },
    {
      "epoch": 2.13,
      "learning_rate": 7.25e-05,
      "loss": 3.2483,
      "step": 1932
    },
    {
      "epoch": 2.13,
      "learning_rate": 7.241666666666666e-05,
      "loss": 2.7909,
      "step": 1933
    },
    {
      "epoch": 2.13,
      "learning_rate": 7.233333333333335e-05,
      "loss": 3.0914,
      "step": 1934
    },
    {
      "epoch": 2.13,
      "learning_rate": 7.225000000000001e-05,
      "loss": 2.9876,
      "step": 1935
    },
    {
      "epoch": 2.13,
      "learning_rate": 7.216666666666667e-05,
      "loss": 2.8014,
      "step": 1936
    },
    {
      "epoch": 2.13,
      "learning_rate": 7.208333333333334e-05,
      "loss": 3.2526,
      "step": 1937
    },
    {
      "epoch": 2.13,
      "learning_rate": 7.2e-05,
      "loss": 3.3866,
      "step": 1938
    },
    {
      "epoch": 2.14,
      "learning_rate": 7.191666666666666e-05,
      "loss": 3.0142,
      "step": 1939
    },
    {
      "epoch": 2.14,
      "learning_rate": 7.183333333333334e-05,
      "loss": 3.0066,
      "step": 1940
    },
    {
      "epoch": 2.14,
      "learning_rate": 7.175000000000001e-05,
      "loss": 3.0426,
      "step": 1941
    },
    {
      "epoch": 2.14,
      "learning_rate": 7.166666666666667e-05,
      "loss": 3.2054,
      "step": 1942
    },
    {
      "epoch": 2.14,
      "learning_rate": 7.158333333333333e-05,
      "loss": 3.0701,
      "step": 1943
    },
    {
      "epoch": 2.14,
      "learning_rate": 7.15e-05,
      "loss": 3.0826,
      "step": 1944
    },
    {
      "epoch": 2.14,
      "learning_rate": 7.141666666666666e-05,
      "loss": 3.2126,
      "step": 1945
    },
    {
      "epoch": 2.14,
      "learning_rate": 7.133333333333334e-05,
      "loss": 2.8669,
      "step": 1946
    },
    {
      "epoch": 2.14,
      "learning_rate": 7.125000000000001e-05,
      "loss": 3.0232,
      "step": 1947
    },
    {
      "epoch": 2.15,
      "learning_rate": 7.116666666666667e-05,
      "loss": 3.1727,
      "step": 1948
    },
    {
      "epoch": 2.15,
      "learning_rate": 7.108333333333333e-05,
      "loss": 2.8829,
      "step": 1949
    },
    {
      "epoch": 2.15,
      "learning_rate": 7.1e-05,
      "loss": 3.0103,
      "step": 1950
    },
    {
      "epoch": 2.15,
      "learning_rate": 7.091666666666666e-05,
      "loss": 3.1832,
      "step": 1951
    },
    {
      "epoch": 2.15,
      "learning_rate": 7.083333333333334e-05,
      "loss": 3.1461,
      "step": 1952
    },
    {
      "epoch": 2.15,
      "learning_rate": 7.075e-05,
      "loss": 2.8593,
      "step": 1953
    },
    {
      "epoch": 2.15,
      "learning_rate": 7.066666666666667e-05,
      "loss": 3.0497,
      "step": 1954
    },
    {
      "epoch": 2.15,
      "learning_rate": 7.058333333333333e-05,
      "loss": 2.9187,
      "step": 1955
    },
    {
      "epoch": 2.15,
      "learning_rate": 7.05e-05,
      "loss": 3.1478,
      "step": 1956
    },
    {
      "epoch": 2.16,
      "learning_rate": 7.041666666666668e-05,
      "loss": 2.9033,
      "step": 1957
    },
    {
      "epoch": 2.16,
      "learning_rate": 7.033333333333334e-05,
      "loss": 3.0631,
      "step": 1958
    },
    {
      "epoch": 2.16,
      "learning_rate": 7.025e-05,
      "loss": 3.1126,
      "step": 1959
    },
    {
      "epoch": 2.16,
      "learning_rate": 7.016666666666667e-05,
      "loss": 3.0609,
      "step": 1960
    },
    {
      "epoch": 2.16,
      "learning_rate": 7.008333333333333e-05,
      "loss": 2.914,
      "step": 1961
    },
    {
      "epoch": 2.16,
      "learning_rate": 7e-05,
      "loss": 3.2597,
      "step": 1962
    },
    {
      "epoch": 2.16,
      "learning_rate": 6.991666666666668e-05,
      "loss": 3.0629,
      "step": 1963
    },
    {
      "epoch": 2.16,
      "learning_rate": 6.983333333333334e-05,
      "loss": 3.017,
      "step": 1964
    },
    {
      "epoch": 2.16,
      "learning_rate": 6.975e-05,
      "loss": 2.9567,
      "step": 1965
    },
    {
      "epoch": 2.17,
      "learning_rate": 6.966666666666668e-05,
      "loss": 3.0276,
      "step": 1966
    },
    {
      "epoch": 2.17,
      "learning_rate": 6.958333333333334e-05,
      "loss": 2.9322,
      "step": 1967
    },
    {
      "epoch": 2.17,
      "learning_rate": 6.95e-05,
      "loss": 3.0976,
      "step": 1968
    },
    {
      "epoch": 2.17,
      "learning_rate": 6.941666666666667e-05,
      "loss": 3.0919,
      "step": 1969
    },
    {
      "epoch": 2.17,
      "learning_rate": 6.933333333333334e-05,
      "loss": 3.1795,
      "step": 1970
    },
    {
      "epoch": 2.17,
      "learning_rate": 6.925e-05,
      "loss": 3.0747,
      "step": 1971
    },
    {
      "epoch": 2.17,
      "learning_rate": 6.916666666666666e-05,
      "loss": 3.1518,
      "step": 1972
    },
    {
      "epoch": 2.17,
      "learning_rate": 6.908333333333334e-05,
      "loss": 2.9769,
      "step": 1973
    },
    {
      "epoch": 2.17,
      "learning_rate": 6.9e-05,
      "loss": 3.0653,
      "step": 1974
    },
    {
      "epoch": 2.18,
      "learning_rate": 6.891666666666667e-05,
      "loss": 3.0112,
      "step": 1975
    },
    {
      "epoch": 2.18,
      "learning_rate": 6.883333333333334e-05,
      "loss": 3.183,
      "step": 1976
    },
    {
      "epoch": 2.18,
      "learning_rate": 6.875e-05,
      "loss": 2.9959,
      "step": 1977
    },
    {
      "epoch": 2.18,
      "learning_rate": 6.866666666666666e-05,
      "loss": 2.9836,
      "step": 1978
    },
    {
      "epoch": 2.18,
      "learning_rate": 6.858333333333334e-05,
      "loss": 2.9888,
      "step": 1979
    },
    {
      "epoch": 2.18,
      "learning_rate": 6.850000000000001e-05,
      "loss": 2.855,
      "step": 1980
    },
    {
      "epoch": 2.18,
      "learning_rate": 6.841666666666667e-05,
      "loss": 2.943,
      "step": 1981
    },
    {
      "epoch": 2.18,
      "learning_rate": 6.833333333333333e-05,
      "loss": 2.9848,
      "step": 1982
    },
    {
      "epoch": 2.18,
      "learning_rate": 6.825e-05,
      "loss": 3.1368,
      "step": 1983
    },
    {
      "epoch": 2.19,
      "learning_rate": 6.816666666666667e-05,
      "loss": 3.052,
      "step": 1984
    },
    {
      "epoch": 2.19,
      "learning_rate": 6.808333333333333e-05,
      "loss": 2.9598,
      "step": 1985
    },
    {
      "epoch": 2.19,
      "learning_rate": 6.800000000000001e-05,
      "loss": 3.0361,
      "step": 1986
    },
    {
      "epoch": 2.19,
      "learning_rate": 6.791666666666667e-05,
      "loss": 3.0318,
      "step": 1987
    },
    {
      "epoch": 2.19,
      "learning_rate": 6.783333333333333e-05,
      "loss": 3.0139,
      "step": 1988
    },
    {
      "epoch": 2.19,
      "learning_rate": 6.775000000000001e-05,
      "loss": 2.9216,
      "step": 1989
    },
    {
      "epoch": 2.19,
      "learning_rate": 6.766666666666667e-05,
      "loss": 3.0314,
      "step": 1990
    },
    {
      "epoch": 2.19,
      "learning_rate": 6.758333333333333e-05,
      "loss": 3.12,
      "step": 1991
    },
    {
      "epoch": 2.19,
      "learning_rate": 6.750000000000001e-05,
      "loss": 3.2067,
      "step": 1992
    },
    {
      "epoch": 2.19,
      "learning_rate": 6.741666666666667e-05,
      "loss": 3.0754,
      "step": 1993
    },
    {
      "epoch": 2.2,
      "learning_rate": 6.733333333333333e-05,
      "loss": 3.0351,
      "step": 1994
    },
    {
      "epoch": 2.2,
      "learning_rate": 6.725000000000001e-05,
      "loss": 3.1046,
      "step": 1995
    },
    {
      "epoch": 2.2,
      "learning_rate": 6.716666666666667e-05,
      "loss": 2.988,
      "step": 1996
    },
    {
      "epoch": 2.2,
      "learning_rate": 6.708333333333333e-05,
      "loss": 3.349,
      "step": 1997
    },
    {
      "epoch": 2.2,
      "learning_rate": 6.7e-05,
      "loss": 2.9844,
      "step": 1998
    },
    {
      "epoch": 2.2,
      "learning_rate": 6.691666666666668e-05,
      "loss": 3.2131,
      "step": 1999
    },
    {
      "epoch": 2.2,
      "learning_rate": 6.683333333333334e-05,
      "loss": 2.9405,
      "step": 2000
    },
    {
      "epoch": 2.2,
      "learning_rate": 6.675e-05,
      "loss": 3.0573,
      "step": 2001
    },
    {
      "epoch": 2.2,
      "learning_rate": 6.666666666666667e-05,
      "loss": 3.0882,
      "step": 2002
    },
    {
      "epoch": 2.21,
      "learning_rate": 6.658333333333334e-05,
      "loss": 3.0597,
      "step": 2003
    },
    {
      "epoch": 2.21,
      "learning_rate": 6.65e-05,
      "loss": 2.7506,
      "step": 2004
    },
    {
      "epoch": 2.21,
      "learning_rate": 6.641666666666668e-05,
      "loss": 3.0333,
      "step": 2005
    },
    {
      "epoch": 2.21,
      "learning_rate": 6.633333333333334e-05,
      "loss": 2.9137,
      "step": 2006
    },
    {
      "epoch": 2.21,
      "learning_rate": 6.625e-05,
      "loss": 2.9513,
      "step": 2007
    },
    {
      "epoch": 2.21,
      "learning_rate": 6.616666666666667e-05,
      "loss": 2.988,
      "step": 2008
    },
    {
      "epoch": 2.21,
      "learning_rate": 6.608333333333334e-05,
      "loss": 2.9494,
      "step": 2009
    },
    {
      "epoch": 2.21,
      "learning_rate": 6.6e-05,
      "loss": 3.0737,
      "step": 2010
    },
    {
      "epoch": 2.21,
      "learning_rate": 6.591666666666667e-05,
      "loss": 2.7944,
      "step": 2011
    },
    {
      "epoch": 2.22,
      "learning_rate": 6.583333333333334e-05,
      "loss": 3.0956,
      "step": 2012
    },
    {
      "epoch": 2.22,
      "learning_rate": 6.575e-05,
      "loss": 2.9849,
      "step": 2013
    },
    {
      "epoch": 2.22,
      "learning_rate": 6.566666666666666e-05,
      "loss": 3.1931,
      "step": 2014
    },
    {
      "epoch": 2.22,
      "learning_rate": 6.558333333333335e-05,
      "loss": 3.0095,
      "step": 2015
    },
    {
      "epoch": 2.22,
      "learning_rate": 6.55e-05,
      "loss": 3.0642,
      "step": 2016
    },
    {
      "epoch": 2.22,
      "learning_rate": 6.541666666666667e-05,
      "loss": 3.1012,
      "step": 2017
    },
    {
      "epoch": 2.22,
      "learning_rate": 6.533333333333334e-05,
      "loss": 3.0555,
      "step": 2018
    },
    {
      "epoch": 2.22,
      "learning_rate": 6.525e-05,
      "loss": 3.2826,
      "step": 2019
    },
    {
      "epoch": 2.22,
      "learning_rate": 6.516666666666666e-05,
      "loss": 3.2229,
      "step": 2020
    },
    {
      "epoch": 2.23,
      "learning_rate": 6.508333333333333e-05,
      "loss": 3.2658,
      "step": 2021
    },
    {
      "epoch": 2.23,
      "learning_rate": 6.500000000000001e-05,
      "loss": 3.2209,
      "step": 2022
    },
    {
      "epoch": 2.23,
      "learning_rate": 6.491666666666667e-05,
      "loss": 3.1773,
      "step": 2023
    },
    {
      "epoch": 2.23,
      "learning_rate": 6.483333333333333e-05,
      "loss": 3.1358,
      "step": 2024
    },
    {
      "epoch": 2.23,
      "learning_rate": 6.475e-05,
      "loss": 2.921,
      "step": 2025
    },
    {
      "epoch": 2.23,
      "learning_rate": 6.466666666666666e-05,
      "loss": 3.2464,
      "step": 2026
    },
    {
      "epoch": 2.23,
      "learning_rate": 6.458333333333334e-05,
      "loss": 2.9648,
      "step": 2027
    },
    {
      "epoch": 2.23,
      "learning_rate": 6.450000000000001e-05,
      "loss": 3.1536,
      "step": 2028
    },
    {
      "epoch": 2.23,
      "learning_rate": 6.441666666666667e-05,
      "loss": 3.1374,
      "step": 2029
    },
    {
      "epoch": 2.24,
      "learning_rate": 6.433333333333333e-05,
      "loss": 3.2291,
      "step": 2030
    },
    {
      "epoch": 2.24,
      "learning_rate": 6.425e-05,
      "loss": 2.8764,
      "step": 2031
    },
    {
      "epoch": 2.24,
      "learning_rate": 6.416666666666668e-05,
      "loss": 2.995,
      "step": 2032
    },
    {
      "epoch": 2.24,
      "learning_rate": 6.408333333333334e-05,
      "loss": 2.9236,
      "step": 2033
    },
    {
      "epoch": 2.24,
      "learning_rate": 6.400000000000001e-05,
      "loss": 2.9928,
      "step": 2034
    },
    {
      "epoch": 2.24,
      "learning_rate": 6.391666666666667e-05,
      "loss": 3.1126,
      "step": 2035
    },
    {
      "epoch": 2.24,
      "learning_rate": 6.383333333333333e-05,
      "loss": 3.1725,
      "step": 2036
    },
    {
      "epoch": 2.24,
      "learning_rate": 6.375e-05,
      "loss": 2.9483,
      "step": 2037
    },
    {
      "epoch": 2.24,
      "learning_rate": 6.366666666666668e-05,
      "loss": 3.0418,
      "step": 2038
    },
    {
      "epoch": 2.25,
      "learning_rate": 6.358333333333334e-05,
      "loss": 2.9357,
      "step": 2039
    },
    {
      "epoch": 2.25,
      "learning_rate": 6.35e-05,
      "loss": 2.9411,
      "step": 2040
    },
    {
      "epoch": 2.25,
      "learning_rate": 6.341666666666667e-05,
      "loss": 3.1487,
      "step": 2041
    },
    {
      "epoch": 2.25,
      "learning_rate": 6.333333333333333e-05,
      "loss": 3.2434,
      "step": 2042
    },
    {
      "epoch": 2.25,
      "learning_rate": 6.324999999999999e-05,
      "loss": 2.9895,
      "step": 2043
    },
    {
      "epoch": 2.25,
      "learning_rate": 6.316666666666668e-05,
      "loss": 3.2622,
      "step": 2044
    },
    {
      "epoch": 2.25,
      "learning_rate": 6.308333333333334e-05,
      "loss": 3.1994,
      "step": 2045
    },
    {
      "epoch": 2.25,
      "learning_rate": 6.3e-05,
      "loss": 3.1869,
      "step": 2046
    },
    {
      "epoch": 2.25,
      "learning_rate": 6.291666666666667e-05,
      "loss": 3.1742,
      "step": 2047
    },
    {
      "epoch": 2.26,
      "learning_rate": 6.283333333333333e-05,
      "loss": 3.0179,
      "step": 2048
    },
    {
      "epoch": 2.26,
      "learning_rate": 6.275e-05,
      "loss": 2.9753,
      "step": 2049
    },
    {
      "epoch": 2.26,
      "learning_rate": 6.266666666666667e-05,
      "loss": 2.8758,
      "step": 2050
    },
    {
      "epoch": 2.26,
      "learning_rate": 6.258333333333334e-05,
      "loss": 2.9233,
      "step": 2051
    },
    {
      "epoch": 2.26,
      "learning_rate": 6.25e-05,
      "loss": 3.0504,
      "step": 2052
    },
    {
      "epoch": 2.26,
      "learning_rate": 6.241666666666666e-05,
      "loss": 3.1297,
      "step": 2053
    },
    {
      "epoch": 2.26,
      "learning_rate": 6.233333333333334e-05,
      "loss": 3.0114,
      "step": 2054
    },
    {
      "epoch": 2.26,
      "learning_rate": 6.225000000000001e-05,
      "loss": 3.1008,
      "step": 2055
    },
    {
      "epoch": 2.26,
      "learning_rate": 6.216666666666667e-05,
      "loss": 2.9945,
      "step": 2056
    },
    {
      "epoch": 2.27,
      "learning_rate": 6.208333333333334e-05,
      "loss": 2.8865,
      "step": 2057
    },
    {
      "epoch": 2.27,
      "learning_rate": 6.2e-05,
      "loss": 2.9108,
      "step": 2058
    },
    {
      "epoch": 2.27,
      "learning_rate": 6.191666666666666e-05,
      "loss": 2.9774,
      "step": 2059
    },
    {
      "epoch": 2.27,
      "learning_rate": 6.183333333333334e-05,
      "loss": 3.1849,
      "step": 2060
    },
    {
      "epoch": 2.27,
      "learning_rate": 6.175000000000001e-05,
      "loss": 3.1436,
      "step": 2061
    },
    {
      "epoch": 2.27,
      "learning_rate": 6.166666666666667e-05,
      "loss": 3.1438,
      "step": 2062
    },
    {
      "epoch": 2.27,
      "learning_rate": 6.158333333333334e-05,
      "loss": 2.9907,
      "step": 2063
    },
    {
      "epoch": 2.27,
      "learning_rate": 6.15e-05,
      "loss": 3.0637,
      "step": 2064
    },
    {
      "epoch": 2.27,
      "learning_rate": 6.141666666666666e-05,
      "loss": 3.2431,
      "step": 2065
    },
    {
      "epoch": 2.28,
      "learning_rate": 6.133333333333334e-05,
      "loss": 3.0499,
      "step": 2066
    },
    {
      "epoch": 2.28,
      "learning_rate": 6.125000000000001e-05,
      "loss": 2.987,
      "step": 2067
    },
    {
      "epoch": 2.28,
      "learning_rate": 6.116666666666667e-05,
      "loss": 3.2008,
      "step": 2068
    },
    {
      "epoch": 2.28,
      "learning_rate": 6.108333333333333e-05,
      "loss": 3.2084,
      "step": 2069
    },
    {
      "epoch": 2.28,
      "learning_rate": 6.1e-05,
      "loss": 3.2464,
      "step": 2070
    },
    {
      "epoch": 2.28,
      "learning_rate": 6.0916666666666666e-05,
      "loss": 3.2907,
      "step": 2071
    },
    {
      "epoch": 2.28,
      "learning_rate": 6.083333333333333e-05,
      "loss": 2.7992,
      "step": 2072
    },
    {
      "epoch": 2.28,
      "learning_rate": 6.0750000000000006e-05,
      "loss": 3.3095,
      "step": 2073
    },
    {
      "epoch": 2.28,
      "learning_rate": 6.066666666666667e-05,
      "loss": 3.1022,
      "step": 2074
    },
    {
      "epoch": 2.29,
      "learning_rate": 6.058333333333333e-05,
      "loss": 3.2561,
      "step": 2075
    },
    {
      "epoch": 2.29,
      "learning_rate": 6.05e-05,
      "loss": 2.8166,
      "step": 2076
    },
    {
      "epoch": 2.29,
      "learning_rate": 6.041666666666667e-05,
      "loss": 2.9551,
      "step": 2077
    },
    {
      "epoch": 2.29,
      "learning_rate": 6.033333333333334e-05,
      "loss": 3.1702,
      "step": 2078
    },
    {
      "epoch": 2.29,
      "learning_rate": 6.025000000000001e-05,
      "loss": 2.8218,
      "step": 2079
    },
    {
      "epoch": 2.29,
      "learning_rate": 6.0166666666666674e-05,
      "loss": 2.9307,
      "step": 2080
    },
    {
      "epoch": 2.29,
      "learning_rate": 6.0083333333333335e-05,
      "loss": 2.9788,
      "step": 2081
    },
    {
      "epoch": 2.29,
      "learning_rate": 6e-05,
      "loss": 3.1269,
      "step": 2082
    },
    {
      "epoch": 2.29,
      "learning_rate": 5.991666666666667e-05,
      "loss": 3.0686,
      "step": 2083
    },
    {
      "epoch": 2.3,
      "learning_rate": 5.983333333333334e-05,
      "loss": 3.1747,
      "step": 2084
    },
    {
      "epoch": 2.3,
      "learning_rate": 5.975000000000001e-05,
      "loss": 3.1186,
      "step": 2085
    },
    {
      "epoch": 2.3,
      "learning_rate": 5.966666666666667e-05,
      "loss": 3.1097,
      "step": 2086
    },
    {
      "epoch": 2.3,
      "learning_rate": 5.9583333333333336e-05,
      "loss": 2.9405,
      "step": 2087
    },
    {
      "epoch": 2.3,
      "learning_rate": 5.95e-05,
      "loss": 2.8219,
      "step": 2088
    },
    {
      "epoch": 2.3,
      "learning_rate": 5.941666666666666e-05,
      "loss": 3.2428,
      "step": 2089
    },
    {
      "epoch": 2.3,
      "learning_rate": 5.9333333333333343e-05,
      "loss": 3.0335,
      "step": 2090
    },
    {
      "epoch": 2.3,
      "learning_rate": 5.9250000000000004e-05,
      "loss": 3.2882,
      "step": 2091
    },
    {
      "epoch": 2.3,
      "learning_rate": 5.916666666666667e-05,
      "loss": 3.1022,
      "step": 2092
    },
    {
      "epoch": 2.31,
      "learning_rate": 5.908333333333334e-05,
      "loss": 3.0794,
      "step": 2093
    },
    {
      "epoch": 2.31,
      "learning_rate": 5.9e-05,
      "loss": 2.9645,
      "step": 2094
    },
    {
      "epoch": 2.31,
      "learning_rate": 5.8916666666666664e-05,
      "loss": 2.9336,
      "step": 2095
    },
    {
      "epoch": 2.31,
      "learning_rate": 5.883333333333334e-05,
      "loss": 3.1139,
      "step": 2096
    },
    {
      "epoch": 2.31,
      "learning_rate": 5.8750000000000005e-05,
      "loss": 3.0135,
      "step": 2097
    },
    {
      "epoch": 2.31,
      "learning_rate": 5.866666666666667e-05,
      "loss": 2.8043,
      "step": 2098
    },
    {
      "epoch": 2.31,
      "learning_rate": 5.858333333333333e-05,
      "loss": 3.1902,
      "step": 2099
    },
    {
      "epoch": 2.31,
      "learning_rate": 5.85e-05,
      "loss": 2.9608,
      "step": 2100
    },
    {
      "epoch": 2.31,
      "learning_rate": 5.8416666666666666e-05,
      "loss": 3.1249,
      "step": 2101
    },
    {
      "epoch": 2.31,
      "learning_rate": 5.833333333333334e-05,
      "loss": 3.2913,
      "step": 2102
    },
    {
      "epoch": 2.32,
      "learning_rate": 5.8250000000000006e-05,
      "loss": 3.1415,
      "step": 2103
    },
    {
      "epoch": 2.32,
      "learning_rate": 5.8166666666666667e-05,
      "loss": 3.0035,
      "step": 2104
    },
    {
      "epoch": 2.32,
      "learning_rate": 5.8083333333333333e-05,
      "loss": 2.9847,
      "step": 2105
    },
    {
      "epoch": 2.32,
      "learning_rate": 5.8e-05,
      "loss": 3.1782,
      "step": 2106
    },
    {
      "epoch": 2.32,
      "learning_rate": 5.7916666666666674e-05,
      "loss": 2.8428,
      "step": 2107
    },
    {
      "epoch": 2.32,
      "learning_rate": 5.783333333333334e-05,
      "loss": 3.0411,
      "step": 2108
    },
    {
      "epoch": 2.32,
      "learning_rate": 5.775e-05,
      "loss": 3.0231,
      "step": 2109
    },
    {
      "epoch": 2.32,
      "learning_rate": 5.766666666666667e-05,
      "loss": 3.0698,
      "step": 2110
    },
    {
      "epoch": 2.32,
      "learning_rate": 5.7583333333333335e-05,
      "loss": 3.1014,
      "step": 2111
    },
    {
      "epoch": 2.33,
      "learning_rate": 5.7499999999999995e-05,
      "loss": 3.1573,
      "step": 2112
    },
    {
      "epoch": 2.33,
      "learning_rate": 5.7416666666666675e-05,
      "loss": 3.0947,
      "step": 2113
    },
    {
      "epoch": 2.33,
      "learning_rate": 5.7333333333333336e-05,
      "loss": 3.0238,
      "step": 2114
    },
    {
      "epoch": 2.33,
      "learning_rate": 5.725e-05,
      "loss": 3.0983,
      "step": 2115
    },
    {
      "epoch": 2.33,
      "learning_rate": 5.716666666666667e-05,
      "loss": 3.1493,
      "step": 2116
    },
    {
      "epoch": 2.33,
      "learning_rate": 5.7083333333333336e-05,
      "loss": 3.0764,
      "step": 2117
    },
    {
      "epoch": 2.33,
      "learning_rate": 5.6999999999999996e-05,
      "loss": 3.0745,
      "step": 2118
    },
    {
      "epoch": 2.33,
      "learning_rate": 5.691666666666668e-05,
      "loss": 3.0152,
      "step": 2119
    },
    {
      "epoch": 2.33,
      "learning_rate": 5.683333333333334e-05,
      "loss": 3.0665,
      "step": 2120
    },
    {
      "epoch": 2.34,
      "learning_rate": 5.6750000000000004e-05,
      "loss": 3.2243,
      "step": 2121
    },
    {
      "epoch": 2.34,
      "learning_rate": 5.666666666666667e-05,
      "loss": 3.1984,
      "step": 2122
    },
    {
      "epoch": 2.34,
      "learning_rate": 5.658333333333333e-05,
      "loss": 3.0472,
      "step": 2123
    },
    {
      "epoch": 2.34,
      "learning_rate": 5.65e-05,
      "loss": 3.3508,
      "step": 2124
    },
    {
      "epoch": 2.34,
      "learning_rate": 5.641666666666667e-05,
      "loss": 3.0584,
      "step": 2125
    },
    {
      "epoch": 2.34,
      "learning_rate": 5.633333333333334e-05,
      "loss": 3.1031,
      "step": 2126
    },
    {
      "epoch": 2.34,
      "learning_rate": 5.6250000000000005e-05,
      "loss": 3.0476,
      "step": 2127
    },
    {
      "epoch": 2.34,
      "learning_rate": 5.6166666666666665e-05,
      "loss": 3.1427,
      "step": 2128
    },
    {
      "epoch": 2.34,
      "learning_rate": 5.608333333333333e-05,
      "loss": 3.1136,
      "step": 2129
    },
    {
      "epoch": 2.35,
      "learning_rate": 5.6000000000000006e-05,
      "loss": 3.2917,
      "step": 2130
    },
    {
      "epoch": 2.35,
      "learning_rate": 5.591666666666667e-05,
      "loss": 3.1848,
      "step": 2131
    },
    {
      "epoch": 2.35,
      "learning_rate": 5.583333333333334e-05,
      "loss": 2.8885,
      "step": 2132
    },
    {
      "epoch": 2.35,
      "learning_rate": 5.575e-05,
      "loss": 3.1494,
      "step": 2133
    },
    {
      "epoch": 2.35,
      "learning_rate": 5.566666666666667e-05,
      "loss": 3.0147,
      "step": 2134
    },
    {
      "epoch": 2.35,
      "learning_rate": 5.5583333333333334e-05,
      "loss": 2.9922,
      "step": 2135
    },
    {
      "epoch": 2.35,
      "learning_rate": 5.550000000000001e-05,
      "loss": 3.1265,
      "step": 2136
    },
    {
      "epoch": 2.35,
      "learning_rate": 5.5416666666666674e-05,
      "loss": 3.1937,
      "step": 2137
    },
    {
      "epoch": 2.35,
      "learning_rate": 5.5333333333333334e-05,
      "loss": 3.0444,
      "step": 2138
    },
    {
      "epoch": 2.36,
      "learning_rate": 5.525e-05,
      "loss": 3.032,
      "step": 2139
    },
    {
      "epoch": 2.36,
      "learning_rate": 5.516666666666667e-05,
      "loss": 3.0499,
      "step": 2140
    },
    {
      "epoch": 2.36,
      "learning_rate": 5.508333333333333e-05,
      "loss": 3.0399,
      "step": 2141
    },
    {
      "epoch": 2.36,
      "learning_rate": 5.500000000000001e-05,
      "loss": 3.1426,
      "step": 2142
    },
    {
      "epoch": 2.36,
      "learning_rate": 5.491666666666667e-05,
      "loss": 3.2509,
      "step": 2143
    },
    {
      "epoch": 2.36,
      "learning_rate": 5.4833333333333336e-05,
      "loss": 3.0939,
      "step": 2144
    },
    {
      "epoch": 2.36,
      "learning_rate": 5.475e-05,
      "loss": 3.0557,
      "step": 2145
    },
    {
      "epoch": 2.36,
      "learning_rate": 5.466666666666666e-05,
      "loss": 3.0569,
      "step": 2146
    },
    {
      "epoch": 2.36,
      "learning_rate": 5.458333333333333e-05,
      "loss": 2.9146,
      "step": 2147
    },
    {
      "epoch": 2.37,
      "learning_rate": 5.45e-05,
      "loss": 2.96,
      "step": 2148
    },
    {
      "epoch": 2.37,
      "learning_rate": 5.441666666666667e-05,
      "loss": 3.0519,
      "step": 2149
    },
    {
      "epoch": 2.37,
      "learning_rate": 5.433333333333334e-05,
      "loss": 3.0842,
      "step": 2150
    },
    {
      "epoch": 2.37,
      "learning_rate": 5.4250000000000004e-05,
      "loss": 3.0991,
      "step": 2151
    },
    {
      "epoch": 2.37,
      "learning_rate": 5.4166666666666664e-05,
      "loss": 2.9319,
      "step": 2152
    },
    {
      "epoch": 2.37,
      "learning_rate": 5.4083333333333345e-05,
      "loss": 3.18,
      "step": 2153
    },
    {
      "epoch": 2.37,
      "learning_rate": 5.4000000000000005e-05,
      "loss": 3.2151,
      "step": 2154
    },
    {
      "epoch": 2.37,
      "learning_rate": 5.391666666666667e-05,
      "loss": 3.1161,
      "step": 2155
    },
    {
      "epoch": 2.37,
      "learning_rate": 5.383333333333334e-05,
      "loss": 2.9608,
      "step": 2156
    },
    {
      "epoch": 2.38,
      "learning_rate": 5.375e-05,
      "loss": 2.9882,
      "step": 2157
    },
    {
      "epoch": 2.38,
      "learning_rate": 5.3666666666666666e-05,
      "loss": 3.0414,
      "step": 2158
    },
    {
      "epoch": 2.38,
      "learning_rate": 5.358333333333334e-05,
      "loss": 2.9438,
      "step": 2159
    },
    {
      "epoch": 2.38,
      "learning_rate": 5.3500000000000006e-05,
      "loss": 3.1621,
      "step": 2160
    },
    {
      "epoch": 2.38,
      "learning_rate": 5.341666666666667e-05,
      "loss": 3.3179,
      "step": 2161
    },
    {
      "epoch": 2.38,
      "learning_rate": 5.333333333333333e-05,
      "loss": 3.0484,
      "step": 2162
    },
    {
      "epoch": 2.38,
      "learning_rate": 5.325e-05,
      "loss": 2.9798,
      "step": 2163
    },
    {
      "epoch": 2.38,
      "learning_rate": 5.316666666666667e-05,
      "loss": 3.1269,
      "step": 2164
    },
    {
      "epoch": 2.38,
      "learning_rate": 5.308333333333334e-05,
      "loss": 2.8764,
      "step": 2165
    },
    {
      "epoch": 2.39,
      "learning_rate": 5.300000000000001e-05,
      "loss": 3.1559,
      "step": 2166
    },
    {
      "epoch": 2.39,
      "learning_rate": 5.291666666666667e-05,
      "loss": 3.2535,
      "step": 2167
    },
    {
      "epoch": 2.39,
      "learning_rate": 5.2833333333333335e-05,
      "loss": 3.1297,
      "step": 2168
    },
    {
      "epoch": 2.39,
      "learning_rate": 5.275e-05,
      "loss": 3.1256,
      "step": 2169
    },
    {
      "epoch": 2.39,
      "learning_rate": 5.266666666666666e-05,
      "loss": 3.3992,
      "step": 2170
    },
    {
      "epoch": 2.39,
      "learning_rate": 5.258333333333334e-05,
      "loss": 3.0543,
      "step": 2171
    },
    {
      "epoch": 2.39,
      "learning_rate": 5.25e-05,
      "loss": 2.9971,
      "step": 2172
    },
    {
      "epoch": 2.39,
      "learning_rate": 5.241666666666667e-05,
      "loss": 3.1721,
      "step": 2173
    },
    {
      "epoch": 2.39,
      "learning_rate": 5.2333333333333336e-05,
      "loss": 2.9459,
      "step": 2174
    },
    {
      "epoch": 2.4,
      "learning_rate": 5.2249999999999996e-05,
      "loss": 3.124,
      "step": 2175
    },
    {
      "epoch": 2.4,
      "learning_rate": 5.216666666666666e-05,
      "loss": 3.1434,
      "step": 2176
    },
    {
      "epoch": 2.4,
      "learning_rate": 5.208333333333334e-05,
      "loss": 3.0347,
      "step": 2177
    },
    {
      "epoch": 2.4,
      "learning_rate": 5.2000000000000004e-05,
      "loss": 3.0137,
      "step": 2178
    },
    {
      "epoch": 2.4,
      "learning_rate": 5.191666666666667e-05,
      "loss": 3.1183,
      "step": 2179
    },
    {
      "epoch": 2.4,
      "learning_rate": 5.183333333333333e-05,
      "loss": 3.1616,
      "step": 2180
    },
    {
      "epoch": 2.4,
      "learning_rate": 5.175e-05,
      "loss": 3.0568,
      "step": 2181
    },
    {
      "epoch": 2.4,
      "learning_rate": 5.166666666666667e-05,
      "loss": 2.8481,
      "step": 2182
    },
    {
      "epoch": 2.4,
      "learning_rate": 5.158333333333334e-05,
      "loss": 3.258,
      "step": 2183
    },
    {
      "epoch": 2.41,
      "learning_rate": 5.1500000000000005e-05,
      "loss": 2.8963,
      "step": 2184
    },
    {
      "epoch": 2.41,
      "learning_rate": 5.141666666666667e-05,
      "loss": 3.0153,
      "step": 2185
    },
    {
      "epoch": 2.41,
      "learning_rate": 5.133333333333333e-05,
      "loss": 3.202,
      "step": 2186
    },
    {
      "epoch": 2.41,
      "learning_rate": 5.125e-05,
      "loss": 3.0136,
      "step": 2187
    },
    {
      "epoch": 2.41,
      "learning_rate": 5.116666666666667e-05,
      "loss": 3.0172,
      "step": 2188
    },
    {
      "epoch": 2.41,
      "learning_rate": 5.108333333333334e-05,
      "loss": 2.9623,
      "step": 2189
    },
    {
      "epoch": 2.41,
      "learning_rate": 5.1000000000000006e-05,
      "loss": 3.1149,
      "step": 2190
    },
    {
      "epoch": 2.41,
      "learning_rate": 5.0916666666666666e-05,
      "loss": 3.0672,
      "step": 2191
    },
    {
      "epoch": 2.41,
      "learning_rate": 5.0833333333333333e-05,
      "loss": 2.8561,
      "step": 2192
    },
    {
      "epoch": 2.42,
      "learning_rate": 5.075e-05,
      "loss": 3.0946,
      "step": 2193
    },
    {
      "epoch": 2.42,
      "learning_rate": 5.0666666666666674e-05,
      "loss": 2.9934,
      "step": 2194
    },
    {
      "epoch": 2.42,
      "learning_rate": 5.058333333333334e-05,
      "loss": 3.1789,
      "step": 2195
    },
    {
      "epoch": 2.42,
      "learning_rate": 5.05e-05,
      "loss": 3.0742,
      "step": 2196
    },
    {
      "epoch": 2.42,
      "learning_rate": 5.041666666666667e-05,
      "loss": 3.0134,
      "step": 2197
    },
    {
      "epoch": 2.42,
      "learning_rate": 5.0333333333333335e-05,
      "loss": 2.9129,
      "step": 2198
    },
    {
      "epoch": 2.42,
      "learning_rate": 5.0249999999999995e-05,
      "loss": 3.3269,
      "step": 2199
    },
    {
      "epoch": 2.42,
      "learning_rate": 5.0166666666666675e-05,
      "loss": 3.391,
      "step": 2200
    },
    {
      "epoch": 2.42,
      "learning_rate": 5.0083333333333335e-05,
      "loss": 2.7245,
      "step": 2201
    },
    {
      "epoch": 2.43,
      "learning_rate": 5e-05,
      "loss": 3.0173,
      "step": 2202
    },
    {
      "epoch": 2.43,
      "learning_rate": 4.991666666666667e-05,
      "loss": 3.2905,
      "step": 2203
    },
    {
      "epoch": 2.43,
      "learning_rate": 4.9833333333333336e-05,
      "loss": 3.1002,
      "step": 2204
    },
    {
      "epoch": 2.43,
      "learning_rate": 4.975e-05,
      "loss": 3.0956,
      "step": 2205
    },
    {
      "epoch": 2.43,
      "learning_rate": 4.966666666666667e-05,
      "loss": 2.9863,
      "step": 2206
    },
    {
      "epoch": 2.43,
      "learning_rate": 4.958333333333334e-05,
      "loss": 2.874,
      "step": 2207
    },
    {
      "epoch": 2.43,
      "learning_rate": 4.9500000000000004e-05,
      "loss": 2.9131,
      "step": 2208
    },
    {
      "epoch": 2.43,
      "learning_rate": 4.9416666666666664e-05,
      "loss": 3.0684,
      "step": 2209
    },
    {
      "epoch": 2.43,
      "learning_rate": 4.933333333333334e-05,
      "loss": 2.9716,
      "step": 2210
    },
    {
      "epoch": 2.44,
      "learning_rate": 4.9250000000000004e-05,
      "loss": 3.0804,
      "step": 2211
    },
    {
      "epoch": 2.44,
      "learning_rate": 4.9166666666666665e-05,
      "loss": 3.0091,
      "step": 2212
    },
    {
      "epoch": 2.44,
      "learning_rate": 4.908333333333334e-05,
      "loss": 2.9878,
      "step": 2213
    },
    {
      "epoch": 2.44,
      "learning_rate": 4.9e-05,
      "loss": 3.1049,
      "step": 2214
    },
    {
      "epoch": 2.44,
      "learning_rate": 4.891666666666667e-05,
      "loss": 3.195,
      "step": 2215
    },
    {
      "epoch": 2.44,
      "learning_rate": 4.883333333333334e-05,
      "loss": 2.9622,
      "step": 2216
    },
    {
      "epoch": 2.44,
      "learning_rate": 4.875e-05,
      "loss": 2.9177,
      "step": 2217
    },
    {
      "epoch": 2.44,
      "learning_rate": 4.866666666666667e-05,
      "loss": 3.145,
      "step": 2218
    },
    {
      "epoch": 2.44,
      "learning_rate": 4.858333333333333e-05,
      "loss": 2.7482,
      "step": 2219
    },
    {
      "epoch": 2.44,
      "learning_rate": 4.85e-05,
      "loss": 3.1306,
      "step": 2220
    },
    {
      "epoch": 2.45,
      "learning_rate": 4.8416666666666673e-05,
      "loss": 3.1117,
      "step": 2221
    },
    {
      "epoch": 2.45,
      "learning_rate": 4.8333333333333334e-05,
      "loss": 3.0766,
      "step": 2222
    },
    {
      "epoch": 2.45,
      "learning_rate": 4.825e-05,
      "loss": 3.1365,
      "step": 2223
    },
    {
      "epoch": 2.45,
      "learning_rate": 4.8166666666666674e-05,
      "loss": 3.1829,
      "step": 2224
    },
    {
      "epoch": 2.45,
      "learning_rate": 4.8083333333333334e-05,
      "loss": 2.9696,
      "step": 2225
    },
    {
      "epoch": 2.45,
      "learning_rate": 4.8e-05,
      "loss": 3.1543,
      "step": 2226
    },
    {
      "epoch": 2.45,
      "learning_rate": 4.791666666666667e-05,
      "loss": 3.0772,
      "step": 2227
    },
    {
      "epoch": 2.45,
      "learning_rate": 4.7833333333333335e-05,
      "loss": 3.3012,
      "step": 2228
    },
    {
      "epoch": 2.45,
      "learning_rate": 4.775e-05,
      "loss": 3.0691,
      "step": 2229
    },
    {
      "epoch": 2.46,
      "learning_rate": 4.766666666666667e-05,
      "loss": 3.079,
      "step": 2230
    },
    {
      "epoch": 2.46,
      "learning_rate": 4.7583333333333336e-05,
      "loss": 3.0063,
      "step": 2231
    },
    {
      "epoch": 2.46,
      "learning_rate": 4.75e-05,
      "loss": 3.3002,
      "step": 2232
    },
    {
      "epoch": 2.46,
      "learning_rate": 4.741666666666667e-05,
      "loss": 3.1982,
      "step": 2233
    },
    {
      "epoch": 2.46,
      "learning_rate": 4.7333333333333336e-05,
      "loss": 3.1904,
      "step": 2234
    },
    {
      "epoch": 2.46,
      "learning_rate": 4.7249999999999997e-05,
      "loss": 3.0508,
      "step": 2235
    },
    {
      "epoch": 2.46,
      "learning_rate": 4.716666666666667e-05,
      "loss": 2.9856,
      "step": 2236
    },
    {
      "epoch": 2.46,
      "learning_rate": 4.708333333333334e-05,
      "loss": 3.1494,
      "step": 2237
    },
    {
      "epoch": 2.46,
      "learning_rate": 4.7e-05,
      "loss": 3.0494,
      "step": 2238
    },
    {
      "epoch": 2.47,
      "learning_rate": 4.691666666666667e-05,
      "loss": 2.8636,
      "step": 2239
    },
    {
      "epoch": 2.47,
      "learning_rate": 4.683333333333334e-05,
      "loss": 3.0093,
      "step": 2240
    },
    {
      "epoch": 2.47,
      "learning_rate": 4.6750000000000005e-05,
      "loss": 3.0689,
      "step": 2241
    },
    {
      "epoch": 2.47,
      "learning_rate": 4.666666666666667e-05,
      "loss": 3.0773,
      "step": 2242
    },
    {
      "epoch": 2.47,
      "learning_rate": 4.658333333333333e-05,
      "loss": 3.0862,
      "step": 2243
    },
    {
      "epoch": 2.47,
      "learning_rate": 4.6500000000000005e-05,
      "loss": 3.0979,
      "step": 2244
    },
    {
      "epoch": 2.47,
      "learning_rate": 4.641666666666667e-05,
      "loss": 2.9577,
      "step": 2245
    },
    {
      "epoch": 2.47,
      "learning_rate": 4.633333333333333e-05,
      "loss": 2.8955,
      "step": 2246
    },
    {
      "epoch": 2.47,
      "learning_rate": 4.6250000000000006e-05,
      "loss": 2.9166,
      "step": 2247
    },
    {
      "epoch": 2.48,
      "learning_rate": 4.6166666666666666e-05,
      "loss": 3.1534,
      "step": 2248
    },
    {
      "epoch": 2.48,
      "learning_rate": 4.608333333333333e-05,
      "loss": 3.1882,
      "step": 2249
    },
    {
      "epoch": 2.48,
      "learning_rate": 4.600000000000001e-05,
      "loss": 2.9905,
      "step": 2250
    },
    {
      "epoch": 2.48,
      "learning_rate": 4.591666666666667e-05,
      "loss": 2.8534,
      "step": 2251
    },
    {
      "epoch": 2.48,
      "learning_rate": 4.5833333333333334e-05,
      "loss": 2.8827,
      "step": 2252
    },
    {
      "epoch": 2.48,
      "learning_rate": 4.575e-05,
      "loss": 3.0392,
      "step": 2253
    },
    {
      "epoch": 2.48,
      "learning_rate": 4.566666666666667e-05,
      "loss": 3.0259,
      "step": 2254
    },
    {
      "epoch": 2.48,
      "learning_rate": 4.5583333333333335e-05,
      "loss": 2.9891,
      "step": 2255
    },
    {
      "epoch": 2.48,
      "learning_rate": 4.55e-05,
      "loss": 3.2711,
      "step": 2256
    },
    {
      "epoch": 2.49,
      "learning_rate": 4.541666666666667e-05,
      "loss": 3.0073,
      "step": 2257
    },
    {
      "epoch": 2.49,
      "learning_rate": 4.5333333333333335e-05,
      "loss": 3.0092,
      "step": 2258
    },
    {
      "epoch": 2.49,
      "learning_rate": 4.525e-05,
      "loss": 2.8672,
      "step": 2259
    },
    {
      "epoch": 2.49,
      "learning_rate": 4.516666666666667e-05,
      "loss": 3.1285,
      "step": 2260
    },
    {
      "epoch": 2.49,
      "learning_rate": 4.5083333333333336e-05,
      "loss": 2.9005,
      "step": 2261
    },
    {
      "epoch": 2.49,
      "learning_rate": 4.5e-05,
      "loss": 3.1838,
      "step": 2262
    },
    {
      "epoch": 2.49,
      "learning_rate": 4.491666666666667e-05,
      "loss": 3.2988,
      "step": 2263
    },
    {
      "epoch": 2.49,
      "learning_rate": 4.483333333333333e-05,
      "loss": 3.0336,
      "step": 2264
    },
    {
      "epoch": 2.49,
      "learning_rate": 4.4750000000000004e-05,
      "loss": 2.9405,
      "step": 2265
    },
    {
      "epoch": 2.5,
      "learning_rate": 4.466666666666667e-05,
      "loss": 3.09,
      "step": 2266
    },
    {
      "epoch": 2.5,
      "learning_rate": 4.458333333333334e-05,
      "loss": 2.9206,
      "step": 2267
    },
    {
      "epoch": 2.5,
      "learning_rate": 4.4500000000000004e-05,
      "loss": 3.1689,
      "step": 2268
    },
    {
      "epoch": 2.5,
      "learning_rate": 4.4416666666666664e-05,
      "loss": 3.1759,
      "step": 2269
    },
    {
      "epoch": 2.5,
      "learning_rate": 4.433333333333334e-05,
      "loss": 3.1654,
      "step": 2270
    },
    {
      "epoch": 2.5,
      "learning_rate": 4.4250000000000005e-05,
      "loss": 2.9015,
      "step": 2271
    },
    {
      "epoch": 2.5,
      "learning_rate": 4.4166666666666665e-05,
      "loss": 2.9258,
      "step": 2272
    },
    {
      "epoch": 2.5,
      "learning_rate": 4.408333333333334e-05,
      "loss": 3.0111,
      "step": 2273
    },
    {
      "epoch": 2.5,
      "learning_rate": 4.4000000000000006e-05,
      "loss": 3.1037,
      "step": 2274
    },
    {
      "epoch": 2.51,
      "learning_rate": 4.3916666666666666e-05,
      "loss": 3.0228,
      "step": 2275
    },
    {
      "epoch": 2.51,
      "learning_rate": 4.383333333333334e-05,
      "loss": 3.0579,
      "step": 2276
    },
    {
      "epoch": 2.51,
      "learning_rate": 4.375e-05,
      "loss": 3.0125,
      "step": 2277
    },
    {
      "epoch": 2.51,
      "learning_rate": 4.3666666666666666e-05,
      "loss": 3.084,
      "step": 2278
    },
    {
      "epoch": 2.51,
      "learning_rate": 4.358333333333334e-05,
      "loss": 2.8855,
      "step": 2279
    },
    {
      "epoch": 2.51,
      "learning_rate": 4.35e-05,
      "loss": 2.801,
      "step": 2280
    },
    {
      "epoch": 2.51,
      "learning_rate": 4.341666666666667e-05,
      "loss": 2.9939,
      "step": 2281
    },
    {
      "epoch": 2.51,
      "learning_rate": 4.3333333333333334e-05,
      "loss": 2.6044,
      "step": 2282
    },
    {
      "epoch": 2.51,
      "learning_rate": 4.325e-05,
      "loss": 2.9986,
      "step": 2283
    },
    {
      "epoch": 2.52,
      "learning_rate": 4.316666666666667e-05,
      "loss": 2.8673,
      "step": 2284
    },
    {
      "epoch": 2.52,
      "learning_rate": 4.3083333333333335e-05,
      "loss": 3.2363,
      "step": 2285
    },
    {
      "epoch": 2.52,
      "learning_rate": 4.3e-05,
      "loss": 2.8864,
      "step": 2286
    },
    {
      "epoch": 2.52,
      "learning_rate": 4.291666666666667e-05,
      "loss": 3.138,
      "step": 2287
    },
    {
      "epoch": 2.52,
      "learning_rate": 4.2833333333333335e-05,
      "loss": 2.9323,
      "step": 2288
    },
    {
      "epoch": 2.52,
      "learning_rate": 4.275e-05,
      "loss": 3.4212,
      "step": 2289
    },
    {
      "epoch": 2.52,
      "learning_rate": 4.266666666666667e-05,
      "loss": 3.1706,
      "step": 2290
    },
    {
      "epoch": 2.52,
      "learning_rate": 4.2583333333333336e-05,
      "loss": 3.1881,
      "step": 2291
    },
    {
      "epoch": 2.52,
      "learning_rate": 4.25e-05,
      "loss": 2.9178,
      "step": 2292
    },
    {
      "epoch": 2.53,
      "learning_rate": 4.241666666666667e-05,
      "loss": 3.0298,
      "step": 2293
    },
    {
      "epoch": 2.53,
      "learning_rate": 4.233333333333334e-05,
      "loss": 2.9579,
      "step": 2294
    },
    {
      "epoch": 2.53,
      "learning_rate": 4.2250000000000004e-05,
      "loss": 2.7679,
      "step": 2295
    },
    {
      "epoch": 2.53,
      "learning_rate": 4.216666666666667e-05,
      "loss": 2.9299,
      "step": 2296
    },
    {
      "epoch": 2.53,
      "learning_rate": 4.208333333333334e-05,
      "loss": 2.9764,
      "step": 2297
    },
    {
      "epoch": 2.53,
      "learning_rate": 4.2e-05,
      "loss": 2.8767,
      "step": 2298
    },
    {
      "epoch": 2.53,
      "learning_rate": 4.191666666666667e-05,
      "loss": 3.0567,
      "step": 2299
    },
    {
      "epoch": 2.53,
      "learning_rate": 4.183333333333334e-05,
      "loss": 3.0925,
      "step": 2300
    },
    {
      "epoch": 2.53,
      "learning_rate": 4.175e-05,
      "loss": 3.0299,
      "step": 2301
    },
    {
      "epoch": 2.54,
      "learning_rate": 4.166666666666667e-05,
      "loss": 3.1316,
      "step": 2302
    },
    {
      "epoch": 2.54,
      "learning_rate": 4.158333333333333e-05,
      "loss": 3.0313,
      "step": 2303
    },
    {
      "epoch": 2.54,
      "learning_rate": 4.15e-05,
      "loss": 2.9358,
      "step": 2304
    },
    {
      "epoch": 2.54,
      "learning_rate": 4.141666666666667e-05,
      "loss": 3.0527,
      "step": 2305
    },
    {
      "epoch": 2.54,
      "learning_rate": 4.133333333333333e-05,
      "loss": 2.8784,
      "step": 2306
    },
    {
      "epoch": 2.54,
      "learning_rate": 4.125e-05,
      "loss": 2.9792,
      "step": 2307
    },
    {
      "epoch": 2.54,
      "learning_rate": 4.116666666666667e-05,
      "loss": 3.2193,
      "step": 2308
    },
    {
      "epoch": 2.54,
      "learning_rate": 4.1083333333333334e-05,
      "loss": 2.9439,
      "step": 2309
    },
    {
      "epoch": 2.54,
      "learning_rate": 4.1e-05,
      "loss": 3.0196,
      "step": 2310
    },
    {
      "epoch": 2.55,
      "learning_rate": 4.091666666666667e-05,
      "loss": 3.0703,
      "step": 2311
    },
    {
      "epoch": 2.55,
      "learning_rate": 4.0833333333333334e-05,
      "loss": 3.2785,
      "step": 2312
    },
    {
      "epoch": 2.55,
      "learning_rate": 4.075e-05,
      "loss": 3.0069,
      "step": 2313
    },
    {
      "epoch": 2.55,
      "learning_rate": 4.066666666666667e-05,
      "loss": 3.0335,
      "step": 2314
    },
    {
      "epoch": 2.55,
      "learning_rate": 4.0583333333333335e-05,
      "loss": 3.1571,
      "step": 2315
    },
    {
      "epoch": 2.55,
      "learning_rate": 4.05e-05,
      "loss": 3.0998,
      "step": 2316
    },
    {
      "epoch": 2.55,
      "learning_rate": 4.041666666666667e-05,
      "loss": 3.2713,
      "step": 2317
    },
    {
      "epoch": 2.55,
      "learning_rate": 4.0333333333333336e-05,
      "loss": 3.09,
      "step": 2318
    },
    {
      "epoch": 2.55,
      "learning_rate": 4.025e-05,
      "loss": 3.1246,
      "step": 2319
    },
    {
      "epoch": 2.56,
      "learning_rate": 4.016666666666667e-05,
      "loss": 3.0028,
      "step": 2320
    },
    {
      "epoch": 2.56,
      "learning_rate": 4.0083333333333336e-05,
      "loss": 2.912,
      "step": 2321
    },
    {
      "epoch": 2.56,
      "learning_rate": 4e-05,
      "loss": 3.1152,
      "step": 2322
    },
    {
      "epoch": 2.56,
      "learning_rate": 3.991666666666667e-05,
      "loss": 3.009,
      "step": 2323
    },
    {
      "epoch": 2.56,
      "learning_rate": 3.983333333333333e-05,
      "loss": 3.1193,
      "step": 2324
    },
    {
      "epoch": 2.56,
      "learning_rate": 3.9750000000000004e-05,
      "loss": 3.1425,
      "step": 2325
    },
    {
      "epoch": 2.56,
      "learning_rate": 3.966666666666667e-05,
      "loss": 2.8998,
      "step": 2326
    },
    {
      "epoch": 2.56,
      "learning_rate": 3.958333333333333e-05,
      "loss": 3.0222,
      "step": 2327
    },
    {
      "epoch": 2.56,
      "learning_rate": 3.9500000000000005e-05,
      "loss": 3.1683,
      "step": 2328
    },
    {
      "epoch": 2.56,
      "learning_rate": 3.941666666666667e-05,
      "loss": 3.2333,
      "step": 2329
    },
    {
      "epoch": 2.57,
      "learning_rate": 3.933333333333333e-05,
      "loss": 2.9698,
      "step": 2330
    },
    {
      "epoch": 2.57,
      "learning_rate": 3.9250000000000005e-05,
      "loss": 3.168,
      "step": 2331
    },
    {
      "epoch": 2.57,
      "learning_rate": 3.9166666666666665e-05,
      "loss": 2.9283,
      "step": 2332
    },
    {
      "epoch": 2.57,
      "learning_rate": 3.908333333333333e-05,
      "loss": 3.0661,
      "step": 2333
    },
    {
      "epoch": 2.57,
      "learning_rate": 3.9000000000000006e-05,
      "loss": 3.0976,
      "step": 2334
    },
    {
      "epoch": 2.57,
      "learning_rate": 3.8916666666666666e-05,
      "loss": 3.1208,
      "step": 2335
    },
    {
      "epoch": 2.57,
      "learning_rate": 3.883333333333333e-05,
      "loss": 3.0461,
      "step": 2336
    },
    {
      "epoch": 2.57,
      "learning_rate": 3.875e-05,
      "loss": 3.0675,
      "step": 2337
    },
    {
      "epoch": 2.57,
      "learning_rate": 3.866666666666667e-05,
      "loss": 3.0502,
      "step": 2338
    },
    {
      "epoch": 2.58,
      "learning_rate": 3.8583333333333334e-05,
      "loss": 2.8992,
      "step": 2339
    },
    {
      "epoch": 2.58,
      "learning_rate": 3.85e-05,
      "loss": 3.1078,
      "step": 2340
    },
    {
      "epoch": 2.58,
      "learning_rate": 3.841666666666667e-05,
      "loss": 2.9114,
      "step": 2341
    },
    {
      "epoch": 2.58,
      "learning_rate": 3.8333333333333334e-05,
      "loss": 2.7132,
      "step": 2342
    },
    {
      "epoch": 2.58,
      "learning_rate": 3.825e-05,
      "loss": 3.1316,
      "step": 2343
    },
    {
      "epoch": 2.58,
      "learning_rate": 3.816666666666667e-05,
      "loss": 3.0923,
      "step": 2344
    },
    {
      "epoch": 2.58,
      "learning_rate": 3.8083333333333335e-05,
      "loss": 3.1497,
      "step": 2345
    },
    {
      "epoch": 2.58,
      "learning_rate": 3.8e-05,
      "loss": 3.0358,
      "step": 2346
    },
    {
      "epoch": 2.58,
      "learning_rate": 3.791666666666667e-05,
      "loss": 3.0544,
      "step": 2347
    },
    {
      "epoch": 2.59,
      "learning_rate": 3.7833333333333336e-05,
      "loss": 3.2151,
      "step": 2348
    },
    {
      "epoch": 2.59,
      "learning_rate": 3.775e-05,
      "loss": 3.0929,
      "step": 2349
    },
    {
      "epoch": 2.59,
      "learning_rate": 3.766666666666667e-05,
      "loss": 3.0119,
      "step": 2350
    },
    {
      "epoch": 2.59,
      "learning_rate": 3.7583333333333337e-05,
      "loss": 3.0161,
      "step": 2351
    },
    {
      "epoch": 2.59,
      "learning_rate": 3.7500000000000003e-05,
      "loss": 3.3245,
      "step": 2352
    },
    {
      "epoch": 2.59,
      "learning_rate": 3.7416666666666664e-05,
      "loss": 3.0332,
      "step": 2353
    },
    {
      "epoch": 2.59,
      "learning_rate": 3.733333333333334e-05,
      "loss": 3.1383,
      "step": 2354
    },
    {
      "epoch": 2.59,
      "learning_rate": 3.7250000000000004e-05,
      "loss": 3.0277,
      "step": 2355
    },
    {
      "epoch": 2.59,
      "learning_rate": 3.7166666666666664e-05,
      "loss": 2.9922,
      "step": 2356
    },
    {
      "epoch": 2.6,
      "learning_rate": 3.708333333333334e-05,
      "loss": 3.0298,
      "step": 2357
    },
    {
      "epoch": 2.6,
      "learning_rate": 3.7e-05,
      "loss": 3.1756,
      "step": 2358
    },
    {
      "epoch": 2.6,
      "learning_rate": 3.6916666666666665e-05,
      "loss": 3.0602,
      "step": 2359
    },
    {
      "epoch": 2.6,
      "learning_rate": 3.683333333333334e-05,
      "loss": 3.0095,
      "step": 2360
    },
    {
      "epoch": 2.6,
      "learning_rate": 3.675e-05,
      "loss": 3.0273,
      "step": 2361
    },
    {
      "epoch": 2.6,
      "learning_rate": 3.6666666666666666e-05,
      "loss": 2.9719,
      "step": 2362
    },
    {
      "epoch": 2.6,
      "learning_rate": 3.658333333333334e-05,
      "loss": 3.2776,
      "step": 2363
    },
    {
      "epoch": 2.6,
      "learning_rate": 3.65e-05,
      "loss": 3.073,
      "step": 2364
    },
    {
      "epoch": 2.6,
      "learning_rate": 3.641666666666667e-05,
      "loss": 2.9881,
      "step": 2365
    },
    {
      "epoch": 2.61,
      "learning_rate": 3.633333333333333e-05,
      "loss": 3.0667,
      "step": 2366
    },
    {
      "epoch": 2.61,
      "learning_rate": 3.625e-05,
      "loss": 2.9361,
      "step": 2367
    },
    {
      "epoch": 2.61,
      "learning_rate": 3.6166666666666674e-05,
      "loss": 3.0558,
      "step": 2368
    },
    {
      "epoch": 2.61,
      "learning_rate": 3.6083333333333334e-05,
      "loss": 3.1821,
      "step": 2369
    },
    {
      "epoch": 2.61,
      "learning_rate": 3.6e-05,
      "loss": 3.2102,
      "step": 2370
    },
    {
      "epoch": 2.61,
      "learning_rate": 3.591666666666667e-05,
      "loss": 3.1264,
      "step": 2371
    },
    {
      "epoch": 2.61,
      "learning_rate": 3.5833333333333335e-05,
      "loss": 3.034,
      "step": 2372
    },
    {
      "epoch": 2.61,
      "learning_rate": 3.575e-05,
      "loss": 2.9183,
      "step": 2373
    },
    {
      "epoch": 2.61,
      "learning_rate": 3.566666666666667e-05,
      "loss": 2.8571,
      "step": 2374
    },
    {
      "epoch": 2.62,
      "learning_rate": 3.5583333333333335e-05,
      "loss": 2.9184,
      "step": 2375
    },
    {
      "epoch": 2.62,
      "learning_rate": 3.55e-05,
      "loss": 3.1797,
      "step": 2376
    },
    {
      "epoch": 2.62,
      "learning_rate": 3.541666666666667e-05,
      "loss": 3.0922,
      "step": 2377
    },
    {
      "epoch": 2.62,
      "learning_rate": 3.5333333333333336e-05,
      "loss": 2.8528,
      "step": 2378
    },
    {
      "epoch": 2.62,
      "learning_rate": 3.525e-05,
      "loss": 3.2601,
      "step": 2379
    },
    {
      "epoch": 2.62,
      "learning_rate": 3.516666666666667e-05,
      "loss": 3.1064,
      "step": 2380
    },
    {
      "epoch": 2.62,
      "learning_rate": 3.508333333333334e-05,
      "loss": 3.0774,
      "step": 2381
    },
    {
      "epoch": 2.62,
      "learning_rate": 3.5e-05,
      "loss": 3.0039,
      "step": 2382
    },
    {
      "epoch": 2.62,
      "learning_rate": 3.491666666666667e-05,
      "loss": 3.0445,
      "step": 2383
    },
    {
      "epoch": 2.63,
      "learning_rate": 3.483333333333334e-05,
      "loss": 2.9499,
      "step": 2384
    },
    {
      "epoch": 2.63,
      "learning_rate": 3.475e-05,
      "loss": 2.9608,
      "step": 2385
    },
    {
      "epoch": 2.63,
      "learning_rate": 3.466666666666667e-05,
      "loss": 3.1164,
      "step": 2386
    },
    {
      "epoch": 2.63,
      "learning_rate": 3.458333333333333e-05,
      "loss": 3.2149,
      "step": 2387
    },
    {
      "epoch": 2.63,
      "learning_rate": 3.45e-05,
      "loss": 3.118,
      "step": 2388
    },
    {
      "epoch": 2.63,
      "learning_rate": 3.441666666666667e-05,
      "loss": 2.9195,
      "step": 2389
    },
    {
      "epoch": 2.63,
      "learning_rate": 3.433333333333333e-05,
      "loss": 3.0492,
      "step": 2390
    },
    {
      "epoch": 2.63,
      "learning_rate": 3.4250000000000006e-05,
      "loss": 2.9906,
      "step": 2391
    },
    {
      "epoch": 2.63,
      "learning_rate": 3.4166666666666666e-05,
      "loss": 2.9881,
      "step": 2392
    },
    {
      "epoch": 2.64,
      "learning_rate": 3.408333333333333e-05,
      "loss": 2.9417,
      "step": 2393
    },
    {
      "epoch": 2.64,
      "learning_rate": 3.4000000000000007e-05,
      "loss": 2.9756,
      "step": 2394
    },
    {
      "epoch": 2.64,
      "learning_rate": 3.391666666666667e-05,
      "loss": 2.8798,
      "step": 2395
    },
    {
      "epoch": 2.64,
      "learning_rate": 3.3833333333333334e-05,
      "loss": 3.1023,
      "step": 2396
    },
    {
      "epoch": 2.64,
      "learning_rate": 3.375000000000001e-05,
      "loss": 3.1586,
      "step": 2397
    },
    {
      "epoch": 2.64,
      "learning_rate": 3.366666666666667e-05,
      "loss": 2.9862,
      "step": 2398
    },
    {
      "epoch": 2.64,
      "learning_rate": 3.3583333333333334e-05,
      "loss": 3.0634,
      "step": 2399
    },
    {
      "epoch": 2.64,
      "learning_rate": 3.35e-05,
      "loss": 2.9719,
      "step": 2400
    },
    {
      "epoch": 2.64,
      "learning_rate": 3.341666666666667e-05,
      "loss": 3.0585,
      "step": 2401
    },
    {
      "epoch": 2.65,
      "learning_rate": 3.3333333333333335e-05,
      "loss": 3.0369,
      "step": 2402
    },
    {
      "epoch": 2.65,
      "learning_rate": 3.325e-05,
      "loss": 3.1235,
      "step": 2403
    },
    {
      "epoch": 2.65,
      "learning_rate": 3.316666666666667e-05,
      "loss": 3.0631,
      "step": 2404
    },
    {
      "epoch": 2.65,
      "learning_rate": 3.3083333333333336e-05,
      "loss": 2.9787,
      "step": 2405
    },
    {
      "epoch": 2.65,
      "learning_rate": 3.3e-05,
      "loss": 3.1296,
      "step": 2406
    },
    {
      "epoch": 2.65,
      "learning_rate": 3.291666666666667e-05,
      "loss": 3.0222,
      "step": 2407
    },
    {
      "epoch": 2.65,
      "learning_rate": 3.283333333333333e-05,
      "loss": 3.1595,
      "step": 2408
    },
    {
      "epoch": 2.65,
      "learning_rate": 3.275e-05,
      "loss": 3.056,
      "step": 2409
    },
    {
      "epoch": 2.65,
      "learning_rate": 3.266666666666667e-05,
      "loss": 3.2061,
      "step": 2410
    },
    {
      "epoch": 2.66,
      "learning_rate": 3.258333333333333e-05,
      "loss": 2.9245,
      "step": 2411
    },
    {
      "epoch": 2.66,
      "learning_rate": 3.2500000000000004e-05,
      "loss": 3.1406,
      "step": 2412
    },
    {
      "epoch": 2.66,
      "learning_rate": 3.2416666666666664e-05,
      "loss": 3.1964,
      "step": 2413
    },
    {
      "epoch": 2.66,
      "learning_rate": 3.233333333333333e-05,
      "loss": 2.9708,
      "step": 2414
    },
    {
      "epoch": 2.66,
      "learning_rate": 3.2250000000000005e-05,
      "loss": 3.1921,
      "step": 2415
    },
    {
      "epoch": 2.66,
      "learning_rate": 3.2166666666666665e-05,
      "loss": 3.0594,
      "step": 2416
    },
    {
      "epoch": 2.66,
      "learning_rate": 3.208333333333334e-05,
      "loss": 3.1749,
      "step": 2417
    },
    {
      "epoch": 2.66,
      "learning_rate": 3.2000000000000005e-05,
      "loss": 2.7926,
      "step": 2418
    },
    {
      "epoch": 2.66,
      "learning_rate": 3.1916666666666665e-05,
      "loss": 3.0363,
      "step": 2419
    },
    {
      "epoch": 2.67,
      "learning_rate": 3.183333333333334e-05,
      "loss": 3.0035,
      "step": 2420
    },
    {
      "epoch": 2.67,
      "learning_rate": 3.175e-05,
      "loss": 3.0439,
      "step": 2421
    },
    {
      "epoch": 2.67,
      "learning_rate": 3.1666666666666666e-05,
      "loss": 3.1342,
      "step": 2422
    },
    {
      "epoch": 2.67,
      "learning_rate": 3.158333333333334e-05,
      "loss": 3.1036,
      "step": 2423
    },
    {
      "epoch": 2.67,
      "learning_rate": 3.15e-05,
      "loss": 3.1787,
      "step": 2424
    },
    {
      "epoch": 2.67,
      "learning_rate": 3.141666666666667e-05,
      "loss": 3.1856,
      "step": 2425
    },
    {
      "epoch": 2.67,
      "learning_rate": 3.1333333333333334e-05,
      "loss": 3.0894,
      "step": 2426
    },
    {
      "epoch": 2.67,
      "learning_rate": 3.125e-05,
      "loss": 3.1649,
      "step": 2427
    },
    {
      "epoch": 2.67,
      "learning_rate": 3.116666666666667e-05,
      "loss": 3.0328,
      "step": 2428
    },
    {
      "epoch": 2.68,
      "learning_rate": 3.1083333333333334e-05,
      "loss": 2.9033,
      "step": 2429
    },
    {
      "epoch": 2.68,
      "learning_rate": 3.1e-05,
      "loss": 3.1343,
      "step": 2430
    },
    {
      "epoch": 2.68,
      "learning_rate": 3.091666666666667e-05,
      "loss": 3.1503,
      "step": 2431
    },
    {
      "epoch": 2.68,
      "learning_rate": 3.0833333333333335e-05,
      "loss": 2.9108,
      "step": 2432
    },
    {
      "epoch": 2.68,
      "learning_rate": 3.075e-05,
      "loss": 2.9395,
      "step": 2433
    },
    {
      "epoch": 2.68,
      "learning_rate": 3.066666666666667e-05,
      "loss": 2.7599,
      "step": 2434
    },
    {
      "epoch": 2.68,
      "learning_rate": 3.0583333333333336e-05,
      "loss": 3.1137,
      "step": 2435
    },
    {
      "epoch": 2.68,
      "learning_rate": 3.05e-05,
      "loss": 3.1301,
      "step": 2436
    },
    {
      "epoch": 2.68,
      "learning_rate": 3.0416666666666666e-05,
      "loss": 3.0611,
      "step": 2437
    },
    {
      "epoch": 2.69,
      "learning_rate": 3.0333333333333337e-05,
      "loss": 3.0865,
      "step": 2438
    },
    {
      "epoch": 2.69,
      "learning_rate": 3.025e-05,
      "loss": 3.1848,
      "step": 2439
    },
    {
      "epoch": 2.69,
      "learning_rate": 3.016666666666667e-05,
      "loss": 3.0088,
      "step": 2440
    },
    {
      "epoch": 2.69,
      "learning_rate": 3.0083333333333337e-05,
      "loss": 3.1175,
      "step": 2441
    },
    {
      "epoch": 2.69,
      "learning_rate": 3e-05,
      "loss": 3.0317,
      "step": 2442
    },
    {
      "epoch": 2.69,
      "learning_rate": 2.991666666666667e-05,
      "loss": 3.1751,
      "step": 2443
    },
    {
      "epoch": 2.69,
      "learning_rate": 2.9833333333333335e-05,
      "loss": 2.9896,
      "step": 2444
    },
    {
      "epoch": 2.69,
      "learning_rate": 2.975e-05,
      "loss": 3.06,
      "step": 2445
    },
    {
      "epoch": 2.69,
      "learning_rate": 2.9666666666666672e-05,
      "loss": 3.1897,
      "step": 2446
    },
    {
      "epoch": 2.69,
      "learning_rate": 2.9583333333333335e-05,
      "loss": 2.932,
      "step": 2447
    },
    {
      "epoch": 2.7,
      "learning_rate": 2.95e-05,
      "loss": 3.0984,
      "step": 2448
    },
    {
      "epoch": 2.7,
      "learning_rate": 2.941666666666667e-05,
      "loss": 3.2321,
      "step": 2449
    },
    {
      "epoch": 2.7,
      "learning_rate": 2.9333333333333336e-05,
      "loss": 3.1105,
      "step": 2450
    },
    {
      "epoch": 2.7,
      "learning_rate": 2.925e-05,
      "loss": 2.9443,
      "step": 2451
    },
    {
      "epoch": 2.7,
      "learning_rate": 2.916666666666667e-05,
      "loss": 3.2772,
      "step": 2452
    },
    {
      "epoch": 2.7,
      "learning_rate": 2.9083333333333333e-05,
      "loss": 2.9765,
      "step": 2453
    },
    {
      "epoch": 2.7,
      "learning_rate": 2.9e-05,
      "loss": 3.1703,
      "step": 2454
    },
    {
      "epoch": 2.7,
      "learning_rate": 2.891666666666667e-05,
      "loss": 3.237,
      "step": 2455
    },
    {
      "epoch": 2.7,
      "learning_rate": 2.8833333333333334e-05,
      "loss": 3.112,
      "step": 2456
    },
    {
      "epoch": 2.71,
      "learning_rate": 2.8749999999999997e-05,
      "loss": 2.9841,
      "step": 2457
    },
    {
      "epoch": 2.71,
      "learning_rate": 2.8666666666666668e-05,
      "loss": 3.0693,
      "step": 2458
    },
    {
      "epoch": 2.71,
      "learning_rate": 2.8583333333333335e-05,
      "loss": 3.0877,
      "step": 2459
    },
    {
      "epoch": 2.71,
      "learning_rate": 2.8499999999999998e-05,
      "loss": 2.9272,
      "step": 2460
    },
    {
      "epoch": 2.71,
      "learning_rate": 2.841666666666667e-05,
      "loss": 3.0941,
      "step": 2461
    },
    {
      "epoch": 2.71,
      "learning_rate": 2.8333333333333335e-05,
      "loss": 2.9649,
      "step": 2462
    },
    {
      "epoch": 2.71,
      "learning_rate": 2.825e-05,
      "loss": 3.0085,
      "step": 2463
    },
    {
      "epoch": 2.71,
      "learning_rate": 2.816666666666667e-05,
      "loss": 2.9522,
      "step": 2464
    },
    {
      "epoch": 2.71,
      "learning_rate": 2.8083333333333333e-05,
      "loss": 3.1936,
      "step": 2465
    },
    {
      "epoch": 2.72,
      "learning_rate": 2.8000000000000003e-05,
      "loss": 3.2299,
      "step": 2466
    },
    {
      "epoch": 2.72,
      "learning_rate": 2.791666666666667e-05,
      "loss": 3.1028,
      "step": 2467
    },
    {
      "epoch": 2.72,
      "learning_rate": 2.7833333333333333e-05,
      "loss": 3.0014,
      "step": 2468
    },
    {
      "epoch": 2.72,
      "learning_rate": 2.7750000000000004e-05,
      "loss": 3.0201,
      "step": 2469
    },
    {
      "epoch": 2.72,
      "learning_rate": 2.7666666666666667e-05,
      "loss": 3.0721,
      "step": 2470
    },
    {
      "epoch": 2.72,
      "learning_rate": 2.7583333333333334e-05,
      "loss": 3.0918,
      "step": 2471
    },
    {
      "epoch": 2.72,
      "learning_rate": 2.7500000000000004e-05,
      "loss": 3.0433,
      "step": 2472
    },
    {
      "epoch": 2.72,
      "learning_rate": 2.7416666666666668e-05,
      "loss": 2.9508,
      "step": 2473
    },
    {
      "epoch": 2.72,
      "learning_rate": 2.733333333333333e-05,
      "loss": 3.0392,
      "step": 2474
    },
    {
      "epoch": 2.73,
      "learning_rate": 2.725e-05,
      "loss": 2.969,
      "step": 2475
    },
    {
      "epoch": 2.73,
      "learning_rate": 2.716666666666667e-05,
      "loss": 3.0535,
      "step": 2476
    },
    {
      "epoch": 2.73,
      "learning_rate": 2.7083333333333332e-05,
      "loss": 2.7389,
      "step": 2477
    },
    {
      "epoch": 2.73,
      "learning_rate": 2.7000000000000002e-05,
      "loss": 3.2183,
      "step": 2478
    },
    {
      "epoch": 2.73,
      "learning_rate": 2.691666666666667e-05,
      "loss": 2.9396,
      "step": 2479
    },
    {
      "epoch": 2.73,
      "learning_rate": 2.6833333333333333e-05,
      "loss": 2.9571,
      "step": 2480
    },
    {
      "epoch": 2.73,
      "learning_rate": 2.6750000000000003e-05,
      "loss": 3.1786,
      "step": 2481
    },
    {
      "epoch": 2.73,
      "learning_rate": 2.6666666666666667e-05,
      "loss": 3.1618,
      "step": 2482
    },
    {
      "epoch": 2.73,
      "learning_rate": 2.6583333333333333e-05,
      "loss": 2.9192,
      "step": 2483
    },
    {
      "epoch": 2.74,
      "learning_rate": 2.6500000000000004e-05,
      "loss": 2.8659,
      "step": 2484
    },
    {
      "epoch": 2.74,
      "learning_rate": 2.6416666666666667e-05,
      "loss": 3.0595,
      "step": 2485
    },
    {
      "epoch": 2.74,
      "learning_rate": 2.633333333333333e-05,
      "loss": 3.0842,
      "step": 2486
    },
    {
      "epoch": 2.74,
      "learning_rate": 2.625e-05,
      "loss": 3.1145,
      "step": 2487
    },
    {
      "epoch": 2.74,
      "learning_rate": 2.6166666666666668e-05,
      "loss": 2.9135,
      "step": 2488
    },
    {
      "epoch": 2.74,
      "learning_rate": 2.608333333333333e-05,
      "loss": 2.9746,
      "step": 2489
    },
    {
      "epoch": 2.74,
      "learning_rate": 2.6000000000000002e-05,
      "loss": 2.9563,
      "step": 2490
    },
    {
      "epoch": 2.74,
      "learning_rate": 2.5916666666666665e-05,
      "loss": 3.2029,
      "step": 2491
    },
    {
      "epoch": 2.74,
      "learning_rate": 2.5833333333333336e-05,
      "loss": 3.0523,
      "step": 2492
    },
    {
      "epoch": 2.75,
      "learning_rate": 2.5750000000000002e-05,
      "loss": 3.171,
      "step": 2493
    },
    {
      "epoch": 2.75,
      "learning_rate": 2.5666666666666666e-05,
      "loss": 3.2045,
      "step": 2494
    },
    {
      "epoch": 2.75,
      "learning_rate": 2.5583333333333336e-05,
      "loss": 2.9292,
      "step": 2495
    },
    {
      "epoch": 2.75,
      "learning_rate": 2.5500000000000003e-05,
      "loss": 3.1824,
      "step": 2496
    },
    {
      "epoch": 2.75,
      "learning_rate": 2.5416666666666667e-05,
      "loss": 2.9902,
      "step": 2497
    },
    {
      "epoch": 2.75,
      "learning_rate": 2.5333333333333337e-05,
      "loss": 3.0203,
      "step": 2498
    },
    {
      "epoch": 2.75,
      "learning_rate": 2.525e-05,
      "loss": 2.7694,
      "step": 2499
    },
    {
      "epoch": 2.75,
      "learning_rate": 2.5166666666666667e-05,
      "loss": 3.2462,
      "step": 2500
    }
  ],
  "logging_steps": 1,
  "max_steps": 2800,
  "num_train_epochs": 4,
  "save_steps": 500,
  "total_flos": 1.0105562995359744e+17,
  "trial_name": null,
  "trial_params": null
}
